{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "#Preliminaries\n",
    "\n",
    "from __future__ import absolute_import, division, print_function  # Python 2/3 compatibility\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "\n",
    "import numpy\n",
    "from keras.models  import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "## Load in the data set (Internet Access needed)\n",
    "\n",
    "##url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('pima-indians-diabetes.data', names=names)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "412               1                     143              84              23   \n",
       "399               3                     193              70              31   \n",
       "42                7                     106              92              18   \n",
       "61                8                     133              72               0   \n",
       "724               1                     111              94               0   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "412      310  42.4              1.076   22             0  \n",
       "399        0  34.9              0.241   25             1  \n",
       "42         0  22.7              0.235   48             0  \n",
       "61         0  32.9              0.270   39             1  \n",
       "724        0  32.8              0.265   45             0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>84</td>\n",
       "      <td>23</td>\n",
       "      <td>310</td>\n",
       "      <td>42.4</td>\n",
       "      <td>1.076</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>3</td>\n",
       "      <td>193</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>34.9</td>\n",
       "      <td>0.241</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>7</td>\n",
       "      <td>106</td>\n",
       "      <td>92</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>22.7</td>\n",
       "      <td>0.235</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>8</td>\n",
       "      <td>133</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.270</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.8</td>\n",
       "      <td>0.265</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "np.mean(y), np.mean(1-y)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "#O método \"predict_classes\" não funciona nas versões do Keras superior a 2.5 \n",
    "\n",
    "# A indicação da correção se encontra em https://keras.rstudio.com/reference/predict_proba.html#details. \n",
    "\n",
    "# usar: \n",
    "# y_pred_class_nn_1 = model_1.predict(X_test_norm)\n",
    "# y_pred_class_nn_1 = (y_pred_prob_nn_1 > 0.5).astype(\"int32\")\n",
    "\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy is 0.771\n",
      "roc-auc is 0.831\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAHiCAYAAADSwATnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABGm0lEQVR4nO3dd3iUVfrG8e8JvVfpzRUQEQsIgi4iuioqKsuKriCCu65ukZVeQo8oiCgIv8W1Y2ERGyi6YCegKB2ko4TeSxIIEEiZ8/tjBjfGhEySmZwp9+e65mLemXfeuedkmGeet42x1iIiIiKhI8Z1ABEREfklFWcREZEQo+IsIiISYlScRUREQoyKs4iISIhRcRYREQkxKs4SlYwxZYwxHxtjjhtj3nOdJ5oYYx40xnybZfqkMeY3fjyukTHGGmOKBzehO3m9RmPMWGPMzKLOJUVPxTkKGGN2GmNSfR+CB40xrxtjymeb51pjzNfGmBRfwfrYGNM82zwVjTHPGWN2+5aV4JuunsvzGmPMY8aYDcaYU8aYvcaY94wxlwXz9fqpG1ATqGatvaewCzPGdDTGeHzjkmKM2WqM+VO2eaxvHE76LsmFfV4/cr1ujEnzPV+iMeYLY0wz332/+KD35TuctTAYY0r4bvvVCRF8y84wxtQuTEZrbXlr7fbCLCMv0VDYJbKoOEePO6215YErgZZA7Lk7jDHXAJ8DHwF1gAuBH4Al5zoaY0xJ4CvgUuBWoCJwDXAMuDqX55wK9AUeA6oCTYEPgc75DR+ED9WGwI/W2owAZtnvG+OKQH/gZWPMxdnmucJXjMpbayvn97kL6GlfrnrAYeD188ybBNyWZfo2322/YIwpB9wNHAd6BixphNOXA/GXinOUsdYeBD7DW6TPeRp401o71VqbYq1NtNaOBJYCY33z9AIaAF2ttZustR5r7WFr7Thr7fzsz2OMaQI8CnS31n5trT1rrT1trf2PtfYp3zzxxpi/ZHlM9tWd1hjzqDHmJ+AnY8y/jTHPZHuej4wxA3zX6xhjPjDGHDHG7DDGPJbTGBhj4oDRwB99HeVDxpgYY8xIY8wuX6f4pjGmkm/+c13XQ8aY3cDXeYyx9Y1JInD5+ebNJZ8/WXr71mAcNcaM8Ge51trTwCygxXlmewvv3/qcXsCbOcx3N5AMPA70zuP1VDPGzDPGnDDGLAcuyna/NcY09l3vbIxZ45t3jzFmbA6L/LMxZr8x5oAxZlCW5cQYY4b51ugcM8a8a4yp6rt7se/fZN/f/BrfY/5sjNlsjEkyxnxmjGnou90YY6b4xv+EMWa9MSbHcfO9jycYY5b75v3o3PPm9N453983r9eYw3O3M8Z8Z4xJNsb8YIzpmC3XE777Txrv2rBqxpj/+HKuMMY0ym3Z4pi1VpcIvwA7gZt81+sB64GpvumyQCZwQw6P+xNwwHd9NvBGPp7zb8CuPOaJB/6SZfpB4Nss0xb4Am/XXQboAOwBjO/+KkAq3m4/BliFt+iWBH4DbAc65fLcY4GZWab/DGzzPa48MAd4y3dfI1+WN4FyQJkcltcR2Ou7HgPcBXiAltleT2M/xs6fLC/7xuQK4CxwSS7Leh14wne9PN7i/E0uY2DxFu5DQGXf+B7y3WazLfcrvF/qagIZwFXneT2zgXd9Y9cC2JfD37lxlnG8zDeGl/ue//fZXvvbvmVdBhzhf+/tvni/UNYDSgEvAm9ne2zxLM/bxTfOlwDFgZHAd777OvneT5UB45un9nnex/t8r60c8MG5cc3pvePn3ze31zg2y7Lr4l1zdbtvvG72TV+QJdc2vF+GKgGbgB+Bm3yv901ghuvPJ11y+X/jOoAuRfBH9hbnk0CK7z/+V0Bl3331fLc1y+FxtwLpvutfAE/l4zlHAEvzmCeevIvzjVmmDbAb6OCbfhj42ne9LbA72/Jjc/vw4deF6SvgH1mmLwbSfR9i5z4wf3Oe19IRbzFOxlssM4F+2eaxwAnfPMnAtFyW5U+WelnuXw7cl8uyXgfO+J7vIDAPuCiXMbBAY+AV4K94v2C97LvNZpmvge+1Xumb/gzfl70cnr+YL3uzLLeNz+HvnOOXFuA5YIrv+rnXnnVZTwOv+q5vBn6X5b7aOYxb1uK8AHgoy3QMcBrvJo8b8RaydkCMH+/jp7JMNwfSfK/9V+8dP/++ub3Gn/9mwFB8RT3LvJ8BvbPkGpHlvmeBBVmm7wTW+vt/WpeivWi1dvT4vbW2At4i0gw4txNXEt4P2px26qkNHPVdP5bLPLnJ7/y52XPuivV+oswGuvtu6gH8x3e9IVDHt3ov2Xh3thqOt7PzRx1gV5bpXXg/LLM+fg/nt996tyNXBKbh/YDPrpW1trLvkuNqdz+zHMxy/TTeDiw3z/ier5a19i5rbUIer+NNvKuzc1ul/QCw2Vq71jf9H6CHMaZEDvNe4Muedex25TAfAMaYtsaYhb5NE8fxfkHIvsNh9mXV8V1vCMzN8vffjPdLUm7vgYbA1CzzJ+L9AljXWvs18C9gOnDYGPOSMaZibrlzyFQiW+6s9+f3vZb1NWbPf0+293x7fvn/7lCW66k5TJ/vfSMOqThHGWvtIrzd1DO+6VPA90BOeyzfi/dbPsCXQCfj3RHIH18B9Ywxrc8zzym8q9XPqZVT5GzTbwPdfNsG2+JdhQjeD7MdWQpfZWttBWvt7X7m3Y/3w+6cBnhX12b9MMueJUfW2rN4u5rLjDG/9/P585slmL7B+wFfE/g2h/t7Ab8x3j3/DwKT8RainMb6CN7s9bPc1uA8zz0Lb3df31pbCXgBb8HMKvuy9vuu7wFuy/YeKG2t3UfOf7s9wF+zzV/GWvsdgLV2mrX2KrydcFNg8HlyZ8+Uzv++2JLt+f35++b2GrPnfytb/nLWt0+HhDcV5+j0HHCzMeYK3/QwoLfxHvZUwRhTxRjzBN69seN887yF98PgA2NMM99OLdWMMcONMb/6ULbW/gQ8D7xtvIcZlTTGlDbG3GeMGeabbS3wB2NMWd8OQQ/lFdxauwbvh94rwGfW2mTfXcuBFGPMUOM9hrmYMaaFMaaNn2PyNtDfGHOh8R5mNh54xxZgb25fzjS8qxFHF+DhAc2SX741FHcCd/mu/8y3I9VFePfQv9J3aYG3qPYiG2ttJt5tqmN9f+fmnH8HsgpAorX2jDHmarxrR7Ib5VvWpXj3i3jHd/sLwJNZduq6wBjTxXffEbxriLIeT/0CEOtbDsaYSsaYe3zX2/i6+BJ4v0Se8T0+Nz2NMc2NMWXx7iT3vu+158Sfv29urzGrmcCdxphOvvd7ad//tXrnySlhQsU5Cllrj+BdXTnaN/0t3h1g/gAcwLsarSXQ3ldkz3WDNwFb8G5/PoG3IFYHluXyVI/xv1WDyUAC0BX42Hf/FLzb5g4Bb/C/VdR5meXLMivLa8oE7sBbLHbwvwJeyc9lvob3C8hi3+PPAP/087HnW2YDY8ydBXhcoLPki7V2o7V2Yw539QY+staut9YePHfBe9jcHeZ/e0dn1Qfv6tODeNfazDjPU/8DeNwYk4L3/fluDvMswruj01d4V9l/7rt9Kt6u+3Pf45fiXbuC9e6p/iTewwOTjTHtrLVzgYnAbGPMCWAD/zuMrCLe7e1JeP8/HAMmnSf3W77XdhAojfe9nxt//r65vcafWWv34N2pbTjeLx978Hb3+lyPACbbF2MREckHY0w83p20XnGdRSKHvmGJiIiEGBVnERGREKPV2iIiIiFGnbOIiEiIUXEWEREJMXn+Qoox5jW8h6gcttb+6sTvxhiD9xCG2/GeqehBa+3qvJZbvXp126hRo5+nT506Rbly/p7fQvJL4xtcGt/g0dgGl8Y3eLKP7apVq45aay/w57H+/HzZ63iPVc3pNH7gPS6wie/SFvi379/zatSoEStXrvx5Oj4+no4dO/oRRwpC4xtcGt/g0dgGl8Y3eLKPrTEm11PXZpfnam1r7WK855zNTRe8PzdorbVLgcqmkD++LiIiEs0C8cPfdfnlSdr3+m47EIBli4hIiJo3bx5fffVV3jNGqVOnThV4rUQgirPfjDGPAI8A1KxZk/j4+J/vO3ny5C+mJbA0vsGl8Q0ejW1wFWZ8Bw4cyI4dOyhTpkxgQ4U5ay1paWnUq1evwGMbiOK8j1/+gko9322/Yq19CXgJoHXr1jbrNwpt9wgujW9waXyDR2MbXIUZ33LlynHHHXfw4YcfBjRTOPN4PGzevJmSJUuyb9++Ao9tIA6lmgf0Ml7tgOPWWq3SFhGRqGKtJTY2FmstTZo0KdSy/DmU6m2gI1DdGLMXGIP3h8Sx1r4AzMd7GNU2vIdS/alQiURERMJMeno6S5YsYdiwYVSpUqXQy8uzOFtru+dxvwUeLXQSERGRMDVu3Dh69eoVkMIMRbxDmIhIqDty5AiffPIJHo/HdZQisWXLFhISEgr02GPHjpH1ZFLR6OzZs3zwwQeMGTOGYsWKBWy5Ks4iIllMmzaNJ554wnWMsNG5c2fXEZx6/vnnufvuuwNamEHFWUTkF9LS0ihZsiTbtm1zHaVIfP/991xzzTUFfnydOnUCmCZ8nDp1ihdffJEBAwYEZfkqziIi2cTExFC/fv28Z4wACQkJUfNaA+nDDz+kR48eQVu+fpVKRETET8ePH2fo0KH06NGDWrVqBe15VJxFRET8kJaWxvLlyxk6dCjeH2QMHq3WFpGI4PF4WL9+PWlpaYVazoEDOoeS/NrRo0cZM2YMU6ZMoWTJkkF/PhVnEQl7S5cu5bHHHmPFihUBWV61atUCshyJDMeOHWPXrl1MmDChSAozqDiLSBjbt28fw4YNY+bMmdSuXZvnn3+eBg0aFHq5F154YQDSSSQ4cOAATzzxBE8//TTlypUrsudVcRaRsHPmzBkmT57M+PHjSU9PJzY2ltjYWCpUqOA6mkSQvXv3kpSUxKRJkyhbtmyRPrd2CBORsGGtZc6cOVxyySWMGDGCW265hc2bNzN+/HgVZgmoAwcO8PTTT9OkSZMiL8ygzllEwsS6devo168fCxcupEWLFnz55Zf87ne/cx1LIlBCQgIpKSlMmjSJUqVKOcmgzllEnMvIyODMmTM5XhITE3n00Udp2bIla9eu5V//+hdr1qxRYZagOHHiBP/+97+59NJLnRVmUOcsIo6lpKTQqFEjEhMTc52nWLFi/OMf/2Ds2LHak1qCZtOmTRw6dIhJkyYF/TjmvKg4i4hTycnJJCYm8oc//IE2bdr86v4dO3bwz3/+kxYtWjhIJ9EiIyODDz74gOHDhzsvzKDiLCIh4vbbb+ehhx761e3x8fEqzBJUq1evZvv27YwaNcp1lJ9pm7OIiEQtay0rVqzg7rvvdh3lF9Q5i4hIVFqyZAkbNmzgr3/9q+sov6LOWUREos6pU6dISkrikUcecR0lR+qcRUQkqnz55Zds3LiRvn37uo6SK3XOIiISNXbs2EG1atVCujCDirOIiESJTz75hAULFtCyZUvXUfKk1doiIhLxvv32W9q0acMdd9zhOopf1DmLiEhEmz9/Ptu2baNmzZquo/hNnbOIiESsOXPmcMstt1C+fHnXUfJFxVkkyp0+fZrY2Fj27dvn7PlFgmHx4sWkpaWFXWEGFWeRqPf0008zbdo0mjdv7uycwq1ataJ169ZOnlsi06uvvkrXrl3p0KGD6ygFouIsEsV2797NxIkTuffee3nnnXdcxxEJiA0bNlC9enWqVq3qOkqBaYcwkSg2dOhQwNs9i0SCqVOnUrZsWbp06eI6SqGoOItEqW+//ZbZs2czePBgGjZs6DqOSKHt2bOH5s2b85vf/MZ1lEJTcRaJQh6Ph379+lG3bt2fu2eRcGWt5amnnuLo0aPcfPPNruMEhLY5i0ShN954g1WrVjFz5kzKlSvnOo5IgVlr2bt3LzfccENYnPnLX+qcRaLMiRMniI2NpV27dvTo0cN1HJECs9YSFxfHwYMHadu2res4AaXOWSTKjB8/nkOHDjFv3jxnh06JFJbH42Hjxo307NmTxo0bu44TcOqcRaJIQkICU6ZMoVevXlx99dWu44gUiLWWkSNH4vF4IrIwgzpnkagyePBgSpQowYQJE1xHESmQjIwM4uPjGTp0KJUqVXIdJ2jUOYtEia+//pq5c+cyfPhw6tSp4zqOSIGMHz+e+vXrR3RhBnXOIkGTkJDA+vXrXcf42ahRo2jUqBEDBgxwHUUk39LS0njnnXcYOXIkMTGR31eqOIsEyR//+EdWrVrlOsbPjDHMmTOH0qVLu44ikm8vv/wynTt3jorCDCrOIkFz+vRpbrrpJiZNmuQ6CgCVK1emUaNGrmOI5Etqair/+te/GDx4sOsoRUrFWSSIqlSpwpVXXuk6hkhYstby8ccfc//997uOUuSiY/2AiIiElZSUFAYPHky3bt2icgdGFWcREQkpZ86cYdWqVQwbNixqtjFnF52vWkREQlJiYiIDBgygXbt2VK9e3XUcZ1ScRYJg1apV7N27V3tGi+TDsWPH2LVrFxMmTIj6/zsqziIB9vHHH9OhQweqVKnC8OHDXccRCQuHDh1i9OjRNG7cOOJPMOIPFWeRAJo+fTq///3vueSSS1i2bBnNmjVzHUkk5O3fv59Dhw7x9NNPU6FCBddxQoKKs0gAeDweBg0aRJ8+fejcuTOLFi2iVq1armOJhLwjR47w1FNP0aRJE/22eBY6zlmkkFJTU4mLi2Px4sX06dOH5557jmLFirmOJRLydu7cybFjx5g0aRKlSpVyHSekqHMWKYTDhw9z44038s033zBlyhSmTZumwizih9OnT/N///d/XHbZZSrMOVDnLFHvyJEjtGzZkqSkpHw/Ni0tjeLFizN27Fj69esX+HAiEWjr1q3s3LmTZ555BmOM6zghScVZot7+/fvZt28fd911F02bNs3XY2NiYvjjH//IiRMngpROJLJkZmby/vvvM3ToUBXm81BxFvF58MEH6dq1a4EeGx8fH9gwIhHohx9+YMOGDYwYMcJ1lJCnbc4iIhJ0Ho+HFStW0L17d9dRwoI6ZxERCaqlS5eyYsUK/vnPf7qOEjbUOYuISNCkpKSQlJREnz59XEcJK+qcJeodOXLEdQSRiBQfH8/KlSsZNGiQ6yhhR52zRLWFCxfSrVs3atasSdu2bV3HEYkY27Zto2rVqirMBaTiLFHrrbfeolOnTtStW5dly5ZF5Q+6iwTDp59+yvz587n88stdRwlbKs4Sday1PP744/Tq1YvrrruOJUuW0LBhQ9exRCLC4sWLadWqFY899pjrKGFNxVmiSlpaGn/+858ZM2YMvXv3ZsGCBVSuXNl1LJGI8Pnnn7N161Zq1KjhOkrY0w5hEjWSk5Pp1q0bX331FXFxcYwaNUpnKBIJkDlz5nDTTTdxyy23uI4SEVScJSrs2rWLzp07s3XrVt544w169erlOpJIxFi2bBmpqalUrFjRdZSIoeIsEW/16tV07tyZ1NRUPvvsM2688UbXkUQixowZM7j99tt1tEOAaZuzRLRPPvmEDh06ULJkSZYsWaLCLBJAP/30ExUrVqRmzZquo0QcFWeJWM8//zxdunShWbNmLFu2jEsvvdR1JJGIMX36dDIzM7n77rtdR4lIKs4ScTweD4MHD+bRRx+lc+fOLFq0iFq1armOJRIxDh48SOPGjWnWrJnrKBFLxVkiSmpqKvfeey/PPPMMffr0Ye7cuZQrV851LJGIYK3lmWeeYffu3XTq1Ml1nIimHcIkYiQnJ3P77bezdOlSJk+eTL9+/XSolEiAWGvZt28f7du35+qrr3YdJ+Kpc5aI8d577/H999/zn//8h/79+6swiwSItZYnnniCPXv20K5dO9dxooI6Z4kYaWlpANx0002Ok4hEDmst69evp0ePHlx00UWu40QNdc4iIpKrsWPHkpGRocJcxNQ5i4jIr2RmZvLll18yaNAgKlSo4DpO1FHnLCIiv/L0009Tv359FWZH1DlLWMnMzGTZsmVkZmb+6r5t27Y5SCQSWdLT05k5cyZDhw4lJkb9mysqzhJWHnzwQWbOnJnr/cWKFaN06dJFmEgksrz++uvceOONKsyOqThL2Pjuu++YOXMmf/vb3+jWrVuO89SsWVOr4UQK4MyZMzz77LMMHz5chyGGAL+KszHmVmAqUAx4xVr7VLb7GwBvAJV98wyz1s4PbFSJZh6Ph759+1KnTh0mTZpE+fLlXUcSiRjWWhYsWEDv3r1VmENEnustjDHFgOnAbUBzoLsxpnm22UYC71prWwL3Ac8HOqhEt7feeouVK1cyceJEFWaRAEpNTWXAgAHceeed1KtXz3Uc8fFno8LVwDZr7XZrbRowG+iSbR4LnPuV7UrA/sBFlGiXkpJCbGwsbdu2pUePHq7jiESM1NRUtm3bRmxsLMWLaytnKDHW2vPPYEw34FZr7V980w8Aba21fbLMUxv4HKgClANustauymFZjwCPANSsWfOq2bNn/3zfyZMn1REFUTiP78svv8ysWbOYPn06zZtnX2kTGsJ5fEOdxjY4Tp48ycsvv0zPnj254IILXMeJSNnfuzfccMMqa21rvx5srT3vBeiGdzvzuekHgH9lm2cAMNB3/RpgExBzvuVeddVVNquFCxdaCZ5wHd8PP/zQlixZ0j7wwAOuo5xXuI5vONDYBt6xY8fs2rVrbWJiosY3iLKPLbDS5lFzz138Wa29D6ifZbqe77asHgLe9RX774HSQHW/vh2I5GLq1Kl07dqVK6+8ksmTJ7uOIxIRjh49yqhRo2jUqBFVqlRxHUdy4U9xXgE0McZcaIwpiXeHr3nZ5tkN/A7AGHMJ3uJ8JJBBJXpkZmbSt29f+vXrR5cuXVi4cCHVq+u7nkhhHTx4kH379vHUU09RqVIl13HkPPIsztbaDKAP8BmwGe9e2RuNMY8bY+7yzTYQeNgY8wPwNvCgr4UXyZdTp05x9913M23aNPr168f7779P2bJlXccSCXtJSUmMGzeOxo0b61wAYcCv3fOs95jl+dluG53l+ibgt4GNJtHm0KFD3HnnnaxcuZKpU6fy2GOPuY4kEhF2797N/v37mTx5MqVKlXIdR/yg87NJSNi8eTPt2rVjw4YNzJ07V4VZJEDOnj3L1KlTadmypQpzGNGBbeLc0aNHufbaaylVqhSLFi2iTZs2riOJRISffvqJrVu38swzz+jMX2FGnbM4t2PHDpKTk3n++edVmEUCxFrL+++/z6233qrCHIbUOUvI0Co3kcDYsGEDK1euJDY21nUUKSB1ziIiEcTj8bBy5Up69erlOooUgjpnEZEIsXLlShYvXsyAAQNcR5FCUucsIhIBjh8/TmJiIv3793cdRQJAnbM48frrr/P+++8DkJyc7DaMSJj75ptvWLJkCcOGDXMdRQJExVmceOWVV/jhhx+4+OKLAejQoQOXX36541Qi4Wfr1q1UrVqVoUOHuo4iAaTiLM60bduWL7/80nUMkbD15Zdfsm7dOm1jjkAqziIiYWjx4sVcfvnl3HTTTa6jSBBohzARkTATHx/Ppk2bqFGjhusoEiTqnEVEwsjcuXPp2LEjHTt2dB1FgkjFWQLmwIEDvPDCC6Snp+c5786dO2nWrFkRpBKJHGvXruXEiRNUqVLFdRQJMhVnCZj33nuPxx9/nOLFi/t1Lt977723CFKJRIa33nqLjh070rt3b9dRpAioOEvAeDweAI4cOULlypXdhhGJILt376ZUqVLUr1/fdRQpItohTEQkhL344oskJSVpTVOUUXEWEQlRR44coUGDBlxxxRWuo0gRU3EWEQlBU6ZMYevWrdx2222uo4gD2uYsIhJCrLXs27ePa6+9lrZt27qOI46ocxYRCRHWWiZMmMCOHTtUmKOcOmcRkRBgrWXt2rV0796dCy+80HUccUyds4hICHjiiSfIyMhQYRZAnbOIiFMej4f58+czYMAAypUr5zqOhAh1ziIiDk2ePJmGDRuqMMsvqHOWQklKSuLAgQMAHDx40HEakfCRkZHBjBkzGDhwoF+nu5XoouIsBbZnzx4uv/xykpOTf74tJiaGEiVKuAslEiZmzpzJ9ddfr8IsOVJxlgIbNmwYqampvPHGG5QuXRqAunXravWcyHmcPXuWiRMnMmrUKBVmyZWKsxTId999x6xZsxgxYgS9evVyHUckLFhr+fLLL+ndu7cKs5yXdgiTfPN4PPTt25fatWszbNgw13FEwsLp06fp378/N998Mw0bNnQdR0KcOmfJt7feeouVK1fy5ptvUr58eddxREJeamoq69evZ9iwYZQsWdJ1HAkD6pwlX1JSUoiNjeXqq6/m/vvvdx1HJOSdOHGCQYMG0axZM2rVquU6joQJdc6SLxMmTODAgQPMmTOHmBh9txM5n6SkJHbv3s3jjz9OpUqVXMeRMKJPV/Hb9u3bmTx5Mj179qRdu3au44iEtMTEREaOHEnDhg2pVq2a6zgSZtQ5i98GDx5MsWLFeOqpp1xHEQlpR44cYd++fUyYMIGKFSu6jiNhSJ2z+CU+Pp45c+YQGxtL3bp1XccRCVkpKSnExcXRuHFjFWYpMHXOkqfMzEz69u1Lw4YNGThwoOs4IiFr37597Nixg8mTJ2uvbCkUdc6Sp1deeYV169YxadIkypQp4zqOSEjKyMhg6tSptG7dWoVZCk2ds/xCZmYmY8eO5ZNPPvn5tp9++okOHTrQrVs3h8lEQtf27dv54YcfePrpp11HkQih4iw/O336ND179mTu3Llcf/31Px/6cfHFFzNu3DidblAkB9ZaPvjgA/r16+c6ikQQFWcB4PDhw9x1110sX76cKVOm6INGxA+bN2/mm2++YfDgwa6jSIRRcRa2bt3KbbfdxsGDB/nggw/o2rWr60giIS8zM5NVq1bx0EMPuY4iEUjFOcp98803dOnSheLFi7Nw4ULatm3rOpJIyFuzZg2ff/45Q4cOdR1FIpT21o5ib7/9NjfddBM1atRg6dKlKswifkhKSiIpKUmrsiWo1DlHiaNHj/KPf/yDU6dOAXDy5EnmzJnD9ddfz5w5c6hatarjhCKh77vvvuPrr79m5MiRrqNIhFNxjhJTp05l2bJlvzi71yOPPMK0adMoVaqUw2Qi4WHz5s1UqVKFESNGuI4iUUDFOQp89dVXfPvtt4wfP57Y2FjXcUTCzqJFi1i+fDmDBg3SIYVSJFScI1xGRgb9+vWjdu3a9O/f33UckbCzaNEimjVrxvXXX+86ikQR7RAW4V5++WU2bNjA3/72N0qXLu06jkhY+e6771i/fj01a9Z0HUWijDrnCJaUlMSoUaPo2LEj1113nes4ImHlo48+4tprr+Xaa691HUWikDrnCBYXF0dSUhLPPfectpOJ5MOmTZs4evQoF1xwgesoEqVUnCPUli1bmD59Og8//DBXXHGF6zgiYeM///kPpUqV0pm/xCkV5wg1YMAAypUrx7hx41xHEQkbBw8eJCYmhosuush1FIlyKs4RaP78+SxYsIDRo0drtZyIn1555RX27NlD9+7dXUcRUXGONGlpaQwYMICmTZvSp08f13FEwkJiYiK1a9emTZs2rqOIANpbO+JMnz6drVu38sknn1CyZEnXcURC3rRp07jsssvo3Lmz6ygiP1NxDgNr1qzh6NGjec6Xnp5OXFwcnTp14vbbby+CZCLhbe/evbRt21Y/+iIhR8U5xB04cIBWrVr5PX/JkiWZPHmyDp0SycNTTz1F27ZtueGGG1xHEfkVFecQd/r0aQBGjhzJrbfemuf8DRo0oH79+sGOJRK2rLWsWrWKHj160KBBA9dxRHKk4hwmmjZtym9/+1vXMUTC3sSJE7n++utVmCWkqTiLSFTweDx8/PHH9O3blzJlyriOI3JeOpRKRKLC9OnTadiwoQqzhAV1ziHixIkTpKam/up2f/bSFpHcZWZm8vLLL9OnTx/tKClhQ8U5BHz55ZfccccdnD17Ntd5dMyySMG88847dOzYUYVZwoqKs2Pp6en885//pF69egwcODDHeUqVKsUdd9xRxMlEwltaWhrjx49n9OjRxMRoC56EFxVnx/7973+zZcsW5s2bx5133uk6jkhE8Hg8LFq0iN69e6swS1jSu9aho0ePMmbMGG6++WZ1xiIBkpqaSv/+/Wnfvj0XXnih6zgiBaLO2aExY8aQkpLClClTtD1MJABOnz7N5s2bGTJkiPbKlrCmztmR9evX88ILL/D3v/+dSy+91HUckbCXkpLC4MGDadSoEXXr1nUdR6RQ1Dk7MmrUKCpXrkxcXJzrKCJh7/jx4+zcuZOxY8dSrVo113FECk2dsyM7d+6kffv2VK1a1XUUkbCWnJxMbGws9evX54ILLnAdRyQg1Dk7pO3MIoVz9OhRdu/ezYQJE6hUqZLrOCIBo85ZRMJSamoqY8eOpUmTJirMEnHUOYtI2Dlw4ACbN29mypQplChRwnUckYBT5ywiYcXj8fDcc8/Rrl07FWaJWOqcHcnMzHQdQSTs7Ny5k6VLlzJx4kTXUUSCyq/O2RhzqzFmqzFmmzFmWC7z3GuM2WSM2WiMmRXYmJFl6dKlbNiwgSuuuMJ1FJGwMmfOHP7whz+4jiESdHl2zsaYYsB04GZgL7DCGDPPWrspyzxNgFjgt9baJGNMjWAFDncej4d+/fpRq1YtBg0a5DqOSFjYunUrX3zxBQMGDHAdRaRI+LNa+2pgm7V2O4AxZjbQBdiUZZ6HgenW2iQAa+3hQAeNFLNmzWLZsmXMmDGDChUquI4jEvIyMzNZvXo1f/vb31xHESky/qzWrgvsyTK913dbVk2BpsaYJcaYpcaYWwMVMJKcPHmSoUOH0rp1a3r16uU6jkjIW7duHbNmzaJ79+4UL65dZCR6BOrdXhxoAnQE6gGLjTGXWWuTs85kjHkEeASgZs2axMfH/3zfyZMnfzEdiV577TX279/PsGHDWLx4cZE+dzSMr0sa38A7fvw4O3bsoEuXLhrbINJ7N3gKNbbW2vNegGuAz7JMxwKx2eZ5AfhTlumvgDbnW+5VV11ls1q4cKGNZLt27bKlSpWy3bt3d/L8kT6+rml8A2vZsmV29OjR1lqNbbBpfIMn+9gCK20eNffcxZ/V2iuAJsaYC40xJYH7gHnZ5vkQb9eMMaY63tXc2wv2dSEyLVq0iLNnzzJsWI47u4uIz8aNG6lUqRJjx451HUXEmTyLs7U2A+gDfAZsBt611m40xjxujLnLN9tnwDFjzCZgITDYWnssWKHDkfdLE5QvX95xEpHQtWTJEubNm0fTpk117nmJan5tc7bWzgfmZ7ttdJbrFhjgu4iI5NvixYtp2rQp1157rQqzRD2dvlNEnFu5ciWrV6+mVq1aKswiqDiLiGMff/wxderUoV+/fq6jiIQMFWcRcSYhIYEDBw5Qp04d11FEQoqKs4g48c4773D27FkeeeQR11FEQo6Ks4gUuWPHjpGRkUHz5s1dRxEJSTofnogUqddff53GjRtz//33u44iErLUOYtIkTl+/DgXXHAB7du3dx1FJKSpcxaRIvH888/TuHFjOnfu7DqKSMhTcRaRoNuzZw9t2rShTZs2rqOIhAWt1haRoHr22WfZsmWLCrNIPqhzFpGgsNayfPly7rvvPurWzf4T8CJyPuqcRSQoJk+eTEZGhgqzSAGocxaRgLLWMnfuXB599FFKly7tOo5IWFLnLCIB9dJLL9GwYUMVZpFCUOcsIgGRmZnJ888/T58+ffTLUiKFpM5ZRAJizpw53HjjjSrMIgGg4iwihZKens6oUaPo2rUrl156qes4IhFBxVlECszj8bBkyRJ69+5N8eLaSiYSKCrOIlIgZ86coX///lx11VU0btzYdRyRiKKvuiKSb6mpqWzdupVBgwZRoUIF13FEIo46ZxHJl1OnTjF48GDq1KlD/fr1XccRiUjqnIPE4/Hw5z//meXLlwOQnJzsNpBIAKSkpLBjxw5GjRpFjRo1XMcRiVgqzkHy+uuv88Ybb9CpUycqVqwIQI0aNWjYsKHjZCIFk5KSwrBhw4iLi6N69equ44hENBXnIDhx4gSxsbFce+21LFiwQMd9SthLTExk+/btjB8/nkqVKrmOIxLxtM05CJ588kkOHz7Mc889p8IsYS8tLY3Ro0fTpEkTFWaRIqLOOcC2bdvGlClT6N27t36/VsLeoUOHWLt2Lc8995yOYxYpQuqcA2zQoEGUKlWKCRMmuI4iUijWWqZNm0b79u1VmEWKmP7HBdDXX3/NRx99xPjx46ldu7brOCIFtmfPHuLj43nyySddRxGJSuqcA2jGjBlUq1aN/v37u44iUigffvgh99xzj+sYIlFLnXOAZGZm8umnn3Lrrbfqd2wlbCUkJDBv3jx9wRRxTJ1zgKxcuZKjR49y++23u44iUiDp6emsXr2aPn36uI4iEvXUOQfIueOZO3Xq5DqKSL5t3LiRd999l7i4ONdRRAR1zgEzf/582rVrR7Vq1VxHEcmXw4cPk5yczOjRo11HEREfFecAOHz4MCtWrOC2225zHUUkX1atWsW0adO49tprKVasmOs4IuKj4hwAn332GYC2N0tY2bBhAxUqVGDcuHE6k51IiFFxDoD58+dTs2ZNWrZs6TqKiF+WL1/Ohx9+SJMmTVSYRUKQinMhZWRk8Nlnn3HrrbcSE6PhlND3zTffUK9ePUaMGKHCLBKiVE0KadmyZSQlJWmVtoSFdevWsXz5curUqaPCLBLCVJwLacGCBRQrVoybb77ZdRSR85o/fz6VKlVi4MCBrqOISB5UnAtp/vz5XHvttVSpUsV1FJFc7dmzh507d9KwYUPXUUTEDyrOhXDmzBnWrFnDDTfc4DqKSK7ef/99jh07xj/+8Q/XUUTETyrOhZCZmQlA+fLlHScRydnx48dJTU3lyiuvdB1FRPJBp+8UiVBvvfUWdevW5YEHHnAdRUTySZ2zSAQ6ceIE1apV48Ybb3QdRUQKQJ2zSIR58cUXqVevHp07d3YdRUQKSMVZJILs2rWL1q1bc9VVV7mOIiKFoNXahXDgwAEAihfXdxxxb+rUqWzatEmFWSQCqKoUwvDhwylTpgzdunVzHUWimLWW7777jnvvvZfatWu7jiMiAaDOuYAWL17Me++9x7Bhw6hfv77rOBLFpk2bRkZGhgqzSARR51wAmZmZ9O3bl/r16zNo0CDXcSRKWWt57733+Nvf/kapUqVcxxGRAFJxLoAZM2awdu1aZs+eTdmyZV3HkSg1Y8YMLr30UhVmkQik4pxPx48fZ8SIEbRv3557773XdRyJQh6Ph2nTptG3b1/9spRIhFJxzsGoUaOYNm1ajvelp6dz5swZ5s+frw9GceKTTz7hxhtv1PtPJIKpOOdgxYoVlClThu7du+d4/zXXXKPDVaTIZWRkEBcXx8iRI7UqWyTCqTjnolGjRkyZMsV1DBHAuxPi8uXLeeCBB1SYRaKADqUSCXFpaWkMGjSISy65hKZNm7qOIyJFQJ2zSAg7c+YMP/74I/369aNKlSqu44hIEVHnLBKiTp8+zeDBg7ngggto2LCh6zgiUoTUOYuEoFOnTpGQkMDw4cN15i+RKKTOWSTEnDp1iiFDhlCrVi0VZpEopc5ZJIQkJyezdetWxo8fT6VKlVzHERFH1DmLhIiMjAxGjx5N06ZNVZhFopw6Z5EQcOTIEZYtW8aUKVMoVqyY6zgi4pg6ZxHHrLX861//omPHjirMIgKocxZxat++fXz22WfExcW5jiIiIUSds4gj1lrmzZuX6zncRSR6qXMWcWDHjh288847DBs2zHUUEQlB6pxFitjZs2dZu3YtAwYMcB1FREKUirNIEdq8eTNxcXF07dqVkiVLuo4jIiFKxVmkiBw8eJDjx48zbtw411FEJMSpOIsUgbVr1zJ16lSuvvpqHS4lInlScRYJsg0bNlCuXDmefPJJYmL0X05E8qZPCpEgWr16Ne+//z6NGzdWYRYRv+nTQiRIlixZQvXq1RkzZgzGGNdxRCSMqDiLBMGWLVv49ttvqV+/vgqziOSbirNIgH3++efExMQwdOhQFWYRKRC/irMx5lZjzFZjzDZjTK6nNDLG3G2MscaY1oGLKBI+Dh06xJYtW2jatKnrKCISxvIszsaYYsB04DagOdDdGNM8h/kqAH2BZYEOKRIOPvzwQ3bu3Mljjz3mOoqIhDl/OuergW3W2u3W2jRgNtAlh/nGAROBMwHMJxIWUlNTOXHiBG3btnUdRUQigD/FuS6wJ8v0Xt9tPzPGtALqW2v/G8BsImHh7bffZv369fTq1ct1FBGJEIX+VSpjTAwwGXjQj3kfAR4BqFmzJvHx8T/fd/LkyV9Mu5SYmBhSeQIh0l5PqDh16hS7du2iRYsWGt8g0Xs3uDS+wVOYsfWnOO8D6meZrue77ZwKQAsg3rdnai1gnjHmLmvtyqwLsta+BLwE0Lp1a9uxY8ef74uPjyfrtEtVq1YlJiYmZPIEQiiNb6R47bXXqFq1KsOGDdP4BpHGNrg0vsFTmLH1pzivAJoYYy7EW5TvA3qcu9Naexyofm7aGBMPDMpemF3IzMwkNTU134/LyMgIQhqJJNu3b6dVq1ZceeWVrqOISATKszhbazOMMX2Az4BiwGvW2o3GmMeBldbaecEOWRApKSlcffXVbNmypUCP/+1vfxvgRBIppk+fToMGDbjzzjtdRxGRCOXXNmdr7XxgfrbbRucyb8fCxyq88ePHs2XLFkaPHk2FChXy/fgOHToEIZWEu2+++YZ77rmHGjVquI4iIhGs0DuEhaKEhAQmT55Mr169iIuLcx1HIsS///1vLr74YhVmEQm6iCzOgwcPpkSJEkyYMMF1FIkA1lpmz57NX/7yF0qUKOE6johEgYg7t/bChQuZO3cusbGx1KlTx3UciQCzZs2iUaNGKswiUmQiqnPOyMigX79+NGrUiAEDBriOI2HO4/Hw3HPP0bdvX4oVK+Y6johEkYgqzrNmzWLdunW89957lClTxnUcCXOff/45N9xwgwqziBS5iFqtvW3bNgDuvvtux0kknGVmZjJy5Eg6dOhAy5YtXccRkSgUUcUZwBij39CVAsvMzGT16tXcf//9lC1b1nUcEYlSEVecRQoqPT2dwYMH07BhQy655BLXcUQkikXUNmeRgjp79iw//fQTffr00XHMIuKcOmeJemfOnGHw4MFUrlyZ3/zmN67jiIhEVudsrXUdQcLM6dOn2bZtG8OGDdNx8SISMiKqcz5w4ABVq1Z1HUPCxJkzZxgyZAg1atRQYRaRkBJRnfOaNWt06Iv45cSJE6xfv57x48dTsWJF13FERH4hYjrn9PR0NmzYoOIsefJ4PIwaNYpmzZqpMItISIqYznnTpk2kpaWpOMt5HTt2jMWLFzNlyhRiYiLmu6mIRJiI+XRavXo1gIqznNfzzz/P7373OxVmEQlpEdM5r1mzhnLlytGkSRPXUSQEHTx4kI8++ohRo0a5jiIikqeIaR/WrFnDFVdcoR8pkF+x1vLxxx/zwAMPuI4iIuKXiCjOHo+HtWvXapW2/MquXbt44oknePjhh3WubBEJGxFRnBMSEjh58qSKs/zCmTNnWLduHUOGDHEdRUQkXyKiOK9ZswbQzmDyPz/++COjR4/mjjvuoFSpUq7jiIjkS8QU5+LFi3PppZe6jiIhYP/+/Rw/fpzx48fr50NFJCxFTHFu0aKFOiRh/fr1TJ06lVatWlG8eMQcjCAiUSbsi7O1ltWrV2uVtrBhwwZKly7NhAkTtNe+iIS1sC/O+/fv58iRIyrOUW7Dhg28++67XHTRRTrBiIiEvbD/FNPOYPL9999Trlw54uLiVJhFJCKE/SfZmjVrMMZwxRVXuI4iDmzfvp2FCxfSqFEj7fwlIhEjIopz48aNqVChgusoUsS++uorTp8+TWxsrAqziESUiCjOrVq1ch1DilhiYiIbNmygRYsWKswiEnHCujifOnWKnTt3cvnll7uOIkXok08+YePGjfTt29d1FBGRoAjr4pyWlgZAuXLlHCeRonLmzBkSExO57rrrXEcREQkanaVBwsa7775L6dKl6dWrl+soIiJBpeIsYeHEiRNUrFiRW2+91XUUEZGgU3GWkPfGG29QtmxZ7rnnHtdRRESKhIqzhLSffvqJVq1acdlll7mOIiJSZEK+OB85coTLLruMpKSkX91nrQXQWaEi1IsvvkitWrXo0qWL6ygiIkUq5Ivz/v37OXToEF27duXiiy/+1f0lSpSgW7duDpJJMC1cuJC7776b6tWru44iIlLkQr44n/PAAw/QtWtX1zGkCLzyyis0aNBAhVlEolbYFGeJfNZaZs6cyYMPPqjfYhaRqKaNtRIy3n//fRo1aqTCLCJRT5+C4py1lsmTJ/PYY49RokQJ13FERJxT5yzOLVy4kOuvv16FWUTER8VZnPF4PIwcOZLWrVvTunVr13FEREKGVmuLE5mZmaxfv5777ruPihUruo4jIhJS1DlLkUtPT2fo0KFccMEFtGjRwnUcEZGQo85ZilRaWhrbtm3jr3/9K3Xr1nUdR0QkJKlzliJz9uxZhgwZQtmyZWnSpInrOCIiIUudsxSJ1NRUfvzxRwYPHqyOWUQkD+qcJejS09MZPHgw1atXV2EWEfGDOmcJqpSUFFavXs2ECROoUKGC6zgiImFBnbMEjbWWsWPH0rx5cxVmEZF8UOcsQZGUlMQXX3zBpEmT9HvbIiL5pE9NCYqXXnqJW265RYVZRKQA1DlLQB0+fJh3332XoUOHuo4iIhK2Qr6tWbJkCQDVqlVznETyYq3lv//9L3/6059cRxERCWsh3TknJSUxevRorr/+eq677jrXceQ89u7dy0svvcTjjz/uOoqISNgL6c45Li6OxMREnnvuOYwxruNILlJTU9mwYQPDhw93HUVEJCKEbHHesmUL06dP5+GHH+bKK690HUdykZCQwIgRI+jUqROlS5d2HUdEJCKEbHEeMGAAZcuWZdy4ca6jSC727t3L8ePHmThxotZsiIgEUEgW5/nz57NgwQLGjBlDjRo1XMeRHGzevJlp06Zx+eWXU6JECddxREQiSsgV57S0NAYMGEDTpk3p06eP6ziSg40bN1K8eHEmTJhA8eIhvU+hiEhYCrniPH36dLZu3cqzzz5LyZIlXceRbLZs2cKsWbO46KKLKFasmOs4IiIRKaSK85EjR4iLi6NTp0507tzZdRzJZvny5RQrVownnnhCZ/4SEQmikPqEHTVqFCdPnmTy5MnawSjE7N27l08//ZTGjRvrbyMiEmQhs8EwISGBl19+mT59+tC8eXPXcSSLRYsWUaFCBUaNGqXCLCJSBEKic7bWMn36dCpXrsyYMWNcx5EsUlJSWLNmDS1btlRhFhEpIiHROX///fesWbOG//u//6Nq1aqu44jPggULKFGiBP369XMdRUQkqoRE55yYmAhAu3btHCeRc9LS0jhy5Ag33XST6ygiIlEnJDpnCS1z5szB4/HQq1cv11FERKKSirP8wvHjxylfvjy33HKL6ygiIlFLxVl+NnPmTGJiYujRo4frKCIiUU3FWQDvmb9atWqlw9hEREJASOwQJm69+uqrbNy4UYVZRCREqHOOcl999RVdu3bVIWwiIiFEnXMUe/PNNzl79qwKs4hIiFHnHKXefPNNevTooZ98FBEJQeqco9C8efNo0KCBCrOISIjyqzgbY241xmw1xmwzxgzL4f4BxphNxph1xpivjDENAx9VCstay7PPPkunTp3o2LGj6zgiIpKLPIuzMaYYMB24DWgOdDfGZN+tdw3Q2lp7OfA+8HSgg0rhLVmyhPbt21OqVCnXUURE5Dz86ZyvBrZZa7dba9OA2UCXrDNYaxdaa0/7JpcC9QIbUwrD4/Hw2muvcckll9C2bVvXcUREJA/+bHSsC+zJMr0XON8n/EPAgpzuMMY8AjwCULNmTeLj4wFYv349AKtWreLkyZN+RBJ/ZWZmsnv3btq0afPzOEvgnTx58uf3swSWxja4NL7BU5ixDegeQcaYnkBr4Pqc7rfWvgS8BNC6dWt7brvnuYJ81VVX0bp160BGimoZGRkMHz6cRx99lB07dmg7cxDFx8drfINEYxtcGt/gKczY+rNaex9QP8t0Pd9tv2CMuQkYAdxlrT1boDQSMOnp6Wzbto2HHnqIhg21f56ISDjxpzivAJoYYy40xpQE7gPmZZ3BGNMSeBFvYT4c+JiSH2lpaQwZMoQSJUpw8cUXu44jIiL5lOdqbWtthjGmD/AZUAx4zVq70RjzOLDSWjsPmASUB94zxgDsttbeFcTckoszZ86wZcsWBg0aRN26dV3HERGRAvBrm7O1dj4wP9tto7NcvynAuaQAMjMzGTJkCIMHD1ZhFhEJYzpFVIQ4deoUS5cuZcKECZQrV851HBERKQSdvjNCPP7447Ro0UKFWUQkAqhzDnPJycn897//5amnnsK3vV9ERMKcOucw9+qrr3LbbbepMIuIRBB1zmHq6NGjvPnmmwwcONB1FBERCTB1zmHIWsunn37Kww8/7DqKiIgEgYpzmNm/fz/Dhw+nZ8+eVKhQwXUcEREJAhXnMHLq1Ck2bdrE6NGj855ZRETClopzmNi5cyfDhw/nxhtvpEyZMq7jiIhIEKk4h4G9e/eSnJzMpEmTiInRn0xEJNLpkz7E/fjjj0yZMoVLL72UkiVLuo4jIiJFQMU5hG3atAmAiRMnUqJECcdpRESkqKg4h6iEhATefPNNLrroIooX1+HoIiLRRMU5BK1atYqzZ88yfvx4ihUr5jqOiIgUMRXnEHP48GE+/vhjLrnkEu38JSISpbS+NIR8++23FC9enLFjx7qOIiIiDqk1CxGpqamsWLGCtm3buo4iIiKOqXMOAV988QVpaWn079/fdRQREQkB6pwdS09P59ChQ3Tu3Nl1FBERCRHqnB2aN28eJ0+epGfPnq6jiIhICFFxdiQpKYly5cpx1113uY4iIiIhRsXZgdmzZ5OWlkavXr1cRxERkRCk4lzENm7cSMuWLbn44otdRxERkRClHcKK0JtvvsnGjRtVmEVE5LzUOReRzz//nC5dulCpUiXXUUREJMSpcy4Cs2fP5uzZsyrMIiLiF3XOQfb6669z//336ycfRUTEb+qcg+jTTz+lXr16KswiIpIv6pyDwFrLs88+y9///nfKlSvnOo6IiIQZdc4BZq1lxYoVXHPNNSrMIiJSICrOAeTxeBgzZgwNGjTgt7/9res4IiISplScA8Tj8fDjjz/y+9//nlq1armOIyIiYUzFOQAyMzOJjY2lePHitGrVynUcEREJc9ohrJAyMjJISEjgT3/6E40bN3YdR0REIoA650JIT09nyJAhGGNo1qyZ6zgiIhIh1DkX0NmzZ9m4cSMDBw6kbt26ruOIiEgEUedcAB6Ph6FDh1KtWjUVZhERCTh1zvl0+vRpFi9ezIQJEyhTpozrOCIiEoHUOefTk08+yRVXXKHCLCIiQaPO2U8nTpxg7ty5PPHEExhjXMcREZEIps7ZTzNmzKBz584qzCIiEnTqnPOQmJjIK6+8wpAhQ1xHERGRKKHO+Tw8Hg9ffPEFf/3rX11HERGRKKLinIuDBw8ydOhQ7r33XipVquQ6joiIRBEV5xykpKSwZcsWxo4dq23MIiJS5FScs9m9ezfDhw+nffv2+j1mERFxQsU5iz179pCcnMwzzzxD8eLaV05ERNxQcfZJSEhgypQpNGvWjFKlSrmOIyIiUUztIbBlyxYAJk6cSIkSJRynERGRaBf1nfPu3buZMWMGTZo0UWEWEZGQENWd89q1a4mJiWHChAnExET99xQREQkRUVuRkpOTmTt3Li1atFBhFhGRkBKVnfPSpUtJS0sjLi7OdRQREZFfibqWMS0tje+//57rrrvOdRQREZEcRVXn/PXXX5OcnEz//v1dRxEREclV1HTO6enpHDhwgD/84Q+uo4iIiJxXVHTO//3vfzly5AgPPvig6ygiIiJ5ivjifPToUcqVK0fnzp1dRxEREfFLRBfn9957j5SUFP785z+7jiIiIuK3iC3O69ato2XLljRu3Nh1FBERkXyJyB3C3n77bdavX6/CLCIiYSniOucFCxbQuXNnKlas6DqKiIhIgURUcf7ggw+IiYlRYRYRkbAWMcX59ddfp3v37votZhERCXsRsc3566+/platWirMIiISEcK6c7bWMnnyZP7yl79QqVIl13FEREQCImw7Z2st69ato02bNirMIiISUcKyOFtrGTduHFWqVKFDhw6u44iIiARU2K3W9ng8bN++ndtuu40GDRq4jiMiIhJwYdU5ezweRo4cSXp6Om3atHEdR0REJCjCpnPOzMwkISGBnj17cskll7iOIyIiEjRh0TlnZGQwdOhQMjMzad68ues4IiIiQRXynXN6ejo//PADAwcOpHbt2q7jiIiIBF1Id87WWoYNG0bVqlVVmEVEJGqEbOd85swZvvzyS5588klKly7tOo6IiEiRCdnO+emnn6Zly5YqzCIiEnX8Ks7GmFuNMVuNMduMMcNyuL+UMeYd3/3LjDGNChro5MmTvPrqq4waNYq6desWdDEiIiJhK8/ibIwpBkwHbgOaA92NMdl3mX4ISLLWNgamABMLGuitt97irrvuwhhT0EWIiIiENX8656uBbdba7dbaNGA20CXbPF2AN3zX3wd+ZwpQXV977TX+/ve/c8EFF+T3oSIiIhHDn+JcF9iTZXqv77Yc57HWZgDHgWr5DXPPPffk9yEiIiIRp0j31jbGPAI8AlCzZk3i4+MB77HMY8aM4dSpUz/fJoF18uRJjW0QaXyDR2MbXBrf4CnM2PpTnPcB9bNM1/PdltM8e40xxYFKwLHsC7LWvgS8BNC6dWvbsWPHn++rUqUKWaclsOLj4zW+QaTxDR6NbXBpfIOnMGPrz2rtFUATY8yFxpiSwH3AvGzzzAN6+653A7621toCJRIREYlyeXbO1toMY0wf4DOgGPCatXajMeZxYKW1dh7wKvCWMWYbkIi3gIuIiEgBGFcNrjHmCLAry03VgaNOwkQHjW9waXyDR2MbXBrf4Mk+tg2ttX4djuSsOGdnjFlprW3tOkek0vgGl8Y3eDS2waXxDZ7CjG3Inr5TREQkWqk4i4iIhJhQKs4vuQ4Q4TS+waXxDR6NbXBpfIOnwGMbMtucRURExCuUOmcRERHBQXEuyp+fjEZ+jO8AY8wmY8w6Y8xXxpiGLnKGo7zGNst8dxtjrDFGe8Dmgz/ja4y51/f+3WiMmVXUGcOVH58LDYwxC40xa3yfDbe7yBmOjDGvGWMOG2M25HK/McZM8439OmNMK78WbK0tsgvek5gkAL8BSgI/AM2zzfMP4AXf9fuAd4oyYzhf/BzfG4Cyvut/1/gGbmx981UAFgNLgdauc4fLxc/3bhNgDVDFN13Dde5wuPg5ti8Bf/ddbw7sdJ07XC5AB6AVsCGX+28HFgAGaAcs82e5Rd05F9nPT0apPMfXWrvQWnvaN7kU77nSJW/+vHcBxuH9PfMzRRkuAvgzvg8D0621SQDW2sNFnDFc+TO2Fqjou14J2F+E+cKatXYx3jNj5qYL8Kb1WgpUNsbUzmu5RV2ci+znJ6OUP+Ob1UN4v9FJ3vIcW9/qqvrW2v8WZbAI4c97tynQ1BizxBiz1Bhza5GlC2/+jO1YoKcxZi8wH/hn0USLCvn9XAaK+CcjJXQYY3oCrYHrXWeJBMaYGGAy8KDjKJGsON5V2x3xrvFZbIy5zFqb7DJUhOgOvG6tfdYYcw3e30poYa31uA4WrYq6c87Pz09yvp+flBz5M74YY24CRgB3WWvPFlG2cJfX2FYAWgDxxpideLctzdNOYX7z5727F5hnrU231u4AfsRbrOX8/Bnbh4B3Aay13wOl8Z4XWgrPr8/l7Iq6OOvnJ4Mrz/E1xrQEXsRbmLXNzn/nHVtr7XFrbXVrbSNrbSO82/PvstaudBM37Pjz2fAh3q4ZY0x1vKu5txdhxnDlz9juBn4HYIy5BG9xPlKkKSPXPKCXb6/tdsBxa+2BvB5UpKu1rX5+Mqj8HN9JQHngPd9+druttXc5Cx0m/BxbKSA/x/cz4BZjzCYgExhsrdVatTz4ObYDgZeNMf3x7hz2oJoi/xhj3sb7pbG6b5v9GKAEgLX2Bbzb8G8HtgGngT/5tVyNv4iISGjRGcJERERCjIqziIhIiFFxFhERCTEqziIiIiFGxVlERCTEqDiLiIiEGBVnERGREKPiLCIiEmL+H+WiKFFD/IgNAAAAAElFTkSuQmCC"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential([\n",
    "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 12)                108       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 1s 15ms/step - loss: 0.8034 - accuracy: 0.4722 - val_loss: 0.7793 - val_accuracy: 0.4896\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7908 - accuracy: 0.4774 - val_loss: 0.7685 - val_accuracy: 0.5052\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.7790 - accuracy: 0.4844 - val_loss: 0.7584 - val_accuracy: 0.5156\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7679 - accuracy: 0.4931 - val_loss: 0.7490 - val_accuracy: 0.5260\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7576 - accuracy: 0.5087 - val_loss: 0.7402 - val_accuracy: 0.5312\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.7479 - accuracy: 0.5260 - val_loss: 0.7320 - val_accuracy: 0.5365\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7388 - accuracy: 0.5365 - val_loss: 0.7243 - val_accuracy: 0.5417\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7303 - accuracy: 0.5417 - val_loss: 0.7172 - val_accuracy: 0.5521\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.7222 - accuracy: 0.5503 - val_loss: 0.7104 - val_accuracy: 0.5521\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7146 - accuracy: 0.5556 - val_loss: 0.7040 - val_accuracy: 0.5573\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7075 - accuracy: 0.5694 - val_loss: 0.6980 - val_accuracy: 0.5469\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7008 - accuracy: 0.5781 - val_loss: 0.6923 - val_accuracy: 0.5573\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6944 - accuracy: 0.5816 - val_loss: 0.6869 - val_accuracy: 0.5573\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6884 - accuracy: 0.5868 - val_loss: 0.6818 - val_accuracy: 0.5573\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6827 - accuracy: 0.5955 - val_loss: 0.6769 - val_accuracy: 0.5625\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6773 - accuracy: 0.6024 - val_loss: 0.6723 - val_accuracy: 0.5625\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6722 - accuracy: 0.6128 - val_loss: 0.6679 - val_accuracy: 0.5677\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6673 - accuracy: 0.6163 - val_loss: 0.6636 - val_accuracy: 0.5729\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6626 - accuracy: 0.6181 - val_loss: 0.6596 - val_accuracy: 0.5833\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6582 - accuracy: 0.6215 - val_loss: 0.6558 - val_accuracy: 0.5885\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6539 - accuracy: 0.6250 - val_loss: 0.6521 - val_accuracy: 0.5833\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6498 - accuracy: 0.6302 - val_loss: 0.6486 - val_accuracy: 0.5833\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6459 - accuracy: 0.6302 - val_loss: 0.6453 - val_accuracy: 0.5885\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6421 - accuracy: 0.6302 - val_loss: 0.6421 - val_accuracy: 0.5938\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6385 - accuracy: 0.6319 - val_loss: 0.6389 - val_accuracy: 0.6146\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6350 - accuracy: 0.6354 - val_loss: 0.6359 - val_accuracy: 0.6146\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6317 - accuracy: 0.6406 - val_loss: 0.6331 - val_accuracy: 0.6146\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6285 - accuracy: 0.6424 - val_loss: 0.6303 - val_accuracy: 0.6146\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6253 - accuracy: 0.6493 - val_loss: 0.6276 - val_accuracy: 0.6146\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6224 - accuracy: 0.6493 - val_loss: 0.6250 - val_accuracy: 0.6198\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6195 - accuracy: 0.6493 - val_loss: 0.6225 - val_accuracy: 0.6198\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6167 - accuracy: 0.6528 - val_loss: 0.6201 - val_accuracy: 0.6198\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6140 - accuracy: 0.6580 - val_loss: 0.6178 - val_accuracy: 0.6198\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6114 - accuracy: 0.6649 - val_loss: 0.6155 - val_accuracy: 0.6250\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6088 - accuracy: 0.6667 - val_loss: 0.6133 - val_accuracy: 0.6250\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6064 - accuracy: 0.6701 - val_loss: 0.6111 - val_accuracy: 0.6250\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6040 - accuracy: 0.6719 - val_loss: 0.6091 - val_accuracy: 0.6302\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6017 - accuracy: 0.6736 - val_loss: 0.6071 - val_accuracy: 0.6302\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5995 - accuracy: 0.6736 - val_loss: 0.6052 - val_accuracy: 0.6354\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5973 - accuracy: 0.6736 - val_loss: 0.6033 - val_accuracy: 0.6406\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5951 - accuracy: 0.6736 - val_loss: 0.6015 - val_accuracy: 0.6562\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5930 - accuracy: 0.6788 - val_loss: 0.5997 - val_accuracy: 0.6667\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.6806 - val_loss: 0.5980 - val_accuracy: 0.6615\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5891 - accuracy: 0.6788 - val_loss: 0.5963 - val_accuracy: 0.6667\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5871 - accuracy: 0.6823 - val_loss: 0.5947 - val_accuracy: 0.6719\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5853 - accuracy: 0.6806 - val_loss: 0.5931 - val_accuracy: 0.6719\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5834 - accuracy: 0.6806 - val_loss: 0.5916 - val_accuracy: 0.6719\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5817 - accuracy: 0.6840 - val_loss: 0.5901 - val_accuracy: 0.6719\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5799 - accuracy: 0.6875 - val_loss: 0.5886 - val_accuracy: 0.6771\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5782 - accuracy: 0.6875 - val_loss: 0.5872 - val_accuracy: 0.6823\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5765 - accuracy: 0.6875 - val_loss: 0.5858 - val_accuracy: 0.6823\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5749 - accuracy: 0.6858 - val_loss: 0.5845 - val_accuracy: 0.6771\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5733 - accuracy: 0.6875 - val_loss: 0.5832 - val_accuracy: 0.6771\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5718 - accuracy: 0.6892 - val_loss: 0.5819 - val_accuracy: 0.6823\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5703 - accuracy: 0.6892 - val_loss: 0.5806 - val_accuracy: 0.6823\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5687 - accuracy: 0.6875 - val_loss: 0.5794 - val_accuracy: 0.6823\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5673 - accuracy: 0.6927 - val_loss: 0.5782 - val_accuracy: 0.6823\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5659 - accuracy: 0.6944 - val_loss: 0.5771 - val_accuracy: 0.6823\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5645 - accuracy: 0.6979 - val_loss: 0.5759 - val_accuracy: 0.6823\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5632 - accuracy: 0.6962 - val_loss: 0.5748 - val_accuracy: 0.6823\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5618 - accuracy: 0.6997 - val_loss: 0.5737 - val_accuracy: 0.6823\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5606 - accuracy: 0.6979 - val_loss: 0.5727 - val_accuracy: 0.6927\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5593 - accuracy: 0.6997 - val_loss: 0.5716 - val_accuracy: 0.6927\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5581 - accuracy: 0.6979 - val_loss: 0.5706 - val_accuracy: 0.6927\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5568 - accuracy: 0.6962 - val_loss: 0.5696 - val_accuracy: 0.6927\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5556 - accuracy: 0.6962 - val_loss: 0.5687 - val_accuracy: 0.6927\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5544 - accuracy: 0.6962 - val_loss: 0.5677 - val_accuracy: 0.6979\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5533 - accuracy: 0.6962 - val_loss: 0.5668 - val_accuracy: 0.6979\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5522 - accuracy: 0.6997 - val_loss: 0.5659 - val_accuracy: 0.6979\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5510 - accuracy: 0.6997 - val_loss: 0.5650 - val_accuracy: 0.6979\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5499 - accuracy: 0.6997 - val_loss: 0.5642 - val_accuracy: 0.6979\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5489 - accuracy: 0.6962 - val_loss: 0.5633 - val_accuracy: 0.7031\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5478 - accuracy: 0.7014 - val_loss: 0.5625 - val_accuracy: 0.7031\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5468 - accuracy: 0.6997 - val_loss: 0.5617 - val_accuracy: 0.7031\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5457 - accuracy: 0.7031 - val_loss: 0.5609 - val_accuracy: 0.7031\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5447 - accuracy: 0.7066 - val_loss: 0.5601 - val_accuracy: 0.7083\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5438 - accuracy: 0.7066 - val_loss: 0.5594 - val_accuracy: 0.7083\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5428 - accuracy: 0.7066 - val_loss: 0.5586 - val_accuracy: 0.7083\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5419 - accuracy: 0.7101 - val_loss: 0.5579 - val_accuracy: 0.7083\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5409 - accuracy: 0.7118 - val_loss: 0.5572 - val_accuracy: 0.7083\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5400 - accuracy: 0.7101 - val_loss: 0.5565 - val_accuracy: 0.7083\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5391 - accuracy: 0.7118 - val_loss: 0.5558 - val_accuracy: 0.7083\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5382 - accuracy: 0.7135 - val_loss: 0.5551 - val_accuracy: 0.7083\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5374 - accuracy: 0.7135 - val_loss: 0.5544 - val_accuracy: 0.7083\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7135 - val_loss: 0.5538 - val_accuracy: 0.7083\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5357 - accuracy: 0.7135 - val_loss: 0.5532 - val_accuracy: 0.7135\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5348 - accuracy: 0.7135 - val_loss: 0.5525 - val_accuracy: 0.7135\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5340 - accuracy: 0.7135 - val_loss: 0.5519 - val_accuracy: 0.7135\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5332 - accuracy: 0.7135 - val_loss: 0.5513 - val_accuracy: 0.7135\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5324 - accuracy: 0.7153 - val_loss: 0.5507 - val_accuracy: 0.7135\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5316 - accuracy: 0.7153 - val_loss: 0.5501 - val_accuracy: 0.7135\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5308 - accuracy: 0.7170 - val_loss: 0.5496 - val_accuracy: 0.7188\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5301 - accuracy: 0.7205 - val_loss: 0.5490 - val_accuracy: 0.7188\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5293 - accuracy: 0.7222 - val_loss: 0.5484 - val_accuracy: 0.7240\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5286 - accuracy: 0.7222 - val_loss: 0.5479 - val_accuracy: 0.7240\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5278 - accuracy: 0.7222 - val_loss: 0.5473 - val_accuracy: 0.7188\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5271 - accuracy: 0.7222 - val_loss: 0.5468 - val_accuracy: 0.7135\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5264 - accuracy: 0.7240 - val_loss: 0.5463 - val_accuracy: 0.7188\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5257 - accuracy: 0.7240 - val_loss: 0.5457 - val_accuracy: 0.7188\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5250 - accuracy: 0.7309 - val_loss: 0.5452 - val_accuracy: 0.7188\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.7309 - val_loss: 0.5447 - val_accuracy: 0.7188\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5236 - accuracy: 0.7292 - val_loss: 0.5442 - val_accuracy: 0.7292\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7326 - val_loss: 0.5437 - val_accuracy: 0.7292\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5222 - accuracy: 0.7326 - val_loss: 0.5432 - val_accuracy: 0.7292\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5216 - accuracy: 0.7344 - val_loss: 0.5428 - val_accuracy: 0.7292\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5209 - accuracy: 0.7344 - val_loss: 0.5423 - val_accuracy: 0.7292\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5203 - accuracy: 0.7361 - val_loss: 0.5419 - val_accuracy: 0.7292\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5196 - accuracy: 0.7378 - val_loss: 0.5414 - val_accuracy: 0.7344\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.7396 - val_loss: 0.5410 - val_accuracy: 0.7344\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.7413 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5177 - accuracy: 0.7413 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5171 - accuracy: 0.7431 - val_loss: 0.5397 - val_accuracy: 0.7344\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.7431 - val_loss: 0.5393 - val_accuracy: 0.7344\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5159 - accuracy: 0.7448 - val_loss: 0.5389 - val_accuracy: 0.7344\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5153 - accuracy: 0.7465 - val_loss: 0.5385 - val_accuracy: 0.7344\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5147 - accuracy: 0.7483 - val_loss: 0.5381 - val_accuracy: 0.7344\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5141 - accuracy: 0.7465 - val_loss: 0.5377 - val_accuracy: 0.7344\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5135 - accuracy: 0.7483 - val_loss: 0.5373 - val_accuracy: 0.7344\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5129 - accuracy: 0.7465 - val_loss: 0.5369 - val_accuracy: 0.7396\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5124 - accuracy: 0.7465 - val_loss: 0.5366 - val_accuracy: 0.7396\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5118 - accuracy: 0.7483 - val_loss: 0.5362 - val_accuracy: 0.7448\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.7465 - val_loss: 0.5358 - val_accuracy: 0.7448\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7483 - val_loss: 0.5355 - val_accuracy: 0.7448\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5101 - accuracy: 0.7483 - val_loss: 0.5351 - val_accuracy: 0.7448\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5096 - accuracy: 0.7483 - val_loss: 0.5348 - val_accuracy: 0.7552\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7483 - val_loss: 0.5344 - val_accuracy: 0.7552\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5086 - accuracy: 0.7500 - val_loss: 0.5341 - val_accuracy: 0.7552\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5080 - accuracy: 0.7517 - val_loss: 0.5338 - val_accuracy: 0.7500\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7517 - val_loss: 0.5334 - val_accuracy: 0.7448\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5070 - accuracy: 0.7517 - val_loss: 0.5331 - val_accuracy: 0.7500\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7517 - val_loss: 0.5328 - val_accuracy: 0.7500\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7517 - val_loss: 0.5325 - val_accuracy: 0.7500\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7517 - val_loss: 0.5322 - val_accuracy: 0.7500\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7535 - val_loss: 0.5319 - val_accuracy: 0.7552\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7535 - val_loss: 0.5316 - val_accuracy: 0.7552\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7535 - val_loss: 0.5313 - val_accuracy: 0.7552\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5036 - accuracy: 0.7535 - val_loss: 0.5310 - val_accuracy: 0.7552\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.7535 - val_loss: 0.5308 - val_accuracy: 0.7552\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7535 - val_loss: 0.5305 - val_accuracy: 0.7552\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5022 - accuracy: 0.7535 - val_loss: 0.5302 - val_accuracy: 0.7552\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7535 - val_loss: 0.5299 - val_accuracy: 0.7552\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7535 - val_loss: 0.5297 - val_accuracy: 0.7552\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5009 - accuracy: 0.7535 - val_loss: 0.5294 - val_accuracy: 0.7552\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5004 - accuracy: 0.7517 - val_loss: 0.5292 - val_accuracy: 0.7552\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5000 - accuracy: 0.7517 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.7517 - val_loss: 0.5287 - val_accuracy: 0.7552\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4991 - accuracy: 0.7517 - val_loss: 0.5285 - val_accuracy: 0.7552\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4987 - accuracy: 0.7517 - val_loss: 0.5283 - val_accuracy: 0.7552\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4983 - accuracy: 0.7535 - val_loss: 0.5280 - val_accuracy: 0.7552\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4979 - accuracy: 0.7535 - val_loss: 0.5278 - val_accuracy: 0.7552\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4975 - accuracy: 0.7535 - val_loss: 0.5276 - val_accuracy: 0.7552\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4971 - accuracy: 0.7535 - val_loss: 0.5274 - val_accuracy: 0.7552\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4967 - accuracy: 0.7535 - val_loss: 0.5272 - val_accuracy: 0.7552\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4964 - accuracy: 0.7552 - val_loss: 0.5270 - val_accuracy: 0.7552\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4960 - accuracy: 0.7569 - val_loss: 0.5268 - val_accuracy: 0.7552\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7587 - val_loss: 0.5266 - val_accuracy: 0.7552\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.7587 - val_loss: 0.5264 - val_accuracy: 0.7552\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4949 - accuracy: 0.7587 - val_loss: 0.5262 - val_accuracy: 0.7552\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.7587 - val_loss: 0.5260 - val_accuracy: 0.7552\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4941 - accuracy: 0.7604 - val_loss: 0.5258 - val_accuracy: 0.7552\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4938 - accuracy: 0.7622 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4934 - accuracy: 0.7622 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4931 - accuracy: 0.7622 - val_loss: 0.5252 - val_accuracy: 0.7552\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4927 - accuracy: 0.7622 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4924 - accuracy: 0.7604 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4920 - accuracy: 0.7604 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4917 - accuracy: 0.7569 - val_loss: 0.5245 - val_accuracy: 0.7552\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4913 - accuracy: 0.7587 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4910 - accuracy: 0.7569 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4907 - accuracy: 0.7587 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4903 - accuracy: 0.7587 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4900 - accuracy: 0.7604 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4897 - accuracy: 0.7587 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4893 - accuracy: 0.7604 - val_loss: 0.5234 - val_accuracy: 0.7552\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4890 - accuracy: 0.7604 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4887 - accuracy: 0.7604 - val_loss: 0.5231 - val_accuracy: 0.7552\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4883 - accuracy: 0.7604 - val_loss: 0.5230 - val_accuracy: 0.7552\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4880 - accuracy: 0.7622 - val_loss: 0.5228 - val_accuracy: 0.7552\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4877 - accuracy: 0.7622 - val_loss: 0.5227 - val_accuracy: 0.7552\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4874 - accuracy: 0.7604 - val_loss: 0.5225 - val_accuracy: 0.7552\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4871 - accuracy: 0.7622 - val_loss: 0.5224 - val_accuracy: 0.7552\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4868 - accuracy: 0.7622 - val_loss: 0.5223 - val_accuracy: 0.7552\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4865 - accuracy: 0.7604 - val_loss: 0.5221 - val_accuracy: 0.7552\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4862 - accuracy: 0.7604 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4859 - accuracy: 0.7604 - val_loss: 0.5219 - val_accuracy: 0.7552\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4856 - accuracy: 0.7604 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4853 - accuracy: 0.7622 - val_loss: 0.5216 - val_accuracy: 0.7552\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4850 - accuracy: 0.7622 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4847 - accuracy: 0.7604 - val_loss: 0.5213 - val_accuracy: 0.7552\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4844 - accuracy: 0.7639 - val_loss: 0.5212 - val_accuracy: 0.7552\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7639 - val_loss: 0.5211 - val_accuracy: 0.7552\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4839 - accuracy: 0.7639 - val_loss: 0.5210 - val_accuracy: 0.7552\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4836 - accuracy: 0.7639 - val_loss: 0.5209 - val_accuracy: 0.7552\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4833 - accuracy: 0.7639 - val_loss: 0.5207 - val_accuracy: 0.7604\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4831 - accuracy: 0.7639 - val_loss: 0.5206 - val_accuracy: 0.7604\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4828 - accuracy: 0.7639 - val_loss: 0.5205 - val_accuracy: 0.7604\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4825 - accuracy: 0.7639 - val_loss: 0.5204 - val_accuracy: 0.7604\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4822 - accuracy: 0.7674 - val_loss: 0.5203 - val_accuracy: 0.7604\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4820 - accuracy: 0.7708 - val_loss: 0.5202 - val_accuracy: 0.7604\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4817 - accuracy: 0.7708 - val_loss: 0.5201 - val_accuracy: 0.7604\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "# y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "# y_pred_prob_nn_1 = model_1.predict(X_test_norm)\n",
    "\n",
    "y_pred_prob_nn_1= model_1.predict(X_test) \n",
    "y_pred_class_nn_1= (y_pred_prob_nn_1 > 0.5).astype(\"int32\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]], dtype=int32)"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "y_pred_prob_nn_1[:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1.       ],\n",
       "       [0.9999995],\n",
       "       [1.       ],\n",
       "       [1.       ],\n",
       "       [1.       ],\n",
       "       [1.       ],\n",
       "       [1.       ],\n",
       "       [1.       ],\n",
       "       [1.       ],\n",
       "       [1.       ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy is 0.354\n",
      "roc-auc is 0.465\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "run_hist_1.history.keys()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb6df9c5640>"
      ]
     },
     "metadata": {},
     "execution_count": 76
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4815 - accuracy: 0.7708 - val_loss: 0.5200 - val_accuracy: 0.7604\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.7708 - val_loss: 0.5199 - val_accuracy: 0.7604\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4810 - accuracy: 0.7708 - val_loss: 0.5198 - val_accuracy: 0.7604\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4807 - accuracy: 0.7708 - val_loss: 0.5197 - val_accuracy: 0.7552\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4804 - accuracy: 0.7708 - val_loss: 0.5195 - val_accuracy: 0.7552\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7708 - val_loss: 0.5194 - val_accuracy: 0.7552\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4799 - accuracy: 0.7708 - val_loss: 0.5193 - val_accuracy: 0.7552\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4797 - accuracy: 0.7708 - val_loss: 0.5192 - val_accuracy: 0.7552\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4795 - accuracy: 0.7708 - val_loss: 0.5191 - val_accuracy: 0.7552\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4792 - accuracy: 0.7708 - val_loss: 0.5190 - val_accuracy: 0.7552\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4790 - accuracy: 0.7708 - val_loss: 0.5189 - val_accuracy: 0.7552\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4788 - accuracy: 0.7708 - val_loss: 0.5188 - val_accuracy: 0.7552\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4785 - accuracy: 0.7708 - val_loss: 0.5188 - val_accuracy: 0.7552\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4783 - accuracy: 0.7726 - val_loss: 0.5187 - val_accuracy: 0.7552\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4781 - accuracy: 0.7726 - val_loss: 0.5186 - val_accuracy: 0.7552\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7726 - val_loss: 0.5185 - val_accuracy: 0.7552\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4776 - accuracy: 0.7726 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4774 - accuracy: 0.7726 - val_loss: 0.5183 - val_accuracy: 0.7552\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4772 - accuracy: 0.7726 - val_loss: 0.5182 - val_accuracy: 0.7552\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4770 - accuracy: 0.7726 - val_loss: 0.5181 - val_accuracy: 0.7552\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4767 - accuracy: 0.7726 - val_loss: 0.5181 - val_accuracy: 0.7552\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7726 - val_loss: 0.5180 - val_accuracy: 0.7552\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.7726 - val_loss: 0.5179 - val_accuracy: 0.7552\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4761 - accuracy: 0.7726 - val_loss: 0.5178 - val_accuracy: 0.7552\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4759 - accuracy: 0.7726 - val_loss: 0.5177 - val_accuracy: 0.7552\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4757 - accuracy: 0.7726 - val_loss: 0.5177 - val_accuracy: 0.7552\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4755 - accuracy: 0.7708 - val_loss: 0.5176 - val_accuracy: 0.7552\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4753 - accuracy: 0.7708 - val_loss: 0.5175 - val_accuracy: 0.7552\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.7743 - val_loss: 0.5174 - val_accuracy: 0.7552\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4749 - accuracy: 0.7726 - val_loss: 0.5174 - val_accuracy: 0.7552\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7743 - val_loss: 0.5173 - val_accuracy: 0.7552\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7743 - val_loss: 0.5172 - val_accuracy: 0.7552\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.7726 - val_loss: 0.5171 - val_accuracy: 0.7604\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7743 - val_loss: 0.5170 - val_accuracy: 0.7604\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.7726 - val_loss: 0.5170 - val_accuracy: 0.7604\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.7726 - val_loss: 0.5169 - val_accuracy: 0.7604\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7760 - val_loss: 0.5168 - val_accuracy: 0.7604\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7760 - val_loss: 0.5167 - val_accuracy: 0.7604\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4731 - accuracy: 0.7726 - val_loss: 0.5166 - val_accuracy: 0.7604\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7778 - val_loss: 0.5165 - val_accuracy: 0.7604\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.7778 - val_loss: 0.5165 - val_accuracy: 0.7604\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7778 - val_loss: 0.5164 - val_accuracy: 0.7604\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.7778 - val_loss: 0.5163 - val_accuracy: 0.7604\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7760 - val_loss: 0.5162 - val_accuracy: 0.7604\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7760 - val_loss: 0.5161 - val_accuracy: 0.7604\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.7760 - val_loss: 0.5160 - val_accuracy: 0.7604\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.7760 - val_loss: 0.5159 - val_accuracy: 0.7604\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4713 - accuracy: 0.7760 - val_loss: 0.5159 - val_accuracy: 0.7604\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7778 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4709 - accuracy: 0.7760 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.7760 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.7760 - val_loss: 0.5155 - val_accuracy: 0.7604\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7778 - val_loss: 0.5155 - val_accuracy: 0.7604\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4702 - accuracy: 0.7743 - val_loss: 0.5154 - val_accuracy: 0.7604\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.7743 - val_loss: 0.5153 - val_accuracy: 0.7604\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7743 - val_loss: 0.5152 - val_accuracy: 0.7604\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7743 - val_loss: 0.5152 - val_accuracy: 0.7604\n",
      "Epoch 58/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4694 - accuracy: 0.7778 - val_loss: 0.5151 - val_accuracy: 0.7604\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4693 - accuracy: 0.7760 - val_loss: 0.5150 - val_accuracy: 0.7604\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7778 - val_loss: 0.5150 - val_accuracy: 0.7604\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4689 - accuracy: 0.7778 - val_loss: 0.5149 - val_accuracy: 0.7604\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4687 - accuracy: 0.7778 - val_loss: 0.5148 - val_accuracy: 0.7604\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4686 - accuracy: 0.7778 - val_loss: 0.5148 - val_accuracy: 0.7604\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4684 - accuracy: 0.7778 - val_loss: 0.5147 - val_accuracy: 0.7604\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7778 - val_loss: 0.5146 - val_accuracy: 0.7604\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4681 - accuracy: 0.7778 - val_loss: 0.5146 - val_accuracy: 0.7604\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7778 - val_loss: 0.5145 - val_accuracy: 0.7604\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7778 - val_loss: 0.5145 - val_accuracy: 0.7604\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7778 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7778 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7778 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7778 - val_loss: 0.5142 - val_accuracy: 0.7604\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4669 - accuracy: 0.7778 - val_loss: 0.5142 - val_accuracy: 0.7604\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7778 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7778 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7795 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7795 - val_loss: 0.5139 - val_accuracy: 0.7500\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7795 - val_loss: 0.5138 - val_accuracy: 0.7500\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7795 - val_loss: 0.5138 - val_accuracy: 0.7448\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.5137 - val_accuracy: 0.7448\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5137 - val_accuracy: 0.7448\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.5136 - val_accuracy: 0.7448\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5136 - val_accuracy: 0.7448\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7882 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7882 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7882 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7882 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.7882 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7865 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7865 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7865 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7865 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7865 - val_loss: 0.5129 - val_accuracy: 0.7396\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7847 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7847 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7847 - val_loss: 0.5128 - val_accuracy: 0.7396\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7830 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7847 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4628 - accuracy: 0.7830 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7830 - val_loss: 0.5126 - val_accuracy: 0.7396\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7830 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7830 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7830 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4621 - accuracy: 0.7830 - val_loss: 0.5124 - val_accuracy: 0.7396\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7830 - val_loss: 0.5124 - val_accuracy: 0.7396\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7830 - val_loss: 0.5123 - val_accuracy: 0.7396\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7830 - val_loss: 0.5123 - val_accuracy: 0.7396\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7830 - val_loss: 0.5123 - val_accuracy: 0.7396\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7812 - val_loss: 0.5122 - val_accuracy: 0.7396\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7830 - val_loss: 0.5122 - val_accuracy: 0.7448\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7830 - val_loss: 0.5122 - val_accuracy: 0.7448\n",
      "Epoch 115/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7812 - val_loss: 0.5121 - val_accuracy: 0.7448\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.5121 - val_accuracy: 0.7448\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7812 - val_loss: 0.5121 - val_accuracy: 0.7448\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7812 - val_loss: 0.5120 - val_accuracy: 0.7448\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.5120 - val_accuracy: 0.7448\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4606 - accuracy: 0.7830 - val_loss: 0.5120 - val_accuracy: 0.7448\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.7830 - val_loss: 0.5119 - val_accuracy: 0.7448\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4604 - accuracy: 0.7830 - val_loss: 0.5119 - val_accuracy: 0.7448\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7830 - val_loss: 0.5119 - val_accuracy: 0.7448\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.5119 - val_accuracy: 0.7448\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4601 - accuracy: 0.7847 - val_loss: 0.5118 - val_accuracy: 0.7448\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.5118 - val_accuracy: 0.7448\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.5118 - val_accuracy: 0.7448\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7812 - val_loss: 0.5118 - val_accuracy: 0.7448\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7812 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7812 - val_loss: 0.5116 - val_accuracy: 0.7448\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7812 - val_loss: 0.5116 - val_accuracy: 0.7448\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.5116 - val_accuracy: 0.7448\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7812 - val_loss: 0.5116 - val_accuracy: 0.7448\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7795 - val_loss: 0.5116 - val_accuracy: 0.7448\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7795 - val_loss: 0.5115 - val_accuracy: 0.7448\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.5115 - val_accuracy: 0.7448\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7795 - val_loss: 0.5115 - val_accuracy: 0.7448\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7795 - val_loss: 0.5115 - val_accuracy: 0.7448\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7778 - val_loss: 0.5115 - val_accuracy: 0.7448\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7778 - val_loss: 0.5114 - val_accuracy: 0.7448\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7778 - val_loss: 0.5114 - val_accuracy: 0.7448\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7778 - val_loss: 0.5114 - val_accuracy: 0.7448\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7778 - val_loss: 0.5114 - val_accuracy: 0.7448\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7778 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7778 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7778 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4577 - accuracy: 0.7778 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7778 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.5113 - val_accuracy: 0.7396\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4574 - accuracy: 0.7760 - val_loss: 0.5112 - val_accuracy: 0.7396\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4573 - accuracy: 0.7760 - val_loss: 0.5112 - val_accuracy: 0.7396\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4572 - accuracy: 0.7760 - val_loss: 0.5112 - val_accuracy: 0.7396\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.5112 - val_accuracy: 0.7396\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7743 - val_loss: 0.5111 - val_accuracy: 0.7396\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7760 - val_loss: 0.5111 - val_accuracy: 0.7396\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7760 - val_loss: 0.5111 - val_accuracy: 0.7396\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.7760 - val_loss: 0.5111 - val_accuracy: 0.7396\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7760 - val_loss: 0.5111 - val_accuracy: 0.7396\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.5110 - val_accuracy: 0.7396\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4565 - accuracy: 0.7760 - val_loss: 0.5110 - val_accuracy: 0.7396\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4564 - accuracy: 0.7760 - val_loss: 0.5110 - val_accuracy: 0.7396\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7760 - val_loss: 0.5110 - val_accuracy: 0.7396\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7760 - val_loss: 0.5110 - val_accuracy: 0.7396\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7760 - val_loss: 0.5110 - val_accuracy: 0.7396\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7760 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7760 - val_loss: 0.5109 - val_accuracy: 0.7448\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7760 - val_loss: 0.5109 - val_accuracy: 0.7448\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7760 - val_loss: 0.5109 - val_accuracy: 0.7448\n",
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7760 - val_loss: 0.5109 - val_accuracy: 0.7448\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.7760 - val_loss: 0.5109 - val_accuracy: 0.7448\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7760 - val_loss: 0.5109 - val_accuracy: 0.7448\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7760 - val_loss: 0.5109 - val_accuracy: 0.7448\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7760 - val_loss: 0.5108 - val_accuracy: 0.7448\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7760 - val_loss: 0.5108 - val_accuracy: 0.7448\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7760 - val_loss: 0.5108 - val_accuracy: 0.7448\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7760 - val_loss: 0.5108 - val_accuracy: 0.7448\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7760 - val_loss: 0.5108 - val_accuracy: 0.7448\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.7760 - val_loss: 0.5108 - val_accuracy: 0.7396\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7760 - val_loss: 0.5107 - val_accuracy: 0.7396\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7778 - val_loss: 0.5107 - val_accuracy: 0.7396\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.7778 - val_loss: 0.5107 - val_accuracy: 0.7396\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.7795 - val_loss: 0.5107 - val_accuracy: 0.7396\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7778 - val_loss: 0.5107 - val_accuracy: 0.7396\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.7778 - val_loss: 0.5107 - val_accuracy: 0.7396\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7812 - val_loss: 0.5107 - val_accuracy: 0.7396\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.7812 - val_loss: 0.5106 - val_accuracy: 0.7396\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.7812 - val_loss: 0.5106 - val_accuracy: 0.7396\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7812 - val_loss: 0.5106 - val_accuracy: 0.7396\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7812 - val_loss: 0.5106 - val_accuracy: 0.7396\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7795 - val_loss: 0.5106 - val_accuracy: 0.7396\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7812 - val_loss: 0.5106 - val_accuracy: 0.7396\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.7795 - val_loss: 0.5106 - val_accuracy: 0.7448\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7812 - val_loss: 0.5106 - val_accuracy: 0.7448\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7795 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7812 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4538 - accuracy: 0.7812 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7795 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.7795 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7778 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7795 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7795 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7795 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7795 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7795 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7795 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7795 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7795 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7795 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7795 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.7795 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7795 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7795 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.7795 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7795 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7795 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.7812 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7812 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.7812 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.7812 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7812 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7812 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7795 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7812 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4519 - accuracy: 0.7812 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7795 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7812 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7795 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7795 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7812 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7812 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7795 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.7812 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4514 - accuracy: 0.7812 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7812 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7830 - val_loss: 0.5104 - val_accuracy: 0.7552\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7847 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7847 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.7847 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7847 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.7847 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.7847 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7847 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7847 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7847 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.7847 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7847 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7847 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7847 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7847 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4495 - accuracy: 0.7847 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7847 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7847 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.7847 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7847 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7830 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7830 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.7847 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7830 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7830 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7847 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7830 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7830 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.7830 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.7847 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7847 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7830 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7830 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7830 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7847 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7847 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7865 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7865 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7865 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7865 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7865 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7865 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7865 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.7865 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7865 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7865 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7865 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4479 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7500\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7500\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7500\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7500\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7500\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7847 - val_loss: 0.5096 - val_accuracy: 0.7500\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4469 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7500\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7500\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7847 - val_loss: 0.5096 - val_accuracy: 0.7500\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.7847 - val_loss: 0.5096 - val_accuracy: 0.7500\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7500\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7500\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.7865 - val_loss: 0.5095 - val_accuracy: 0.7500\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7500\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7500\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7500\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7500\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7500\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7500\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7500\n",
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7500\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7448\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7448\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7448\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7448\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4447 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7865 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7865 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7865 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7865 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7865 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7865 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7865 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7865 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7865 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7865 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4429 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.7865 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7865 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7865 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7865 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7865 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7865 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7865 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7865 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7847 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7865 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7865 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7847 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7865 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7847 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7865 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7847 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7847 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7847 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7830 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7847 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7847 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4422 - accuracy: 0.7847 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4421 - accuracy: 0.7830 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4421 - accuracy: 0.7847 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4420 - accuracy: 0.7847 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4420 - accuracy: 0.7847 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.7830 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4419 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4419 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4419 - accuracy: 0.7830 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.7830 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4418 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.7830 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4417 - accuracy: 0.7830 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4417 - accuracy: 0.7830 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4417 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4415 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4415 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7812 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4413 - accuracy: 0.7812 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4413 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4412 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.7812 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.7812 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7812 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.7812 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.7812 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4408 - accuracy: 0.7812 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.7812 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7812 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.7812 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7812 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7812 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4407 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7812 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.7812 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.7812 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.7812 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.7812 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.7812 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.7812 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4404 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.7812 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7812 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7830 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4393 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4392 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4377 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4374 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4373 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4372 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4372 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4371 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7830 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7830 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7830 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7830 - val_loss: 0.5092 - val_accuracy: 0.7500\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7830 - val_loss: 0.5092 - val_accuracy: 0.7500\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7812 - val_loss: 0.5092 - val_accuracy: 0.7500\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7830 - val_loss: 0.5092 - val_accuracy: 0.7500\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7812 - val_loss: 0.5092 - val_accuracy: 0.7500\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7830 - val_loss: 0.5092 - val_accuracy: 0.7500\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7812 - val_loss: 0.5092 - val_accuracy: 0.7500\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7830 - val_loss: 0.5092 - val_accuracy: 0.7500\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7830 - val_loss: 0.5092 - val_accuracy: 0.7500\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7830 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7830 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7830 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7830 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4364 - accuracy: 0.7830 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7830 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7830 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7830 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7830 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7830 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7830 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7830 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4362 - accuracy: 0.7830 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4362 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4358 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4355 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4355 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7604\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7604\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7604\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7604\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7604\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7604\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7847 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7847 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7847 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7847 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7847 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7847 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7847 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7847 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4341 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7847 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7847 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7847 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7847 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7865 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7865 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7865 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.7865 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7865 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7865 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7865 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7865 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7865 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7865 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7865 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7865 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7865 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7865 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7865 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7865 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7865 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7865 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7865 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7865 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7865 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7865 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7865 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7865 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7865 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7865 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7865 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7865 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7865 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7865 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7865 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7865 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7865 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7865 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7865 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7882 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7865 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7865 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7865 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7882 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7865 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7865 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7865 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7865 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7865 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7865 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7865 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.7865 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7865 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7865 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7882 - val_loss: 0.5104 - val_accuracy: 0.7552\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7865 - val_loss: 0.5104 - val_accuracy: 0.7552\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7865 - val_loss: 0.5104 - val_accuracy: 0.7552\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7865 - val_loss: 0.5104 - val_accuracy: 0.7552\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7865 - val_loss: 0.5104 - val_accuracy: 0.7552\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7865 - val_loss: 0.5104 - val_accuracy: 0.7552\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7865 - val_loss: 0.5104 - val_accuracy: 0.7552\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7865 - val_loss: 0.5104 - val_accuracy: 0.7552\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7865 - val_loss: 0.5104 - val_accuracy: 0.7552\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7865 - val_loss: 0.5104 - val_accuracy: 0.7552\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7865 - val_loss: 0.5104 - val_accuracy: 0.7552\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7865 - val_loss: 0.5105 - val_accuracy: 0.7552\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7865 - val_loss: 0.5105 - val_accuracy: 0.7552\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7865 - val_loss: 0.5105 - val_accuracy: 0.7552\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7865 - val_loss: 0.5105 - val_accuracy: 0.7552\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7865 - val_loss: 0.5105 - val_accuracy: 0.7552\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7865 - val_loss: 0.5105 - val_accuracy: 0.7552\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7865 - val_loss: 0.5105 - val_accuracy: 0.7552\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7865 - val_loss: 0.5105 - val_accuracy: 0.7552\n",
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7865 - val_loss: 0.5105 - val_accuracy: 0.7552\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7865 - val_loss: 0.5105 - val_accuracy: 0.7552\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4323 - accuracy: 0.7865 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7865 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7865 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7865 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7865 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7865 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7865 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7865 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4317 - accuracy: 0.7830 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4315 - accuracy: 0.7865 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4315 - accuracy: 0.7865 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7865 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7552\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7847 - val_loss: 0.5110 - val_accuracy: 0.7552\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4315 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4313 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4313 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.7847 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.7882 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.7882 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7882 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7899 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7882 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7882 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7882 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4311 - accuracy: 0.7882 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7899 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.7899 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7899 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7899 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.7899 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.7899 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.7899 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4309 - accuracy: 0.7899 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7899 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4309 - accuracy: 0.7899 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4309 - accuracy: 0.7899 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4309 - accuracy: 0.7899 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4309 - accuracy: 0.7899 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7899 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7899 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7899 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7899 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4307 - accuracy: 0.7899 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4307 - accuracy: 0.7899 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7899 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4307 - accuracy: 0.7899 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7899 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7899 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.7899 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4306 - accuracy: 0.7899 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.7899 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4306 - accuracy: 0.7899 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.7899 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7899 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7899 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4305 - accuracy: 0.7899 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7899 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.7899 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.7899 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7899 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4304 - accuracy: 0.7899 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7899 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7899 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4303 - accuracy: 0.7899 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7899 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7899 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4303 - accuracy: 0.7899 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7899 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7917 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7899 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7917 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.7899 - val_loss: 0.5114 - val_accuracy: 0.7500\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7899 - val_loss: 0.5114 - val_accuracy: 0.7500\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.7899 - val_loss: 0.5114 - val_accuracy: 0.7500\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.7899 - val_loss: 0.5114 - val_accuracy: 0.7500\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7917 - val_loss: 0.5114 - val_accuracy: 0.7500\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4301 - accuracy: 0.7899 - val_loss: 0.5114 - val_accuracy: 0.7500\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.7899 - val_loss: 0.5114 - val_accuracy: 0.7500\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.7899 - val_loss: 0.5114 - val_accuracy: 0.7500\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.7899 - val_loss: 0.5114 - val_accuracy: 0.7500\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.7917 - val_loss: 0.5115 - val_accuracy: 0.7500\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4300 - accuracy: 0.7899 - val_loss: 0.5115 - val_accuracy: 0.7500\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7899 - val_loss: 0.5115 - val_accuracy: 0.7500\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7899 - val_loss: 0.5115 - val_accuracy: 0.7500\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4299 - accuracy: 0.7899 - val_loss: 0.5115 - val_accuracy: 0.7500\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7899 - val_loss: 0.5115 - val_accuracy: 0.7500\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4299 - accuracy: 0.7899 - val_loss: 0.5115 - val_accuracy: 0.7500\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7500\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7500\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4298 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7500\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7500\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb6df75bf70>"
      ]
     },
     "metadata": {},
     "execution_count": 78
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6gAAAHSCAYAAADhZ+amAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABWzUlEQVR4nO3de3zU5Z33/9eVA6CIgoCHghXwh1bkTISOeAjSWlsteKjWQ4uoleq9HrseatutLq632nVX6671WLW2rty0XSmsWttS46FGa1AUQamKVMHqCgpSEXK6fn/MJExCEjLJJDNJXs/HI535HnNNnE7y5rquzxVijEiSJEmSlGsFuW6AJEmSJElgQJUkSZIk5QkDqiRJkiQpLxhQJUmSJEl5wYAqSZIkScoLBlRJkiRJUl4oynUDGhs0aFAcNmxYrpshSZIkSeoAS5YsWRdjHNzUsbwLqMOGDaOioiLXzZAkSZIkdYAQwl+bO+YQX0mSJElSXjCgSpIkSZLyggFVkiRJkpQX8m4OqiRJkqTcqKqqYs2aNWzZsiXXTVE30KdPH4YOHUpxcXGrrzGgSpIkSQJgzZo19OvXj2HDhhFCyHVz1IXFGFm/fj1r1qxh+PDhrb7OIb6SJEmSANiyZQsDBw40nKrdQggMHDgw4954A6okSZKkeoZTZUtb3ksGVEmSJEl5Yf369YwfP57x48ez1157MWTIkPrtysrKFq+tqKjgwgsvzOj7DRs2jHXr1rWnyW22evVqdtppJ8aPH8+oUaOYNWsWVVVVWbn397//ffbZZx922WWXrNyvMxlQJUmSJOWFgQMHsnTpUpYuXcq5557LJZdcUr/dq1cvqqurm722pKSEW265pRNb23777bcfS5cuZdmyZaxZs4b58+dn5b5f/epX+fOf/5yVe3U2A6okSZKktisvh+uuSz52gNmzZ3PuuecyZcoULr/8cv785z+TSCSYMGEChxxyCCtXrgSgrKyMY489FoCrr76as846i9LSUkaMGJFRcF29ejVHHnkkY8eOZfr06bz99tsA/PKXv2T06NGMGzeOww8/HIDly5czefJkxo8fz9ixY3n99dfb9BoLCwuZPHkya9euBRr27FZUVFBaWprR6/r85z/P3nvv3aa25JpVfCVJkiRt7+KLYenSls/ZuBFefhlqa6GgAMaOhd12a/788ePh5pszbsqaNWt45plnKCws5OOPP+app56iqKiIP/zhD3zve9/j17/+9XbXvPbaazz++ONs2rSJAw44gPPOO69Vy51ccMEFnHHGGZxxxhncc889XHjhhSxYsIC5c+fy2GOPMWTIEDZs2ADA7bffzkUXXcTpp59OZWUlNTU1Gb82SBaneu655/jxj3+8w3Pb+rq6CntQJUmSJLXNxo3JcArJx40bO+TbnHTSSRQWFqa+5UZOOukkRo8ezSWXXMLy5cubvOaYY46hd+/eDBo0iD322IP333+/Vd+rvLyc0047DYBvfvObPP300wBMnTqV2bNnc9ddd9UH0UQiwf/9v/+XG264gb/+9a/stNNOGb2uN998k/Hjx7Pnnnuy9957M3bs2B1e09bX1VXYgypJkiRpe63p6Swvh+nTobISevWCBx6ARCLrTenbt2/983/6p39i2rRpPPTQQ6xevbp++GtjvXv3rn9eWFjY4vzV1rj99tt57rnnePjhh5k0aRJLlizhtNNOY8qUKTz88MN85Stf4Y477uDII4+sv+ahhx7in//5nwG4++67KSkpaXDPujmo69atY+rUqSxcuJAZM2ZQVFREbSr4N16mJduvK9/YgypJkiSpbRIJWLwYrrkm+dgB4bSxjRs3MmTIEADuu+++rN//kEMOYd68eQA88MADHHbYYUCyt3PKlCnMnTuXwYMH884777Bq1SpGjBjBhRdeyMyZM3n55Zcb3Ov444+vL/LUOJymGzRoENdffz3XXXcdkJyDumTJEoAmhy93ZwZUSZIkSW2XSMCVV3ZKOAW4/PLLufLKK5kwYUJWeg/Hjh3L0KFDGTp0KN/5znf4j//4D+69917Gjh3Lz3/+8/p5oZdddhljxoxh9OjRHHLIIYwbN4758+czevRoxo8fzyuvvMKsWbPa3I7jjjuOzZs389RTT3HVVVdx0UUXUVJSUj+0OROXX345Q4cOZfPmzQwdOpSrr766ze3qbCHGmOs2NFBSUhIrKipy3QxJkiSpx3n11Vc58MADc90MdSNNvadCCEtijE12KduDmqmyMvjhDzusjLYkSZIk9VQWScpE3STw2lq48cZOG2cvSZIkST1Bq3pQQwhHhxBWhhDeCCF8t4njnw0hPB5CeDGE8HII4Stpx65MXbcyhPClbDa+05WVbSujXVmZ3JYkSZIkZcUOA2oIoRC4FfgyMAo4NYQwqtFpPwDmxxgnAKcAP0ldOyq1fRBwNPCT1P26ptJSqJuk3KtXcluSJEmSlBWt6UGdDLwRY1wVY6wE5gEzG50TgV1Tz3cD3k09nwnMizFujTG+BbyRul/XlEjAccdBnz4O75UkSZKkLGtNQB0CvJO2vSa1L93VwDdCCGuAR4ALMriWEMKcEEJFCKHigw8+aGXTc2T//aG6Gj7/+Vy3RJIkSZK6lWxV8T0VuC/GOBT4CvDzEEKr7x1jvDPGWBJjLBk8eHCWmtRB+vVLBtQtW3LdEkmSJKlbWb9+PePHj2f8+PHstddeDBkypH67srKyxWsrKiq48MILM/p+w4YNY926de1pcputXr2anXbaifHjxzNq1ChmzZpFVVVVu++7efNmjjnmGD73uc9x0EEH8d3vbldCKK+1porvWmCftO2hqX3pziY5x5QYY3kIoQ8wqJXXdi27pkYyb9oEO+2U27ZIkiRJ3cjAgQNZunQpAFdffTW77LILl156af3x6upqioqajjAlJSWUlDS5tGbe2m+//Vi6dCk1NTV88YtfZP78+Zx++untvu+ll17KtGnTqKysZPr06Tz66KN8+ctfzkKLO15rejmfB0aGEIaHEHqRLHq0sNE5bwPTAUIIBwJ9gA9S550SQugdQhgOjAT+nK3G50S/fsnHjz/ObTskSZKkfLDqI/jtG8nHDjB79mzOPfdcpkyZwuWXX86f//xnEokEEyZM4JBDDmHlypUAlJWVceyxxwLJcHvWWWdRWlrKiBEjuOWWW1r9/VavXs2RRx7J2LFjmT59Om+//TYAv/zlLxk9ejTjxo3j8MMPB2D58uVMnjyZ8ePHM3bsWF5//fU2vcbCwkImT57M2rXJvrz0nt2KigpKU8VZW/O6dt55Z6ZNmwZAr169mDhxImvWrGlTu3Jhhz2oMcbqEML5wGNAIXBPjHF5CGEuUBFjXAj8I3BXCOESkgWTZscYI7A8hDAfWAFUA/8QY6zpqBfTKdJ7UCVJkqTu6pfLYc0OOmU+rYK1m5IJIABD+sFOxc2fP3RXOOmgjJuyZs0annnmGQoLC/n444956qmnKCoq4g9/+APf+973+PWvf73dNa+99hqPP/44mzZt4oADDuC8886juLiFtqVccMEFnHHGGZxxxhncc889XHjhhSxYsIC5c+fy2GOPMWTIEDZs2ADA7bffzkUXXcTpp59OZWUlNTVtizpbtmzhueee48c//vEOz83kdW3YsIFFixZx0UUXtaldudCaIb7EGB8hWfwofd8P056vAKY2c+21wLXtaGN+qetBNaBKkiSpp/u0OhlOIfn4aXXLAbWNTjrpJApTyz1u3LiRM844g9dff50QQrPzNo855hh69+5N79692WOPPXj//fcZOnToDr9XeXk5//3f/w3AN7/5TS6//HIApk6dyuzZszn55JM54YQTAEgkElx77bWsWbOGE044gZEjR2b0ut58803Gjx/PW2+9xTHHHMPYsWN3eE1rX1d1dTWnnnoqF154ISNGjMioXbnUqoCqNA7xlSRJUk/Qmp7OVR/Bj5+FmlooLIAzJ8CIAVlvSt++feuf/9M//RPTpk3joYceYvXq1fXDXxvr3bt3/fPCwkKqq6vb1Ybbb7+d5557jocffphJkyaxZMkSTjvtNKZMmcLDDz/MV77yFe644w6OPPLI+mseeugh/vmf/xmAu+++e7s5snVzUNetW8fUqVNZuHAhM2bMoKioiNraWiDZu9qW1zVnzhxGjhzJxRdf3K7X3dmyVcW353CIryRJkpQ0YgBc9Hk49oDkYweE08Y2btzIkCHJlSvvu+++rN//kEMOYd68eQA88MADHHbYYUCyt3PKlCnMnTuXwYMH884777Bq1SpGjBjBhRdeyMyZM3n55Zcb3Ov4449n6dKlLF26tMUCToMGDeL666/nuuuuA5JzUJcsWQLQ5PDlHfnBD37Axo0bufnmmzO+NtcMqJmq60GdPx/Ky3PbFkmSJCnXRgyAo/+/TgmnAJdffjlXXnklEyZMaHevKMDYsWMZOnQoQ4cO5Tvf+Q7/8R//wb333svYsWP5+c9/Xj8v9LLLLmPMmDGMHj2aQw45hHHjxjF//nxGjx7N+PHjeeWVV5g1a1ab23HcccexefNmnnrqKa666iouuugiSkpK6oc2t9aaNWu49tprWbFiBRMnTmT8+PHcfffdbW5XZwvJWkb5o6SkJFZUVOS6Gc37wx/gi1+EEKBPH1i8GBKJXLdKkiRJardXX32VAw88MNfNUDfS1HsqhLAkxthkl7I9qJn6c2qVnBihshLKynLaHEmSJEnqLgyomUqtKUQI0KsXNDMpW5IkSZKUGQNqphIJGDQIJk1yeK8kSZIkZZEBtS0GDoQRIwynkiRJkpRFBtS22HVX10GVJEmSpCwzoLZFv36ugypJkiRJWWZAbQt7UCVJkqSsmzZtGo899liDfTfffDPnnXdes9eUlpZSt0zlV77yFTZs2LDdOVdffTU33nhji997wYIFrFixon77hz/8IX/4wx8yaH3TysrKOPbYY9t9n7a6+uqrGTJkCOPHj2fUqFE8+OCDWbnv+vXrmTZtGrvssgvnn39+Vu4JBtS2sQdVkiRJyrpTTz2VefPmNdg3b948Tj311FZd/8gjj9C/f/82fe/GAXXu3Ll84QtfaNO98s0ll1zC0qVL+c1vfsO3v/1tqqqq2n3PPn36cM011+ww+GfKgNoWu+5qQJUkSZKA8nK47rrkY3t97Wtf4+GHH6ayshKA1atX8+6773LYYYdx3nnnUVJSwkEHHcRVV13V5PXDhg1j3bp1AFx77bXsv//+HHrooaxcubL+nLvuuouDDz6YcePGceKJJ7J582aeeeYZFi5cyGWXXcb48eN58803mT17Nr/61a8AWLx4MRMmTGDMmDGcddZZbN26tf77XXXVVUycOJExY8bw2muvtfq1Pvjgg4wZM4bRo0dzxRVXAFBTU8Ps2bMZPXo0Y8aM4aabbgLglltuYdSoUYwdO5ZTTjklw5/qNiNHjmTnnXfmo48+2q5n9/zzz+e+++5r9evq27cvhx56KH369Glze5pSlNW79RT9+jnEV5IkSd3axRfD0qUtn7NxI7z8MtTWQkEBjB0Lu+3W/Pnjx8PNNzd/fPfdd2fy5Mk8+uijzJw5k3nz5nHyyScTQuDaa69l9913p6amhunTp/Pyyy8zduzYJu+zZMkS5s2bx9KlS6murmbixIlMmjQJgBNOOIFzzjkHgB/84Af89Kc/5YILLmDGjBkce+yxfO1rX2twry1btjB79mwWL17M/vvvz6xZs7jtttu4+OKLARg0aBAvvPACP/nJT7jxxhu5++67W/6hAe+++y5XXHEFS5YsYcCAARx11FEsWLCAffbZh7Vr1/LKK68A1A9Xvv7663nrrbfo3bt3k0OYW+uFF15g5MiR7LHHHg16i5vSlteVDfagZqi8HK574SjKqyZB6l9OJEmSpJ5o48ZkOIXk48aN7b9n+jDf9OG98+fPZ+LEiUyYMIHly5e3GLCeeuopjj/+eHbeeWd23XVXZsyYUX/slVde4bDDDmPMmDE88MADLF++vMX2rFy5kuHDh7P//vsDcMYZZ/Dkk0/WHz/hhBMAmDRpEqtXr27Va3z++ecpLS1l8ODBFBUVcfrpp/Pkk08yYsQIVq1axQUXXMBvf/tbdt11VwDGjh3L6aefzi9+8QuKijLvY7zppps46KCDmDJlCt///vdbdU1bXlc22IOagfJyKC2Fqsoj6MNiFv/nEhL/eEiumyVJkiRlXUs9nXXKy2H6dKishF694IEHIJFo3/edOXMml1xyCS+88AKbN29m0qRJvPXWW9x44408//zzDBgwgNmzZ7Nly5Y23X/27NksWLCAcePGcd9991FWVtau9vbu3RuAwsJCqqur23WvAQMG8NJLL/HYY49x++23M3/+fO655x4efvhhnnzySRYtWsS1117LsmXLGgTVM888kxdffJHPfOYzPPLII9vd95JLLuHSSy9l4cKFnH322bz55psUFRVRW/evC7DdzzObrysT9qBmoKwMKisjkQIqKabsu49mZ7C9JEmS1AUlErB4MVxzTfKxveEUYJdddmHatGmcddZZ9b2nH3/8MX379mW33Xbj/fff59FHH23xHocffjgLFizg008/ZdOmTSxatKj+2KZNm9h7772pqqrigQceqN/fr18/NjVRZ+aAAw5g9erVvPHGGwD8/Oc/54gjjmjXa5w8eTJPPPEE69ato6amhgcffJAjjjiCdevWUVtby4knnsi//Mu/8MILL1BbW8s777zDtGnTuOGGG9i4cSN///vfG9zv3nvvZenSpU2G03QzZsygpKSEn/3sZ+y7776sWLGCrVu3smHDBhYvXtyu15Qt9qBmoLQUCkOkJkIvqiitfRzKds7O/xMlSZKkLiiRyP6fw6eeeirHH398/VDfcePGMWHCBD73uc+xzz77MHXq1BavnzhxIl//+tcZN24ce+yxBwcffHD9sWuuuYYpU6YwePBgpkyZUh9KTznlFM455xxuueWW+uJIkKxWe++993LSSSdRXV3NwQcfzLnnnpvR61m8eDFDhw6t3/7lL3/J9ddfz7Rp04gxcswxxzBz5kxeeuklzjzzzPqezeuuu46amhq+8Y1vsHHjRmKMXHjhhW2uVAzJ5XNOO+00zjnnHE4++WRGjx7N8OHDmTBhQsb3GjZsGB9//DGVlZUsWLCA3/3ud4waNarNbQMIMcZ23SDbSkpKYt06RvnoxNL1/PaJPvyBL5Do/SI8/rgBVZIkSd3Cq6++yoEHHpjrZqgbaeo9FUJYEmMsaep8h/hm6IBDBlJZuBOf51m4+mrDqSRJkiRliQE1Q/37Q3VNAZvZGfbeO9fNkSRJkqRuw4Caobrh3hvoD+1Yg0iSJEmS1JABNUN1AXUju2VnoSdJkiRJEmBAzdhuuyUfN/TZ24AqSZIkSVlkQM1Q/RDfnT9jQJUkSZKkLDKgZqh+iO9OezkHVZIkScqiadOm8dhjjzXYd/PNN3Peeec1e01paSl1y1R+5StfYUMTf6NfffXV3HjjjS1+7wULFrBixYr67R/+8If84Q9/yKD1TSsrK+PYY49t933a6uqrr2bIkCGMHz+eUaNG8eCDD2blvr///e+ZNGkSY8aMYdKkSfzxj3/Myn0NqBmqG+I77+MvU/5sgPLy3DZIkiRJ6iZOPfVU5s2b12DfvHnzOPXUU1t1/SOPPEL/uh6lDDUOqHPnzuULX/hCm+6Vby655BKWLl3Kb37zG7797W9TVVXV7nsOGjSIRYsWsWzZMn72s5/xzW9+MwstNaBm7LXXko+LNh3B9LU/o7z0SkOqJEmSeqy1n9RS/l4Naz+pbfe9vva1r/Hwww9TWVkJwOrVq3n33Xc57LDDOO+88ygpKeGggw7iqquuavL6YcOGsW7dOgCuvfZa9t9/fw499FBWrlxZf85dd93FwQcfzLhx4zjxxBPZvHkzzzzzDAsXLuSyyy5j/PjxvPnmm8yePZtf/epXACxevJgJEyYwZswYzjrrLLZu3Vr//a666iomTpzImDFjeK0uLLTCgw8+yJgxYxg9ejRXXHEFADU1NcyePZvRo0czZswYbrrpJgBuueUWRo0axdixYznllFMy/KluM3LkSHbeeWc++uij7Xp2zz//fO67775Wv64JEybwmc98BoCDDjqITz/9tP7n0h5F7b5DD5PMopFIIZUUU1Y1lURZGSQSOW6ZJEmSlD1/WFPD+5/GFs/ZWhP54FOIQPgbDN6pht6Fodnz99wp8IWhhc0e33333Zk8eTKPPvooM2fOZN68eZx88smEELj22mvZfffdqampYfr06bz88suMHTu2yfssWbKEefPmsXTpUqqrq5k4cSKTJk0C4IQTTuCcc84B4Ac/+AE//elPueCCC5gxYwbHHnssX/va1xrca8uWLcyePZvFixez//77M2vWLG677TYuvvhiINmT+MILL/CTn/yEG2+8kbvvvrvFnxnAu+++yxVXXMGSJUsYMGAARx11FAsWLGCfffZh7dq1vPLKKwD1w5Wvv/563nrrLXr37t3kEObWeuGFFxg5ciR77LFHg97ipmTyun79618zceJEevfu3ea21bEHNUOlpcnHQC29qKK0+E/bdkqSJEk9yNaaZDiF5OPWmvbfM32Yb/rw3vnz5zNx4kQmTJjA8uXLWwxYTz31FMcffzw777wzu+66KzNmzKg/9sorr3DYYYcxZswYHnjgAZYvX95ie1auXMnw4cPZf//9ATjjjDN48skn64+fcMIJAEyaNInVq1e36jU+//zzlJaWMnjwYIqKijj99NN58sknGTFiBKtWreKCCy7gt7/9LbvuuisAY8eO5fTTT+cXv/gFRUWZ9zHedNNNHHTQQUyZMoXvf//7rbqmta9r+fLlXHHFFdxxxx0Zt6sp9qBmKJGAffYJ9N/0Nnd8fDqJsn+191SSJEndTks9nXXWflLLg6/XUBOhMMCMYYUM6du+PrCZM2dyySWX8MILL7B582YmTZrEW2+9xY033sjzzz/PgAEDmD17Nlu2bGnT/WfPns2CBQsYN24c9913H2VlZe1qb12vYWFhIdXV1e2614ABA3jppZd47LHHuP3225k/fz733HMPDz/8ME8++SSLFi3i2muvZdmyZQ2C6plnnsmLL77IZz7zGR555JHt7nvJJZdw6aWXsnDhQs4++2zefPNNioqKqK3dNiy78c+zNa9rzZo1HH/88dx///3st99+7XrtdexBbYO994Yhg6tJ1P4JJkzIdXMkSZKknBjSt4BTRxZy+N7Jx/aGU4BddtmFadOmcdZZZ9X3nn788cf07duX3Xbbjffff59HH320xXscfvjhLFiwgE8//ZRNmzaxaNGi+mObNm1i7733pqqqigceeKB+f79+/di0adN29zrggANYvXo1b7zxBgA///nPOeKII9r1GidPnswTTzzBunXrqKmp4cEHH+SII45g3bp11NbWcuKJJ/Iv//IvvPDCC9TW1vLOO+8wbdo0brjhBjZu3Mjf//73Bve79957Wbp0aZPhNN2MGTMoKSnhZz/7Gfvuuy8rVqxg69atbNiwgcWLF2f0GjZs2MAxxxzD9ddfz9SpUzP+GTTHHtQ22G032PBB3+TGxo3Qp09uGyRJkiTlyJC+BQzpm917nnrqqRx//PH1Q33HjRvHhAkT+NznPsc+++yzw0A0ceJEvv71rzNu3Dj22GMPDj744Ppj11xzDVOmTGHw4MFMmTKlPpSecsopnHPOOdxyyy31xZEA+vTpw7333stJJ51EdXU1Bx98MOeee25Gr2fx4sUMHTq0fvuXv/wl119/PdOmTSPGyDHHHMPMmTN56aWXOPPMM+t7Nq+77jpqamr4xje+wcaNG4kxcuGFF7a5UjEkl8857bTTOOecczj55JMZPXo0w4cPZ0KGHW//+Z//yRtvvMHcuXOZO3cuAL/73e/YY4892tw2gBBjyxOfO1tJSUmsW8coX518Miz700Zefbc/rFwJqfHokiRJUlf26quvcuCBB+a6GepGmnpPhRCWxBhLmjrfIb5t0L8/bNySqlC1cWNO2yJJkiRJ3YUBtQ122w02fFKc3GhHmWdJkiRJ0jYG1Db4+GP4dGshT3KoPaiSJEmSlCUG1AyVl8O99yaff4nHKP/PJcmdkiRJUjeQbzVq1HW15b1kQM1QWRnUpBYgrqIXZU8EmD7dkCpJkqQur0+fPqxfv96QqnaLMbJ+/Xr6ZLjiicvMZKi0FIqKoLISiqimlMeTG2VlkEjkunmSJElSmw0dOpQ1a9bwwQcf5Lop6gb69OnTYHmd1jCgZiiRgFtvhXPOgWv5HonwHPTqk0yukiRJUhdWXFzM8OHDc90M9WAO8W2DI45IPu45oBrGjoXFi+09lSRJkqR2MqC2we67Jx8/3OWzsPfehlNJkiRJygIDahv07598/LB4T/joo5y2RZIkSZK6i1YF1BDC0SGElSGEN0II323i+E0hhKWpr7+EEDakHatJO7Ywi23PmcLCZEj9sHAQfPhhrpsjSZIkSd3CDoskhRAKgVuBLwJrgOdDCAtjjCvqzokxXpJ2/gXAhLRbfBpjHJ+1FueJ3XeHDxloD6okSZIkZUlrelAnA2/EGFfFGCuBecDMFs4/FXgwG43LZ716wfPrh1P+4QHgOlGSJEmS1G6tCahDgHfSttek9m0nhLAvMBz4Y9ruPiGEihDCsyGE45q5bk7qnIqusOZSeTn85S/wlw8HMb32d5T/R0WumyRJkiRJXV62iySdAvwqxliTtm/fGGMJcBpwcwhhv8YXxRjvjDGWxBhLBg8enOUmZV9ZGdTWRiBQSTFl/7gwmVolSZIkSW3WmoC6FtgnbXtoal9TTqHR8N4Y49rU4yqgjIbzU7uk0lIoKohApBdVlNY+nkytkiRJkqQ2a01AfR4YGUIYHkLoRTKEbleNN4TwOWAAUJ62b0AIoXfq+SBgKrCi8bVdTSIB3zh6HYHI7/kCieKKZGqVJEmSJLXZDgNqjLEaOB94DHgVmB9jXB5CmBtCmJF26inAvBgbVAw6EKgIIbwEPA5cn179tysb+4U9iBRwECvghz9MplZJkiRJUpvtcJkZgBjjI8Ajjfb9sNH21U1c9wwwph3ty1u77558/JDd6d8F5s1KkiRJUr7LdpGkHiM9oLoWqiRJkiS1nwG1jeoDauEe8OGHuW2MJEmSJHUDBtQ2qg+ou+xjD6okSZIkZYEBtY3qAup/1Xyd8jcG5bYxkiRJktQNGFDb6C9/ST7+z99Lmf74Dyi/c1luGyRJkiRJXZwBtY2efhogEimgMhZR9g+/hPLyHV0mSZIkSWqGAbWNSkshAIFaelFFae0foawsx62SJEmSpK7LgNpGiQSMGr6ZEaxiMdNJ9H4hmVolSZIkSW1iQG2H4Qf1pd/AXiR4Fh55JJlaJUmSJEltYkBth8GD4YOaVDnfkSNz2xhJkiRJ6uIMqO0weDCs+2QnIsC6dblujiRJkiR1aQbUdvjkE9haVchijjSgSpIkSVI7GVDbqLwc7ror+fyr/I8rzEiSJElSOxlQ26isDKqrk8+rKKbsv9a6DqokSZIktYMBtY1KS6G4OPm8kGpKX70dpk83pEqSJElSGxlQ2yiRgF/8Ivn8cn5EgnKorEx2rUqSJEmSMmZAbYejjko+7sYmCAF69Up2rUqSJEmSMmZAbYd+/ZKZdN3AA2C//WDx4mTXqiRJkiQpY0W5bkBXFkJyLdQPwmdh110Np5IkSZLUDvagttNOO0H5poMoX/vZXDdFkiRJkro0A2o7lJfDqlXw6sbPMP39ByzgK0mSJEntYEBth7IyqK0FCFRSTNnvKnPcIkmSJEnqugyo7VBaCkVFAJFeVFHa2y5USZIkSWorA2o7JBLwrWP/BgT+h2NIXP0lHOcrSZIkSW1jQG2nKYVLABjGX6GqKjnuV5IkSZKUMQNqO+15yH4AvM+eyfG+paW5bZAkSZIkdVEG1Hbaa9qBALzHXjBnjmuhSpIkSVIbGVDbac89k48/KziT8o8+l9vGSJIkSVIXZkBtpzffTD4urD2W6fO+ZY0kSZIkSWojA2o7Pf108jFSQGVNoTWSJEmSJKmNDKjtVFoKIQDUJtdCHbgsxy2SJEmSpK7JgNpOiQRMOmAT+7CGxRxJ4uIproUqSZIkSW1gQM2C/Xu/TRHVJHgWKitdC1WSJEmS2sCAmgV7HTiA99iLCNCrl2uhSpIkSVIbGFCzYMvun+FTdmYxR8J997kWqiRJkiS1gQG1ncrL4e67k8+/yv9Q/uEBuW2QJEmSJHVRBtR2KiuD6urk80qKKXu6MKftkSRJkqSuyoDaTqWlyWmnAEXUUPr2z63iK0mSJEltYEBtp0QCFi5MPj+HO0k8/a8wfbohVZIkSZIyZEDNgi98Afr2qqSYaojRpWYkSZIkqQ0MqFkQAgzZq4a1DEnucKkZSZIkScqYATVLdhm0E88VH0b54BmweLFLzUiSJElShopy3YDuoLwcXnoJamr2Yvq6eSxmJ4ynkiRJkpSZVvWghhCODiGsDCG8EUL4bhPHbwohLE19/SWEsCHt2BkhhNdTX2dkse15o6wMamsBApWxiLLHY45bJEmSJEldzw57UEMIhcCtwBeBNcDzIYSFMcYVdefEGC9JO/8CYELq+e7AVUAJEIElqWs/yuqryLHSUigqgqoqKKaa0j4VYB+qJEmSJGWkNT2ok4E3YoyrYoyVwDxgZgvnnwo8mHr+JeD3McYPU6H098DR7WlwPkokYO7ZfwXgNs4j8f0jXWZGkiRJkjLUmoA6BHgnbXtNat92Qgj7AsOBP2Z6bVd3ZHgcgIGsd5kZSZIkSWqDbFfxPQX4VYyxJpOLQghzQggVIYSKDz74IMtN6hxDjh4DwE85i/KCqS4zI0mSJEkZak1AXQvsk7Y9NLWvKaewbXhvq6+NMd4ZYyyJMZYMHjy4FU3KP6sGTAIiC5nJ9PgHyp2DKkmSJEkZaU1AfR4YGUIYHkLoRTKELmx8Ugjhc8AAIH3y5WPAUSGEASGEAcBRqX3dztNPAwQiBVTWFjrCV5IkSZIytMMqvjHG6hDC+SSDZSFwT4xxeQhhLlARY6wLq6cA82KMMe3aD0MI15AMuQBzY4wfZvcl5IfSUigogNraWnoVVFNaWpjrJkmSJElSlxLS8mReKCkpiRUVFbluRpsccQS89sx6Fgw6h8R/X5Ys7ytJkiRJqhdCWBJjLGnqWLaLJPVoY/f4G1urC0m89xBMn+5SM5IkSZKUAQNqFlW/8y4b6c8fKXWpGUmSJEnKkAE1S8rL4Z4lEwA4hkcoLzzUpWYkSZIkKQMG1CwpK4Pq2uSPs5Jiymb8m3NQJUmSJCkDBtQsKS2FXr2SzwupoXTypzltjyRJkiR1NQbULEkk4He/gxAi3+ABEk//q0WSJEmSJCkDBtQsOuww2GePrVRTBIsWWclXkiRJkjJgQM2y3cMGnuIwyuMUK/lKkiRJUgYMqFlUXg7L/ndPVjOM6Sy2kq8kSZIkZcCAmkVlZVAbAxCSlXzP+pmVfCVJkiSplQyoWVRaCkVFyefFVFP6zc/mtD2SJEmS1JUYULMokYB///fk8x9xGYlH/skiSZIkSZLUSgbULDvmmORjGaWU/9/HreQrSZIkSa1kQM2yNWsAIg9xAtPj7ynfOtFKvpIkSZLUCgbULHv66eRjpCBZKKngSCv5SpIkSVIrFOW6Ad1NaSkUFEBtbS29CmoovfUkSIzJdbMkSZIkKe/Zg5pliQR86UuB3cLfWTz9OhJzDKeSJEmS1BoG1A5w8MGwKfZl0l8etECSJEmSJLWSAbUDDKt+g1oK+f5fz6G89EpDqiRJkiS1ggG1A3zy8psA/DvfYXrlI5Tf/3qOWyRJkiRJ+c+A2gHe6T8agFoKk5V8OSLHLZIkSZKk/GdA7QAzzh0CRAI19CqG0ln75rpJkiRJkpT3DKgdYOpU2HtwDYNYx82nPkcikesWSZIkSVL+M6B2gPJyeH99IR+wBxf/ooTyO5flukmSJEmSlPcMqB2grAxiLUCgsraQsn/4pZV8JUmSJGkHDKgdoLQUigprASimmtLaPyZTqyRJkiSpWQbUDpBIwE0X/RWA67mCRO8XkqlVkiRJktQsA2oHOe47IwD4I9Mp/9FTWClJkiRJklpmQO0gf/0rQGQRX2X6JWMslCRJkiRJO2BA7SBPPJF8jBRQWR0slCRJkiRJO2BA7SClpVAYIhDpRZWFkiRJkiRpBwyoHSSRgNOOWkcBtTzGlyyUJEmSJEk7YEDtQEectAe1FPKb3c+k/ObnLJQkSZIkSS0woHagysrk400fnsH0C0c5BVWSJEmSWmBA7UBrn1sDQC2FVG6tpez+v+a4RZIkSZKUvwyoHeiYnf4IRAK1yUJJPJHrJkmSJElS3jKgdqDErJHsz1/ox8fcXHgpiVkjc90kSZIkScpbBtQOVE6CVQUj+ZjduDj+O+XLdsl1kyRJkiQpbxlQO1BZGdTEAAQqa4so+4dfYqUkSZIkSWqaAbUDlZZCr4IaAIqoprT2j8nUKkmSJEnajgG1AyUS8NCP/gLARJZAUVEytUqSJEmStmNA7WD9E6OAyLMkmB4WU04i102SJEmSpLxkQO1gdSN6IwVUVuJaqJIkSZLUDANqBysthaKCCER6xa2U3nOGhZIkSZIkqQmtCqghhKNDCCtDCG+EEL7bzDknhxBWhBCWhxD+K21/TQhhaeprYbYa3lUkEnDx5D8BgRP5FVRXWyhJkiRJkppQtKMTQgiFwK3AF4E1wPMhhIUxxhVp54wErgSmxhg/CiHskXaLT2OM47Pb7K5l+NTPwLPwX5zOr2u/xuKBbzoTVZIkSZIaaU0P6mTgjRjjqhhjJTAPmNnonHOAW2OMHwHEGP83u83s2t7beT8AaimksqAPZevH5LhFkiRJkpR/WhNQhwDvpG2vSe1Ltz+wfwjhTyGEZ0MIR6cd6xNCqEjtP659ze2avjx0GVAL1FJYW0npwGW5bpIkSZIk5Z0dDvHN4D4jgVJgKPBkCGFMjHEDsG+McW0IYQTwxxDCshjjm+kXhxDmAHMAPvvZz2apSXnkxRcpYBS1FBBS22AvqiRJkiSla00P6lpgn7Ttoal96dYAC2OMVTHGt4C/kAysxBjXph5XAWXAhMbfIMZ4Z4yxJMZYMnjw4IxfRL4r4wgiAQhUU0gZR+S6SZIkSZKUd1oTUJ8HRoYQhocQegGnAI2r8S4g2XtKCGEQySG/q0IIA0IIvdP2TwVW0MOUztqX4qIIQFGIlE74OMctkiRJkqT8s8OAGmOsBs4HHgNeBebHGJeHEOaGEGakTnsMWB9CWAE8DlwWY1wPHAhUhBBeSu2/Pr36b0+RSMD8a1YCcHB8Di64wLVQJUmSJKmRVs1BjTE+AjzSaN8P055H4Dupr/RznsHJlgAMXl0BHMifmMr0ykdYfP+vSCRcbEaSJEmS6rRmiK+y4IlwBBCJFFBJsfNQJUmSJKkRA2onKZ21L0UhApEQAgN3rc51kyRJkiQprxhQO0kiAWdMXg4EamPg4h/tTfmdrocqSZIkSXUMqJ1o15oNANRSmBzm++v1uW2QJEmSJOURA2onOvHs/kAkUEsvqig9cWCumyRJkiRJecOA2ommnjuWzxW9wS78nZtPf57EHAscS5IkSVIdA2onKr9zGW9UD2MT/bj4gYOdgypJkiRJaQyonajs1+uppQAIbKWXc1AlSZIkKY0BtROVnjiQXlTWbw8cv08OWyNJkiRJ+cWA2okSc8bw44vfAiK1FHLxj4dRXp7rVkmSJElSfjCgdrL1W/oCEQhUbq2l7P6/5rpJkiRJkpQXDKidrJQnKKYagAAMfG95bhskSZIkSXnCgNrJErNGclG4BYAaCrj44aMc5itJkiRJGFA7XyLBLpNHAZFIIZVV0WG+kiRJkoQBNSeOOuBtArVALYXUUMoTuW6SJEmSJOWcATUXpk6lIFUoKQBMmJDjBkmSJElS7hlQc6Bs/RgiAQhUhV6UrR+T6yZJkiRJUs4ZUHOgdOAyerMViBAjAze8mesmSZIkSVLOGVBzILH+f7iZi4FILQVcfNNnreQrSZIkqcczoOZCaSnri/ZMzj8lsKW6kPvvz3GbJEmSJCnHDKi5kEhQ+p1JFFINQIyBe39aay+qJEmSpB7NgJojif6vcioPprYC1dWRsrJctkiSJEmScsuAmiulpZxXeDfUrYdaECktzXGbJEmSJCmHDKi5kkjAySdTSC0QCDXVsGxZrlslSZIkSTljQM2hsvcP3LYeKkWU/Xp9rpskSZIkSTljQM2h0q/vuW09VAIDx++T6yZJkiRJUs4YUHMoMebv3MzFhLr1UH88zEq+kiRJknosA2oulZWxnkGpjcCWrcH1UCVJkiT1WAbUXCotpbTXMxRRBUAkcO+92IsqSZIkqUcyoOZSIkHiP07jTO6jbh5qdZXroUqSJEnqmQyoubZ+PbO5j0AtECkMNa6HKkmSJKlHMqDmWmkpFBbVr4ea/JIkSZKknseAmmuJBGWH/oDaVDCtqgnc/6O/5bhRkiRJktT5DKh5oHT/dymiGojJQkmLBlsoSZIkSVKPY0DNA4kzP8dZ3JvaClTWFrrcjCRJkqQex4CaJ2YVPEAxlQDEiMvNSJIkSepxDKj5oKyMBOWcyb3ULTdTVYXLzUiSJEnqUQyo+aC0FHr3ZhJLUjsitbUwcGAuGyVJkiRJncuAmg8SCbj5ZtYzOLUeaiAQefHFXDdMkiRJkjqPATVfrF9PKWUUU0Wymq/zUCVJkiT1LAbUfFFaSqK4omE138poNV9JkiRJPYYBNV8kEnDmmczifoqoAqzmK0mSJKlnMaDmk9mzSYTnmM19WM1XkiRJUk9jQM03hYUczPOpDav5SpIkSeo5WhVQQwhHhxBWhhDeCCF8t5lzTg4hrAghLA8h/Ffa/jNCCK+nvs7IVsO7pbIyqK1lPYO2VfMNWM1XkiRJUo+ww4AaQigEbgW+DIwCTg0hjGp0zkjgSmBqjPEg4OLU/t2Bq4ApwGTgqhDCgGy+gG6ltBSKihpW843ReaiSJEmSeoTW9KBOBt6IMa6KMVYC84CZjc45B7g1xvgRQIzxf1P7vwT8Psb4YerY74Gjs9P0biiRgLPOIsGzjar5YjVfSZIkSd1eawLqEOCdtO01qX3p9gf2DyH8KYTwbAjh6AyuVbpZs6BXL2ZxP8VUAlbzlSRJktQzZKtIUhEwEigFTgXuCiH0b+3FIYQ5IYSKEELFBx98kKUmdVGJBPzbv5HgWc7kXpLVfLGaryRJkqRurzUBdS2wT9r20NS+dGuAhTHGqhjjW8BfSAbW1lxLjPHOGGNJjLFk8ODBmbS/e9q0CYBJLEntsJqvJEmSpO6vNQH1eWBkCGF4CKEXcAqwsNE5C0j2nhJCGERyyO8q4DHgqBDCgFRxpKNS+9SSVBJdzyAKUtV8wWq+kiRJkrq3HQbUGGM1cD7JYPkqMD/GuDyEMDeEMCN12mPA+hDCCuBx4LIY4/oY44fANSRD7vPA3NQ+tWT9eigooJQyilLVfMF5qJIkSZK6txBjzHUbGigpKYkVFRW5bkZulZcnl5yprOQ8fsLtfBsoIAT49rfhttty3UBJkiRJapsQwpIYY0lTx7JVJEnZlFpuBmAW99OLSpJrosJPf2ovqiRJkqTuyYCar2bNguJiEjzLV3ikfndVlWuiSpIkSeqeDKj5KpGAM88EYC/eb3Dovfdy0SBJkiRJ6lgG1Hw2aRKQHOZbnBrmC7BoEdx5Zw7bJUmSJEkdwICaz9avhxBI8Cxnc0/97poaOP9856JKkiRJ6l4MqPmstBSKi4FkL2r6kjPV1c5FlSRJktS9GFDzWVo13wTPcmu4gJAKqFb0lSRJktTdGFDz3axZ0KsXAHMKfsqXDnqn/pAVfSVJkiR1JwbUfJdIwL/9W/J5TQ3DXnuMumG+YEVfSZIkSd2HAbUr2LSp/ums2p9RVFBTv21FX0mSJEndhQG1Kxg4sP5pIj7Dt8Y8X79tRV9JkiRJ3YUBtStILTdTZ9Yrl1NYWFu/XV0NZWU5aJckSZIkZZEBtSsoLYXCwvrNRO2f+Mcxv6vfjhE2bOj8ZkmSJElSNhlQu4JEAm69FQpS/7lipP+yP5FeLOnGG52LKkmSJKlrM6B2FXPmwDnn1G+W1iymKGwrllRb61xUSZIkSV2bAbUrOeOM+qG+Ccq5teBCCoJzUSVJkiR1DwbUriSRgBNOqN+cE+/g0sOerd92LqokSZKkrsyA2tV84QvbntfW0n/3ovQCv85FlSRJktRlGVC7mvQlZ0KglLL0Ar/U1sL/+T/ORZUkSZLU9RhQu5rSUiguTj6PkcSi73Hr159o0ItaUwP335+T1kmSJElSmxlQu5pEAs46a9t2TQ1z5n+RmYetb3Dae+91crskSZIkqZ0MqF3RrFk0GNdbXc3lox6u71gFWLTIuaiSJEmSuhYDaleUSMA//uO27RhJTNjC2Wdv21VT41xUSZIkSV2LAbWr6t+/QbEkXnxxu47Vmhr40Y9y0jpJkiRJypgBtatqVCyJu+4isexOvvrVhqf95jcO9ZUkSZLUNRhQu6omiiVx/vlc/uVlDXpRY3SoryRJkqSuwYDalTVRLCmx/n/4yU/YbtkZh/pKkiRJyncG1K6siWJJDBzInDkwc2bDUx3qK0mSJCnfGVC7uvRiSQAvvgjA5ZfjUF9JkiRJXYoBtatLL5YEcNddcOedJBI41FeSJElSl2JA7eqaKpaU6ip1qK8kSZKkrsSA2h00tQDq/fcDDvWVJEmS1HUYULuDRILtFkB97736Qw71lSRJktQVGFC7i8svbzgXddGi+rG8TQ31XbAArrii85onSZIkSTtiQO0uEgk4++xt2zU1cP759WN5Gw/1hWQvqiFVkiRJUr4woHYns2ZBUdG27epqKCsDmh7qC/Cv/2rRJEmSJEn5wYDanSQS8J3vbNuOETZsqN+cMwcuu6zhJRZNkiRJkpQvDKjdTf/+DbtJb7yxQRfpDTckh/ums2iSJEmSpHxgQO1uSksbTjatrW0wFxWSIfW44xpetmABHH+8PamSJEmScseA2t0kEnDrrVCQ9p82bS5qnaaKJi1YAEccYUiVJEmSlBsG1O5ozhy49NJt243mosK2okkFjd4BVVXwrW8ZUiVJkiR1PgNqd7WDuaiQzLG33bZ9Zd8VK+xJlSRJktT5DKjdVVNzUZso1ztnDtx++/YhtarKwkmSJEmSOpcBtbuqm4uanjxrauD++7c7tbmQumABXHFFxzZTkiRJkuq0KqCGEI4OIawMIbwRQvhuE8dnhxA+CCEsTX19K+1YTdr+hdlsvHZgzhyYObPhvvfea/bUpkLqj37kcF9JkiRJnWOHATWEUAjcCnwZGAWcGkIY1cSp/y/GOD71dXfa/k/T9s/ITrPVapdfDsXF27YXLdpuLmqd5kLqk08aUiVJkiR1vNb0oE4G3ogxrooxVgLzgJk7uEb5IpGAs8/etl1T0+Rc1Dpz5sBll22/3+q+kiRJkjpaawLqEOCdtO01qX2NnRhCeDmE8KsQwj5p+/uEECpCCM+GEI5rR1vVVrNmNSyYVFPTYgWkG25Idrw2ZnVfSZIkSR0pW0WSFgHDYoxjgd8DP0s7tm+MsQQ4Dbg5hLBf44tDCHNSIbbigw8+yFKTVC+RgK9+teG+3/ym2aG+kAypd9zRdHVfe1IlSZIkdYTWBNS1QHqP6NDUvnoxxvUxxq2pzbuBSWnH1qYeVwFlwITG3yDGeGeMsSTGWDJ48OCMXoBa6fLLG/aixtjiUF9ofk7qihVw6KEt5ltJkiRJylhrAurzwMgQwvAQQi/gFKBBNd4Qwt5pmzOAV1P7B4QQeqeeDwKmAiuy0XBlKJGAn/xk+2VndrDYaXMhtbYWvv1tl6GRJEmSlD07DKgxxmrgfOAxksFzfoxxeQhhbgihrirvhSGE5SGEl4ALgdmp/QcCFan9jwPXxxgNqLnS1LIzOxjqW3dZUyEVXIZGkiRJUvaEGGOu29BASUlJrKioyHUzuq/ycjjssGTvaZ3CQnjqqWQvawvuvBPOOy/Ze9pYQQHcdlsyzEqSJElSc0IIS1J1iraTrSJJ6iraONQXkuHz6afh8MO3P+aQX0mSJEntZUDtido41BeS+faJJ5pehgYc8itJkiSp7QyoPVVTVX3PO6/VpXnrlqEpaOId9OSTVvmVJEmSlDkDak9VN9Q3PWHW1u5w6Zl0DvmVJEmSlE0G1J5szpxkZaN0rZyPWschv5IkSZKyxYDa082ZA8cd13BfK+ejptvRkN9DDjGoSpIkSWqZAVVNz0fNYKhvnZaG/EIyqE6d6rBfSZIkSU0zoGrbfNR0GQ71Tb9V3ZDf9JVs6sSYvO3w4RZRkiRJktSQAVVJWRrqW+eGG+BPf2q+N3X16mQRJYf9SpIkSapjQNU2WRrqW6euN/WOO2DffZs+p27Y7/HHG1QlSZKkns6Aqm3qhvqmj81t41DfdHPmJHtMm6v0GyMsWGBQlSRJkno6A6oamjMHZs5suG/BgqxUNrrhBnjmmeaH/RpUJUmSpJ7NgKrtNR7qC8le1CyE1PRhv00tSQMGVUmSJKmnMqBqe00N9QX413/NWunduiVpjjuu6Wq/sC2oHnIIHHSQVX8lSZKk7s6AqqbNmQOXXdZwXzuLJjWWSMBDDyWr/bYUVAFWrEhW/XV5GkmSJKn7MqCqeTfcsH1loywUTWosk6BatzzN/vvDlCmGVUmSJKk7MaCqZTfcsP36qFkqmtRYJkH19dfhz39OhtW993auqiRJktQdGFC1Yx1YNKkp6UH13HNh/PiWz3/vvW1zVe1ZlSRJkrquEGPMdRsaKCkpiRUVFbluhhq7885kWkx/v4QAt9+enK/awcrL4bvfhaeeatiEluy1VzKwjhoFs2Ylg68kSZKk3AohLIkxljR5zICqVrviiu3nn3ZiSIVkUL3/fnj2WVi6NLNrhw1L9sZefrlhVZIkScoVA6qyJw9Cap3y8mRTnn02Ocw3EyNHQlERHHCAgVWSJEnqTAZUZdfxxycnfaYrLEyOv81R0rvzTvjpT+Gjj5IFlDJlYJUkSZI6hwFV2VVeDkccAVVVDfePGgV3353zdFfXs/rii/D2262fs5pu2DDo3x+2bjW0SpIkSdlkQFX2lZfDt74FK1Y03F9cDE88kTdprm7O6ooV8Je/ZD4UOF1dL+vgwRZekiRJktrKgKqOUV4Ohx0GNTUN9+dJT2pT6oYCV1Ymw2p7AivY0ypJkiRlyoCqjtPU8jOQdz2pzUkPrB99BH/9a9vvNeLgWkpm1lJyaKT/YCgIUBth9z6Bz+9ZwJC+LjssSZIkGVDVsZoLqXnck9qcuvmrK1dC796t72X97NhazrmrhqLi5I8hQOp/tulXDH0Kk6G1LrzuVASDdgqM2d0AK0mSpJ6hpYBa1NmNUTdUt7xM45C6YkWymFIX6Emtk0jAQw813Ne4l7WpwkvDJ0UKCpPPQ6NgWmdTVfKrga2w5pPI0nU17FpcQ28DrCRJknowe1CVPd2oJ7Ul6YWXPvgg2dPaa49ajv3nGop6Jc9pqge1vXYtZrsA6/BhSZIkdTUO8VXnaS6kFhbCT36yrbe1G/rts7W8+H4tu30mUtw3GSK31sDHjXtNO0BTw4cLAhQVwLiBBYwfVNjxjZAkSZJawSG+6jzNDfetqUnuSz+nmzn68wUczfY9mWs/qeXZ92r4cGvD8JjN8Nrk8OGUv22u5cl3a+lbBLU0bIPDiCVJkpRPDKjKvroA+n/+T8MlaGKEb38b3nwTbrghN23LgSF9Czhxv6aD39pPalm2vpZ1WyKfVndcgN1ck/xqUto82H7FNexWDAS2a49hVpIkSR3NgKqOMWcOjBkD3/pWcrJmuh/9KPnYg0Jqc4b0bTnodVaArdNSTyywXZjtU9B0r2zjR+fKSpIkqTUMqOo4iUSyONIRR0BVo9RjSG2V1gTYpoYP10aoibChsuPatqkKNrXy3PVbI69vrGFgrxp6F8GWaigMrQu3zT3amytJkrRNXcfGJ9WRvsVd928kiySp45WXw3e/C08+uf2xww+H66/vNhV+801LAbYzizh1tN17JcNuYeq1FQaItD38podgaHq4c1OPFqWSJKlpO/qbJJu/j3N1z2zcO7Btuyb1N01NhD6pe26pTp0DFKQeA8m/6RpP5yoMcNrIwrwMqVbxVX644optPafpiou71Fqp3U3jYcTNfah2lzDbGfoUJr9i6mcX2fZLpE9hcq3cul7kul8+dcG6vb3K0PV/gRv0JXVHLU3byZfP31Y9AjWkfq+lBamdipK/75oKUDW1sKm683/mgiP2LiCxV/79PrWKr/JD3XDexiG1qio5V7UbrZXalexoGHG6TH+5FgT4pKqFAk3d1Jaa5Fen29pF7tmKe/9tcy1la2vpU5QW3psI/AU07C1P/6OrsIn3Y3t61rvLPwDk2z1tr+3tzACV/vlQk3ZNCMl/VGwcrNIfaxp9r5q0x96pX6Nbaxtdm7p3dW0bfhfm6PO3rT7qwGlFapvCAJ/tF3LdjIzZg6rO11xPakEB3HZbt12Gpidbuq6Gl9bXUpj6jGzvHzP25kqSJDVv5G75XaDSHlTllxtugP32236t1NraHrkMTU8wflBh1odrphcC+LQ69/+C39FFqSRJ6g52LoS+xbnvrc/bEQDtuGd3KSBpQFVu1PWSNg6pkOxdffZZiyepRZkMTe4srSkA0R1/IWbz3gZ9ST3BrsXQuzC/Pn87+p7WF1BrGVCVO3Uh9bzzkr2n6Z58Eg491CG/6lKG9C3gxP3yKzR3RflW6bE7/QNAPt7T9trentLe7tK7JXU0A6pya84cGDOm6WVoHPIr9UgGfUmSei7/AlDuJRLJZWYuv7zp4z/6ERxxRHI9VUmSJEndlgFV+eOGG+COO6Cgibdl3ZDfO+/s/HZJkiRJ6hStCqghhKNDCCtDCG+EEL7bxPHZIYQPQghLU1/fSjt2Rgjh9dTXGdlsvLqhOXPg6afh8MO3P1Y35PeKKzq/XZIkSZI63A4DagihELgV+DIwCjg1hDCqiVP/X4xxfOrr7tS1uwNXAVOAycBVIYQBWWu9uieH/EqSJEk9Umt6UCcDb8QYV8UYK4F5wMxW3v9LwO9jjB/GGD8Cfg8c3bamqsfZ0ZDfqVPtTZUkSZK6kdYE1CHAO2nba1L7GjsxhPByCOFXIYR9MrxWalpLQ35jtDdVkiRJ6kayVSRpETAsxjiWZC/pzzK5OIQwJ4RQEUKo+OCDD7LUJHUb6UN+Q9j+eF1v6vHHG1QlSZKkLqw1AXUtsE/a9tDUvnoxxvUxxq2pzbuBSa29NnX9nTHGkhhjyeDBg1vbdvU0N9wAf/pT872pCxZY6VeSJEnqwloTUJ8HRoYQhocQegGnAAvTTwgh7J22OQN4NfX8MeCoEMKAVHGko1L7pLbZUQGlukq/DvuVJEmSupwdBtQYYzVwPslg+SowP8a4PIQwN4QwI3XahSGE5SGEl4ALgdmpaz8EriEZcp8H5qb2Se3TUgElsIiSJEmS1AWFGGOu29BASUlJrKioyHUz1FWUlycLJf3mN8lhvk0ZNgyuvDJZcEmSJElSToUQlsQYS5o6lq0iSVJuJBLw0EPNz00FWL06Oex3+HDnp0qSJEl5zICq7qFubuodd8C++zZ9Tl1QdX6qJEmSlJcMqOpe5sxJBtHmiiiBy9JIkiRJecqAqu7phhvgmWeaH/ZbtyyNQVWSJEnKGwZUdV91w34NqpIkSVKXYEBV95c+P7W5ZWkMqpIkSVLOGVDVc8yZA08/DccdByE0fU5dUD3kEIspSZIkSZ3MgKqeJX1ZmpaCKiSLKRlUJUmSpE5jQFXPZFCVJEmS8o4BVT1belA991wYP775cw2qkiRJUocyoEqQDKq33QYvvpgsprTvvs2fWxdUJ0yA884zrEqSJElZYkCVGpszB1av3nFQXboUbr/dyr+SJElSlhhQpea0NqjWVf494Sz4xtWw8MlOaqAkSZLUvRhQpR1pTVDd83Pw1Wuh3yR4+CO49BG4owJWfdSpTZUkSZK6MgOq1FrpQfXAAxtW/v3MGCgohlAABYWwuRZeeh9ufAaufRIeXGZYlSRJknbAgCplas4cWLGi4RI17y6DWJsc7hsCkBZe126Cp942rEqSJEk7EGKMuW5DAyUlJbGioiLXzZBar7wc7r8fNu4Gu01N9qK2xl67wJHD4dDPdmz7JEmSpDwSQlgSYyxp8pgBVcqiVR/B796Etz6CTZWtu6ZfLxgxAL64X/JRkiRJ6sZaCqhFnd0YqVsbMQDOTf1/7em34U9vwydVsG5z89dsqkzOV33pfRi0M+xSDId81p5VSZIk9TgGVKmjHJoWMp9+G/64Ct77pOVr1m2GdcDqZbBopT2rkiRJ6lEMqFJnqAurqz6CZ9ckhwCv3dTyNfasSpIkqYcxoEqdacSAbb2hmcxXbdyzumdf2LsfTBlq76okSZK6DQOqlCttma8KyTC7qRLe+Ci5fM2QflBcYO+qJEmSujwDqpQP0uerZloJuG6osL2rkiRJ6uIMqFK+aWvPKmzfu7r7TrDPrhZakiRJUpdgQJXyWVM9q2s2wodbWnf9h58mvyy0JEmSpC4gxBhz3YYGSkpKYkVFRa6bIeW3umrAm7Yme1Z3VBG4sX69HAosSZKknAghLIkxljR1zB5UqStKrwYMmfeuNjUUePc+BlZJkiTllAFV6g7S563W9a6+twne/6R1hZbqhgKnVwauqYU9d3H+qiRJkjqNAVXqbhr3rmZaaAm2DRl+75Nt81eLgoFVkiRJHcqAKnV37S20BNuCbePAuksvhwVLkiQpawyoUk/S3FDgDz9tW2Dlk4bzWHcqguICKwVLkiSpTQyoUk/VVKGlusrAn1S2fv5qnQ8/3fZ89TJYtBJ27e1cVkmSJLWaAVVSUuPACtvmr1bXwsdbMwusdZWCYdvQ4CH9kr2sf690eLAkSZK2Y0CV1LxDGw3VTQ+sn1ZlNiwYGq3X2sTwYHtbJUmSejQDqqTWaxxY0+ex/r0SqmPrKwWnSx8e3LgQU2GBwVWSJKmHMKBKarumhgXXVQr+378nw2WmQ4PrNA66zQVXhwpLkiR1GwZUSdmVXim4Tt3Q4OKC5HamVYPTbddDmzZU2PAqSZLUpRlQJXW8xkODYfvhwe3pba3TUnhNn+daWOByOJIkSXnIgCopN5oaHgwNCzHVhcn2BldoOM+1TuPlcOp6Xg2wkiRJOWFAlZRfmupthaaDa01t2wsz1UlfDqex1cuS82nThw1btEmSJKnDGFAldQ3NBVdoOry2ZRmcpjQXfuuLNu0ERQXbB1jnv0qSJGXMgCqp62suvDY1zzUbva7p1jUxdBhoMP+1f2/YuRfUpoIrNGyPYVaSJAkwoErqzpqb5wrbL4eTzWHDjW3YmvwC4JMmTkgLswP6wM7F28+JNchKkqQeoFUBNYRwNPBjoBC4O8Z4fTPnnQj8Cjg4xlgRQhgGvAqsTJ3ybIzx3Ha3WpLaq6nlcNI11/uaraJNzfloS/KrSTsIsum9s4ZZSZLUBe0woIYQCoFbgS8Ca4DnQwgLY4wrGp3XD7gIeK7RLd6MMY7PTnMlqZO01PsKzRdtyub815Y0GWQ/afi8Nb2yFn2SJEl5pDU9qJOBN2KMqwBCCPOAmcCKRuddA9wAXJbVFkpSPmqpaBM03wPbeA5qzsJsI3VFn3bfCYoDFBU23V5DrSRJ6kCtCahDgHfSttcAU9JPCCFMBPaJMT4cQmgcUIeHEF4EPgZ+EGN8qj0NlqQuYUc9sOlaGk7cmb2y0MR6sU3NmU2pD7V9kuvG1oXa5nppDbaSJGkH2l0kKYRQAPw7MLuJw38DPhtjXB9CmAQsCCEcFGP8uNE95gBzAD772RZ6JCSpO2ptmN1RkK3r7fzw084Js3Uy/V51wXavvsmhx5urdhxqCwuSIfiQHfRcS5KkLq01AXUtsE/a9tDUvjr9gNFAWQgBYC9gYQhhRoyxAtgKEGNcEkJ4E9gfqEj/BjHGO4E7AUpKSmLbXookdXPZ7pXtjKJPLXmvhd7Z5qxeBgtfg369IcbmQ7pDkiVJ6pJaE1CfB0aGEIaTDKanAKfVHYwxbgQG1W2HEMqAS1NVfAcDH8YYa0III4CRwKostl+S1JRMwiw0X/SpucCXq1AL8Peq5FeTWjMkudE829b03hpwJUnqFDsMqDHG6hDC+cBjJJeZuSfGuDyEMBeoiDEubOHyw4G5IYQqoBY4N8b4YTYaLknKoh0VfWpKS5WM8623Nt1282xbqS7g9u8NfYoh1mYWch2iLEnSDoUY82tEbUlJSayoqNjxiZKkrqku2BYXJLd3NAS5phaqI6zbnNt2Z8vORbBrL6ghOVQ5AJ+04meQ3qvtGreSpC4shLAkxtjkgvTtLpIkSVJG2tJbC8l5tb97E/737y2HN8ivIcmNba5OfgF80JbQnbbGbf/esFMx1DbRm9vSfFx7diVJecoeVElSz9CWIcmdvcxPLvUthn69oDYmw25tBv8AYA+vJCkD9qBKktTWnts6renB7cpDlD+pSn61fFJrbrSth3e33rBTUTL0Fu9gvu6Owq89vZLUI9iDKklSZ2gq4LZ2GG5P6sndkV2KYZferStSZeiVpLzUUg+qAVWSpK6ktWvctib8doWe3c7QmuHNrrkrSVnjEF9JkrqLTNe43ZFMhi7vKPR21R7eVg1v3u6i5g/Vr7nbGwoLk8Ob2xt67fGV1EMYUCVJ6slGDIBzm/xH7LZpbQ9vJuGsq/b0frg1wwtaMcd39TL4zWvbenx3NLfX8CupizGgSpKk7Ml2D2+dthSp6o6hF7Lf41tn9TJY8BrsWpxcp7eooOkljNo6h9rhz5JawYAqSZLyX7Z7eqF9lZm7wpq7bbG5KvnVKq2p6txI3fDn/r2TwbcoND33ty3h155hqVswoEqSpJ6pI0IvtH3N3e7a49uUDTsa/tyG8NucumHRg3ZObn9a1fpiWJn8t+vbC3bt7RrAUjsZUCVJkrKpvWvuNqcjeny7Y/htyidV8MnGjvwG256mrwFcE1tfJKs9Q6gdOq1uxIAqSZLUFXRUjy9kf45vU49dffhzJjZuTX61Swa9yHVDp3frlawcXRggxuQQ6moazieuzeIQ6h29H3bpBXv3s1dZGTGgSpIk9XQdGX7TtXb4czYCVE/oGW5sY2v/ASCLQ6hbvOcn8MZHyV7lfr2gTxFEUsE5bh+cO/L9sKN7Ol85bxhQJUmS1Dk6avhzc9J7hjsi5KQ/rt3Uea+rK9pU2Y4e9E4K1HWVrHcphlqSQbotw7Tb8l6zt7meAVWSJEndU2f1DEPb1wBub8jpSUOnO0NGlayb05ZA3ai3eaeihiG5X69t7evmYdeAKkmSJLVXR60B3BqZVo7ujCGzn1bBh1ty8/Po6prqbf4gk+HqqbBbvgYu/nyXC6kGVEmSJKkr6+yh062VrV7ljg7U3XW+cnUt/GW9AVWSJEmSctqrnKn2LOPU3kDdUb3NRQWw/8Ds37eDGVAlSZIk9WydOV+5KTvqbc4k9DoHVZIkSZLUZl2pt7mDFeS6AZIkSZIkgQFVkiRJkpQnDKiSJEmSpLxgQJUkSZIk5QUDqiRJkiQpLxhQJUmSJEl5wYAqSZIkScoLBlRJkiRJUl4woEqSJEmS8oIBVZIkSZKUFwyokiRJkqS8YECVJEmSJOUFA6okSZIkKS8YUCVJkiRJecGAKkmSJEnKCwZUSZIkSVJeCDHGXLehgRDCB8Bfc92OHRgErMt1I5SXfG+oJb4/1BzfG2qJ7w81x/eGmpPv7419Y4yDmzqQdwG1KwghVMQYS3LdDuUf3xtqie8PNcf3hlri+0PN8b2h5nTl94ZDfCVJkiRJecGAKkmSJEnKCwbUtrkz1w1Q3vK9oZb4/lBzfG+oJb4/1BzfG2pOl31vOAdVkiRJkpQX7EGVJEmSJOUFA2qGQghHhxBWhhDeCCF8N9ftUecKIewTQng8hLAihLA8hHBRav/uIYTfhxBeTz0OSO0PIYRbUu+Xl0MIE3P7CtTRQgiFIYQXQwj/k9oeHkJ4LvUe+H8hhF6p/b1T22+kjg/LacPV4UII/UMIvwohvBZCeDWEkPCzQwAhhEtSv1NeCSE8GELo42dHzxVCuCeE8L8hhFfS9mX8WRFCOCN1/ushhDNy8VqUXc28N/419Xvl5RDCQyGE/mnHrky9N1aGEL6Utj+v84wBNQMhhELgVuDLwCjg1BDCqNy2Sp2sGvjHGOMo4PPAP6TeA98FFscYRwKLU9uQfK+MTH3NAW7r/Cark10EvJq2fQNwU4zx/wM+As5O7T8b+Ci1/6bUeerefgz8Nsb4OWAcyfeJnx09XAhhCHAhUBJjHA0UAqfgZ0dPdh9wdKN9GX1WhBB2B64CpgCTgavqQq26tPvY/r3xe2B0jHEs8BfgSoDU36enAAelrvlJ6h/R8z7PGFAzMxl4I8a4KsZYCcwDZua4TepEMca/xRhfSD3fRPIPzCEk3wc/S532M+C41POZwP0x6Vmgfwhh785ttTpLCGEocAxwd2o7AEcCv0qd0vi9Ufee+RUwPXW+uqEQwm7A4cBPAWKMlTHGDfjZoaQiYKcQQhGwM/A3/OzosWKMTwIfNtqd6WfFl4Dfxxg/jDF+RDLENA426mKaem/EGH8XY6xObT4LDE09nwnMizFujTG+BbxBMsvkfZ4xoGZmCPBO2vaa1D71QKlhVROA54A9Y4x/Sx16D9gz9dz3TM9yM3A5UJvaHghsSPvFkf7fv/69kTq+MXW+uqfhwAfAvakh4HeHEPriZ0ePF2NcC9wIvE0ymG4EluBnhxrK9LPCz5Ce6Szg0dTzLvveMKBKbRBC2AX4NXBxjPHj9GMxWRrb8tg9TAjhWOB/Y4xLct0W5aUiYCJwW4xxAvAJ24boAX529FSpYZczSf4jxmeAvtjTpRb4WaGmhBC+T3Iq2gO5bkt7GVAzsxbYJ217aGqfepAQQjHJcPpAjPG/U7vfrxt+l3r839R+3zM9x1RgRghhNcnhMkeSnHPYPzVsDxr+969/b6SO7was78wGq1OtAdbEGJ9Lbf+KZGD1s0NfAN6KMX4QY6wC/pvk54mfHUqX6WeFnyE9SAhhNnAscHrctoZol31vGFAz8zwwMlVZrxfJiccLc9wmdaLUPJ+fAq/GGP897dBCoK5C3hnAb9L2z0pV2fs8sDFtiI66kRjjlTHGoTHGYSQ/G/4YYzwdeBz4Wuq0xu+NuvfM11Ln+y/i3VSM8T3gnRDCAald04EV+Nmh5NDez4cQdk79jql7b/jZoXSZflY8BhwVQhiQ6qU/KrVP3UwI4WiS04tmxBg3px1aCJySqvw9nGQhrT/TBfJM8DMtMyGEr5CcZ1YI3BNjvDa3LVJnCiEcCjwFLGPbPMPvkZyHOh/4LPBX4OQY44epPzb+k+Rwrc3AmTHGik5vuDpVCKEUuDTGeGwIYQTJHtXdgReBb8QYt4YQ+gA/JzmP+UPglBjjqhw1WZ0ghDCeZAGtXsAq4EyS/1DsZ0cPF0L4Z+DrJIfnvQh8i+ScMD87eqAQwoNAKTAIeJ9kNd4FZPhZEUI4i+TfKADXxhjv7cSXoQ7QzHvjSqA320ZSPBtjPDd1/vdJzkutJjkt7dHU/rzOMwZUSZIkSVJecIivJEmSJCkvGFAlSZIkSXnBgCpJkiRJygsGVEmSJElSXjCgSpIkSZLyggFVkiRJkpQXDKiSJEmSpLxgQJUkSZIk5YX/H9t6gKEtfHc/AAAAAElFTkSuQmCC"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise\n",
    "Now it's your turn.  Do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "model_2 = Sequential([\n",
    "    Dense(6, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(6,input_shape = (6,),activation='relu'),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 1s 15ms/step - loss: 0.6624 - accuracy: 0.6719 - val_loss: 0.6535 - val_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6605 - accuracy: 0.6771 - val_loss: 0.6516 - val_accuracy: 0.6719\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6587 - accuracy: 0.6840 - val_loss: 0.6497 - val_accuracy: 0.6771\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6568 - accuracy: 0.6840 - val_loss: 0.6479 - val_accuracy: 0.6719\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6550 - accuracy: 0.6840 - val_loss: 0.6461 - val_accuracy: 0.6719\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6533 - accuracy: 0.6840 - val_loss: 0.6442 - val_accuracy: 0.6667\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6515 - accuracy: 0.6858 - val_loss: 0.6424 - val_accuracy: 0.6667\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6498 - accuracy: 0.6875 - val_loss: 0.6406 - val_accuracy: 0.6667\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6481 - accuracy: 0.6875 - val_loss: 0.6388 - val_accuracy: 0.6667\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6463 - accuracy: 0.6892 - val_loss: 0.6370 - val_accuracy: 0.6771\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6447 - accuracy: 0.6927 - val_loss: 0.6352 - val_accuracy: 0.6771\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6430 - accuracy: 0.6927 - val_loss: 0.6335 - val_accuracy: 0.6771\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6413 - accuracy: 0.6927 - val_loss: 0.6317 - val_accuracy: 0.6875\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6397 - accuracy: 0.6910 - val_loss: 0.6300 - val_accuracy: 0.6875\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6381 - accuracy: 0.6927 - val_loss: 0.6283 - val_accuracy: 0.6875\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6364 - accuracy: 0.6962 - val_loss: 0.6267 - val_accuracy: 0.6823\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6348 - accuracy: 0.6962 - val_loss: 0.6251 - val_accuracy: 0.6823\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6332 - accuracy: 0.6944 - val_loss: 0.6235 - val_accuracy: 0.6823\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6317 - accuracy: 0.6962 - val_loss: 0.6219 - val_accuracy: 0.6875\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6301 - accuracy: 0.6979 - val_loss: 0.6203 - val_accuracy: 0.6875\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6286 - accuracy: 0.6979 - val_loss: 0.6187 - val_accuracy: 0.6875\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6271 - accuracy: 0.6979 - val_loss: 0.6172 - val_accuracy: 0.6875\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6256 - accuracy: 0.6979 - val_loss: 0.6156 - val_accuracy: 0.6875\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6241 - accuracy: 0.6979 - val_loss: 0.6141 - val_accuracy: 0.6875\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6226 - accuracy: 0.6997 - val_loss: 0.6126 - val_accuracy: 0.6979\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6211 - accuracy: 0.6979 - val_loss: 0.6111 - val_accuracy: 0.6979\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6196 - accuracy: 0.6997 - val_loss: 0.6095 - val_accuracy: 0.6979\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6181 - accuracy: 0.7014 - val_loss: 0.6079 - val_accuracy: 0.6979\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6167 - accuracy: 0.6997 - val_loss: 0.6064 - val_accuracy: 0.6979\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6152 - accuracy: 0.6997 - val_loss: 0.6049 - val_accuracy: 0.7031\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6138 - accuracy: 0.6979 - val_loss: 0.6034 - val_accuracy: 0.7031\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6123 - accuracy: 0.7014 - val_loss: 0.6019 - val_accuracy: 0.7031\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6110 - accuracy: 0.7031 - val_loss: 0.6004 - val_accuracy: 0.7031\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6095 - accuracy: 0.7066 - val_loss: 0.5990 - val_accuracy: 0.7031\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6081 - accuracy: 0.7066 - val_loss: 0.5976 - val_accuracy: 0.7031\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6068 - accuracy: 0.7066 - val_loss: 0.5962 - val_accuracy: 0.6979\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6054 - accuracy: 0.7083 - val_loss: 0.5948 - val_accuracy: 0.6979\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6041 - accuracy: 0.7083 - val_loss: 0.5934 - val_accuracy: 0.6979\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6028 - accuracy: 0.7101 - val_loss: 0.5921 - val_accuracy: 0.7031\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6015 - accuracy: 0.7101 - val_loss: 0.5908 - val_accuracy: 0.7031\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6001 - accuracy: 0.7101 - val_loss: 0.5895 - val_accuracy: 0.7031\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5988 - accuracy: 0.7101 - val_loss: 0.5882 - val_accuracy: 0.7031\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5975 - accuracy: 0.7101 - val_loss: 0.5870 - val_accuracy: 0.7031\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5962 - accuracy: 0.7101 - val_loss: 0.5857 - val_accuracy: 0.7031\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5948 - accuracy: 0.7101 - val_loss: 0.5845 - val_accuracy: 0.7031\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5934 - accuracy: 0.7101 - val_loss: 0.5833 - val_accuracy: 0.7031\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5920 - accuracy: 0.7101 - val_loss: 0.5820 - val_accuracy: 0.7031\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5907 - accuracy: 0.7101 - val_loss: 0.5809 - val_accuracy: 0.7031\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5894 - accuracy: 0.7101 - val_loss: 0.5797 - val_accuracy: 0.7031\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5880 - accuracy: 0.7118 - val_loss: 0.5785 - val_accuracy: 0.7031\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5866 - accuracy: 0.7101 - val_loss: 0.5774 - val_accuracy: 0.7031\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5852 - accuracy: 0.7118 - val_loss: 0.5762 - val_accuracy: 0.7031\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5838 - accuracy: 0.7118 - val_loss: 0.5751 - val_accuracy: 0.7083\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5825 - accuracy: 0.7101 - val_loss: 0.5739 - val_accuracy: 0.7031\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5811 - accuracy: 0.7118 - val_loss: 0.5728 - val_accuracy: 0.7031\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5797 - accuracy: 0.7101 - val_loss: 0.5717 - val_accuracy: 0.7083\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5784 - accuracy: 0.7118 - val_loss: 0.5706 - val_accuracy: 0.7083\n",
      "Epoch 58/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5772 - accuracy: 0.7118 - val_loss: 0.5695 - val_accuracy: 0.7083\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5758 - accuracy: 0.7118 - val_loss: 0.5684 - val_accuracy: 0.7083\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5745 - accuracy: 0.7118 - val_loss: 0.5674 - val_accuracy: 0.7083\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5733 - accuracy: 0.7135 - val_loss: 0.5663 - val_accuracy: 0.7083\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5722 - accuracy: 0.7135 - val_loss: 0.5653 - val_accuracy: 0.7083\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5710 - accuracy: 0.7135 - val_loss: 0.5642 - val_accuracy: 0.7083\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5699 - accuracy: 0.7135 - val_loss: 0.5632 - val_accuracy: 0.7083\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5688 - accuracy: 0.7135 - val_loss: 0.5622 - val_accuracy: 0.7083\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5676 - accuracy: 0.7135 - val_loss: 0.5612 - val_accuracy: 0.7083\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5666 - accuracy: 0.7118 - val_loss: 0.5602 - val_accuracy: 0.7083\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5654 - accuracy: 0.7118 - val_loss: 0.5592 - val_accuracy: 0.7083\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5645 - accuracy: 0.7135 - val_loss: 0.5583 - val_accuracy: 0.7083\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5633 - accuracy: 0.7135 - val_loss: 0.5574 - val_accuracy: 0.7031\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5622 - accuracy: 0.7135 - val_loss: 0.5565 - val_accuracy: 0.7031\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5611 - accuracy: 0.7153 - val_loss: 0.5556 - val_accuracy: 0.7031\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5601 - accuracy: 0.7135 - val_loss: 0.5548 - val_accuracy: 0.7031\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5590 - accuracy: 0.7135 - val_loss: 0.5539 - val_accuracy: 0.7031\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5579 - accuracy: 0.7170 - val_loss: 0.5531 - val_accuracy: 0.7135\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5569 - accuracy: 0.7153 - val_loss: 0.5523 - val_accuracy: 0.7135\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5559 - accuracy: 0.7170 - val_loss: 0.5515 - val_accuracy: 0.7135\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5548 - accuracy: 0.7170 - val_loss: 0.5507 - val_accuracy: 0.7135\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5539 - accuracy: 0.7153 - val_loss: 0.5499 - val_accuracy: 0.7135\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5529 - accuracy: 0.7153 - val_loss: 0.5491 - val_accuracy: 0.7135\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5519 - accuracy: 0.7153 - val_loss: 0.5484 - val_accuracy: 0.7135\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5508 - accuracy: 0.7153 - val_loss: 0.5476 - val_accuracy: 0.7135\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5498 - accuracy: 0.7170 - val_loss: 0.5469 - val_accuracy: 0.7135\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5489 - accuracy: 0.7170 - val_loss: 0.5461 - val_accuracy: 0.7135\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5479 - accuracy: 0.7170 - val_loss: 0.5455 - val_accuracy: 0.7135\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5470 - accuracy: 0.7170 - val_loss: 0.5448 - val_accuracy: 0.7135\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5461 - accuracy: 0.7188 - val_loss: 0.5442 - val_accuracy: 0.7135\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5451 - accuracy: 0.7170 - val_loss: 0.5435 - val_accuracy: 0.7135\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5443 - accuracy: 0.7188 - val_loss: 0.5429 - val_accuracy: 0.7135\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5434 - accuracy: 0.7188 - val_loss: 0.5423 - val_accuracy: 0.7135\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5425 - accuracy: 0.7188 - val_loss: 0.5417 - val_accuracy: 0.7188\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7205 - val_loss: 0.5412 - val_accuracy: 0.7188\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5408 - accuracy: 0.7205 - val_loss: 0.5406 - val_accuracy: 0.7188\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5401 - accuracy: 0.7240 - val_loss: 0.5401 - val_accuracy: 0.7188\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5393 - accuracy: 0.7240 - val_loss: 0.5396 - val_accuracy: 0.7188\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5385 - accuracy: 0.7240 - val_loss: 0.5391 - val_accuracy: 0.7188\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5378 - accuracy: 0.7257 - val_loss: 0.5386 - val_accuracy: 0.7188\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5370 - accuracy: 0.7257 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5363 - accuracy: 0.7257 - val_loss: 0.5377 - val_accuracy: 0.7188\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5356 - accuracy: 0.7257 - val_loss: 0.5372 - val_accuracy: 0.7188\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5349 - accuracy: 0.7257 - val_loss: 0.5368 - val_accuracy: 0.7188\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.7257 - val_loss: 0.5363 - val_accuracy: 0.7188\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5334 - accuracy: 0.7257 - val_loss: 0.5359 - val_accuracy: 0.7188\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.7257 - val_loss: 0.5355 - val_accuracy: 0.7135\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5320 - accuracy: 0.7257 - val_loss: 0.5351 - val_accuracy: 0.7188\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5314 - accuracy: 0.7257 - val_loss: 0.5347 - val_accuracy: 0.7188\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5308 - accuracy: 0.7274 - val_loss: 0.5344 - val_accuracy: 0.7188\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5302 - accuracy: 0.7274 - val_loss: 0.5340 - val_accuracy: 0.7188\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5296 - accuracy: 0.7274 - val_loss: 0.5336 - val_accuracy: 0.7240\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5290 - accuracy: 0.7274 - val_loss: 0.5333 - val_accuracy: 0.7240\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5284 - accuracy: 0.7274 - val_loss: 0.5329 - val_accuracy: 0.7240\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5278 - accuracy: 0.7257 - val_loss: 0.5326 - val_accuracy: 0.7240\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5272 - accuracy: 0.7274 - val_loss: 0.5323 - val_accuracy: 0.7240\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5266 - accuracy: 0.7257 - val_loss: 0.5320 - val_accuracy: 0.7240\n",
      "Epoch 115/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5260 - accuracy: 0.7274 - val_loss: 0.5316 - val_accuracy: 0.7240\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5254 - accuracy: 0.7274 - val_loss: 0.5313 - val_accuracy: 0.7292\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5249 - accuracy: 0.7240 - val_loss: 0.5310 - val_accuracy: 0.7292\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5243 - accuracy: 0.7240 - val_loss: 0.5307 - val_accuracy: 0.7240\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5238 - accuracy: 0.7257 - val_loss: 0.5304 - val_accuracy: 0.7240\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5233 - accuracy: 0.7257 - val_loss: 0.5301 - val_accuracy: 0.7240\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.7240 - val_loss: 0.5298 - val_accuracy: 0.7240\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5221 - accuracy: 0.7257 - val_loss: 0.5295 - val_accuracy: 0.7240\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5217 - accuracy: 0.7257 - val_loss: 0.5293 - val_accuracy: 0.7240\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5211 - accuracy: 0.7257 - val_loss: 0.5290 - val_accuracy: 0.7240\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5205 - accuracy: 0.7257 - val_loss: 0.5288 - val_accuracy: 0.7240\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5200 - accuracy: 0.7257 - val_loss: 0.5286 - val_accuracy: 0.7188\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5196 - accuracy: 0.7257 - val_loss: 0.5284 - val_accuracy: 0.7188\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5190 - accuracy: 0.7257 - val_loss: 0.5281 - val_accuracy: 0.7188\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.7257 - val_loss: 0.5279 - val_accuracy: 0.7188\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5181 - accuracy: 0.7257 - val_loss: 0.5277 - val_accuracy: 0.7188\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5176 - accuracy: 0.7274 - val_loss: 0.5275 - val_accuracy: 0.7188\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5171 - accuracy: 0.7274 - val_loss: 0.5273 - val_accuracy: 0.7188\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5168 - accuracy: 0.7274 - val_loss: 0.5271 - val_accuracy: 0.7188\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5163 - accuracy: 0.7257 - val_loss: 0.5269 - val_accuracy: 0.7188\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5159 - accuracy: 0.7274 - val_loss: 0.5268 - val_accuracy: 0.7188\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5154 - accuracy: 0.7274 - val_loss: 0.5266 - val_accuracy: 0.7188\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5151 - accuracy: 0.7274 - val_loss: 0.5264 - val_accuracy: 0.7188\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5147 - accuracy: 0.7274 - val_loss: 0.5263 - val_accuracy: 0.7188\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.7274 - val_loss: 0.5261 - val_accuracy: 0.7188\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5139 - accuracy: 0.7257 - val_loss: 0.5260 - val_accuracy: 0.7188\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5135 - accuracy: 0.7274 - val_loss: 0.5258 - val_accuracy: 0.7188\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.7292 - val_loss: 0.5257 - val_accuracy: 0.7188\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5127 - accuracy: 0.7292 - val_loss: 0.5256 - val_accuracy: 0.7188\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.7309 - val_loss: 0.5254 - val_accuracy: 0.7188\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5120 - accuracy: 0.7309 - val_loss: 0.5253 - val_accuracy: 0.7188\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.7326 - val_loss: 0.5251 - val_accuracy: 0.7188\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5113 - accuracy: 0.7326 - val_loss: 0.5250 - val_accuracy: 0.7188\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5108 - accuracy: 0.7326 - val_loss: 0.5248 - val_accuracy: 0.7188\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5105 - accuracy: 0.7344 - val_loss: 0.5247 - val_accuracy: 0.7188\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5101 - accuracy: 0.7344 - val_loss: 0.5245 - val_accuracy: 0.7188\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5098 - accuracy: 0.7344 - val_loss: 0.5244 - val_accuracy: 0.7188\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7326 - val_loss: 0.5243 - val_accuracy: 0.7188\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5090 - accuracy: 0.7344 - val_loss: 0.5242 - val_accuracy: 0.7188\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5087 - accuracy: 0.7326 - val_loss: 0.5241 - val_accuracy: 0.7188\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5084 - accuracy: 0.7344 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5080 - accuracy: 0.7344 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5077 - accuracy: 0.7344 - val_loss: 0.5237 - val_accuracy: 0.7188\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5073 - accuracy: 0.7344 - val_loss: 0.5236 - val_accuracy: 0.7188\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5070 - accuracy: 0.7378 - val_loss: 0.5236 - val_accuracy: 0.7188\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5067 - accuracy: 0.7344 - val_loss: 0.5235 - val_accuracy: 0.7188\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5063 - accuracy: 0.7378 - val_loss: 0.5234 - val_accuracy: 0.7188\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5060 - accuracy: 0.7361 - val_loss: 0.5233 - val_accuracy: 0.7188\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5056 - accuracy: 0.7361 - val_loss: 0.5233 - val_accuracy: 0.7188\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5053 - accuracy: 0.7396 - val_loss: 0.5232 - val_accuracy: 0.7188\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5049 - accuracy: 0.7413 - val_loss: 0.5231 - val_accuracy: 0.7188\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5046 - accuracy: 0.7396 - val_loss: 0.5230 - val_accuracy: 0.7188\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7378 - val_loss: 0.5229 - val_accuracy: 0.7188\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5040 - accuracy: 0.7396 - val_loss: 0.5228 - val_accuracy: 0.7188\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5037 - accuracy: 0.7378 - val_loss: 0.5228 - val_accuracy: 0.7188\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5034 - accuracy: 0.7378 - val_loss: 0.5227 - val_accuracy: 0.7188\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5031 - accuracy: 0.7361 - val_loss: 0.5227 - val_accuracy: 0.7188\n",
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5028 - accuracy: 0.7378 - val_loss: 0.5226 - val_accuracy: 0.7188\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7361 - val_loss: 0.5226 - val_accuracy: 0.7188\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5022 - accuracy: 0.7361 - val_loss: 0.5225 - val_accuracy: 0.7188\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5020 - accuracy: 0.7361 - val_loss: 0.5225 - val_accuracy: 0.7188\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5017 - accuracy: 0.7361 - val_loss: 0.5224 - val_accuracy: 0.7188\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5013 - accuracy: 0.7361 - val_loss: 0.5223 - val_accuracy: 0.7188\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5011 - accuracy: 0.7361 - val_loss: 0.5223 - val_accuracy: 0.7188\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5008 - accuracy: 0.7361 - val_loss: 0.5222 - val_accuracy: 0.7135\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7361 - val_loss: 0.5221 - val_accuracy: 0.7188\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5003 - accuracy: 0.7344 - val_loss: 0.5221 - val_accuracy: 0.7188\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5000 - accuracy: 0.7344 - val_loss: 0.5220 - val_accuracy: 0.7188\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7361 - val_loss: 0.5220 - val_accuracy: 0.7188\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7344 - val_loss: 0.5219 - val_accuracy: 0.7188\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4992 - accuracy: 0.7344 - val_loss: 0.5219 - val_accuracy: 0.7188\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4989 - accuracy: 0.7344 - val_loss: 0.5218 - val_accuracy: 0.7188\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4986 - accuracy: 0.7361 - val_loss: 0.5218 - val_accuracy: 0.7188\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4983 - accuracy: 0.7344 - val_loss: 0.5218 - val_accuracy: 0.7188\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4981 - accuracy: 0.7344 - val_loss: 0.5217 - val_accuracy: 0.7188\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4979 - accuracy: 0.7344 - val_loss: 0.5217 - val_accuracy: 0.7188\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4975 - accuracy: 0.7344 - val_loss: 0.5217 - val_accuracy: 0.7188\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4974 - accuracy: 0.7344 - val_loss: 0.5216 - val_accuracy: 0.7188\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4971 - accuracy: 0.7344 - val_loss: 0.5216 - val_accuracy: 0.7188\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4968 - accuracy: 0.7344 - val_loss: 0.5216 - val_accuracy: 0.7188\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4965 - accuracy: 0.7361 - val_loss: 0.5215 - val_accuracy: 0.7188\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4963 - accuracy: 0.7361 - val_loss: 0.5215 - val_accuracy: 0.7188\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7361 - val_loss: 0.5214 - val_accuracy: 0.7188\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4959 - accuracy: 0.7361 - val_loss: 0.5214 - val_accuracy: 0.7188\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7361 - val_loss: 0.5214 - val_accuracy: 0.7188\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4953 - accuracy: 0.7361 - val_loss: 0.5214 - val_accuracy: 0.7188\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4951 - accuracy: 0.7361 - val_loss: 0.5214 - val_accuracy: 0.7188\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.7361 - val_loss: 0.5213 - val_accuracy: 0.7188\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4945 - accuracy: 0.7361 - val_loss: 0.5213 - val_accuracy: 0.7188\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.7361 - val_loss: 0.5213 - val_accuracy: 0.7188\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4942 - accuracy: 0.7361 - val_loss: 0.5213 - val_accuracy: 0.7188\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4939 - accuracy: 0.7378 - val_loss: 0.5213 - val_accuracy: 0.7188\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4936 - accuracy: 0.7344 - val_loss: 0.5213 - val_accuracy: 0.7188\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4934 - accuracy: 0.7378 - val_loss: 0.5212 - val_accuracy: 0.7188\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.7396 - val_loss: 0.5212 - val_accuracy: 0.7188\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4929 - accuracy: 0.7396 - val_loss: 0.5212 - val_accuracy: 0.7188\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4927 - accuracy: 0.7396 - val_loss: 0.5212 - val_accuracy: 0.7188\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4925 - accuracy: 0.7396 - val_loss: 0.5212 - val_accuracy: 0.7188\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4921 - accuracy: 0.7413 - val_loss: 0.5212 - val_accuracy: 0.7188\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4920 - accuracy: 0.7413 - val_loss: 0.5211 - val_accuracy: 0.7188\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4918 - accuracy: 0.7413 - val_loss: 0.5211 - val_accuracy: 0.7188\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4915 - accuracy: 0.7431 - val_loss: 0.5211 - val_accuracy: 0.7188\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4914 - accuracy: 0.7431 - val_loss: 0.5211 - val_accuracy: 0.7188\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4912 - accuracy: 0.7431 - val_loss: 0.5211 - val_accuracy: 0.7188\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4908 - accuracy: 0.7431 - val_loss: 0.5211 - val_accuracy: 0.7188\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4906 - accuracy: 0.7465 - val_loss: 0.5211 - val_accuracy: 0.7188\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4903 - accuracy: 0.7448 - val_loss: 0.5211 - val_accuracy: 0.7188\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4901 - accuracy: 0.7448 - val_loss: 0.5211 - val_accuracy: 0.7188\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4899 - accuracy: 0.7448 - val_loss: 0.5211 - val_accuracy: 0.7188\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4897 - accuracy: 0.7448 - val_loss: 0.5211 - val_accuracy: 0.7188\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.7448 - val_loss: 0.5211 - val_accuracy: 0.7188\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4893 - accuracy: 0.7431 - val_loss: 0.5212 - val_accuracy: 0.7188\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4891 - accuracy: 0.7465 - val_loss: 0.5212 - val_accuracy: 0.7188\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4888 - accuracy: 0.7465 - val_loss: 0.5212 - val_accuracy: 0.7188\n",
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7465 - val_loss: 0.5212 - val_accuracy: 0.7188\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4884 - accuracy: 0.7448 - val_loss: 0.5211 - val_accuracy: 0.7188\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.7448 - val_loss: 0.5211 - val_accuracy: 0.7188\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4879 - accuracy: 0.7431 - val_loss: 0.5211 - val_accuracy: 0.7188\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4877 - accuracy: 0.7431 - val_loss: 0.5211 - val_accuracy: 0.7188\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4875 - accuracy: 0.7431 - val_loss: 0.5211 - val_accuracy: 0.7188\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4872 - accuracy: 0.7431 - val_loss: 0.5211 - val_accuracy: 0.7188\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4871 - accuracy: 0.7448 - val_loss: 0.5211 - val_accuracy: 0.7188\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.7431 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7431 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4865 - accuracy: 0.7448 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7448 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.7448 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.7448 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7448 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7448 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4853 - accuracy: 0.7448 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7448 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.7448 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.7448 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7448 - val_loss: 0.5212 - val_accuracy: 0.7240\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7483 - val_loss: 0.5212 - val_accuracy: 0.7240\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7483 - val_loss: 0.5212 - val_accuracy: 0.7240\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4840 - accuracy: 0.7483 - val_loss: 0.5212 - val_accuracy: 0.7292\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7465 - val_loss: 0.5212 - val_accuracy: 0.7292\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4836 - accuracy: 0.7483 - val_loss: 0.5212 - val_accuracy: 0.7292\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4835 - accuracy: 0.7483 - val_loss: 0.5212 - val_accuracy: 0.7292\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7483 - val_loss: 0.5213 - val_accuracy: 0.7292\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4831 - accuracy: 0.7465 - val_loss: 0.5212 - val_accuracy: 0.7292\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4829 - accuracy: 0.7483 - val_loss: 0.5212 - val_accuracy: 0.7292\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4826 - accuracy: 0.7500 - val_loss: 0.5212 - val_accuracy: 0.7292\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4825 - accuracy: 0.7500 - val_loss: 0.5212 - val_accuracy: 0.7292\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4823 - accuracy: 0.7500 - val_loss: 0.5212 - val_accuracy: 0.7344\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7500 - val_loss: 0.5212 - val_accuracy: 0.7344\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4820 - accuracy: 0.7517 - val_loss: 0.5212 - val_accuracy: 0.7344\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7517 - val_loss: 0.5213 - val_accuracy: 0.7344\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7500 - val_loss: 0.5213 - val_accuracy: 0.7344\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4814 - accuracy: 0.7517 - val_loss: 0.5213 - val_accuracy: 0.7344\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.7517 - val_loss: 0.5213 - val_accuracy: 0.7344\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4811 - accuracy: 0.7517 - val_loss: 0.5213 - val_accuracy: 0.7344\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4810 - accuracy: 0.7517 - val_loss: 0.5213 - val_accuracy: 0.7344\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4808 - accuracy: 0.7517 - val_loss: 0.5213 - val_accuracy: 0.7344\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4806 - accuracy: 0.7517 - val_loss: 0.5213 - val_accuracy: 0.7344\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.7500 - val_loss: 0.5213 - val_accuracy: 0.7344\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4804 - accuracy: 0.7517 - val_loss: 0.5214 - val_accuracy: 0.7344\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4801 - accuracy: 0.7517 - val_loss: 0.5214 - val_accuracy: 0.7344\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4800 - accuracy: 0.7500 - val_loss: 0.5213 - val_accuracy: 0.7344\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4797 - accuracy: 0.7517 - val_loss: 0.5213 - val_accuracy: 0.7344\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4796 - accuracy: 0.7535 - val_loss: 0.5214 - val_accuracy: 0.7292\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7535 - val_loss: 0.5214 - val_accuracy: 0.7292\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4793 - accuracy: 0.7535 - val_loss: 0.5214 - val_accuracy: 0.7292\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4792 - accuracy: 0.7535 - val_loss: 0.5214 - val_accuracy: 0.7292\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7535 - val_loss: 0.5214 - val_accuracy: 0.7292\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4788 - accuracy: 0.7535 - val_loss: 0.5214 - val_accuracy: 0.7344\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.7517 - val_loss: 0.5214 - val_accuracy: 0.7344\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.7535 - val_loss: 0.5214 - val_accuracy: 0.7344\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4783 - accuracy: 0.7517 - val_loss: 0.5214 - val_accuracy: 0.7344\n",
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.7535 - val_loss: 0.5215 - val_accuracy: 0.7292\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7535 - val_loss: 0.5215 - val_accuracy: 0.7292\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7535 - val_loss: 0.5215 - val_accuracy: 0.7344\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4777 - accuracy: 0.7517 - val_loss: 0.5215 - val_accuracy: 0.7344\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7535 - val_loss: 0.5215 - val_accuracy: 0.7344\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.7552 - val_loss: 0.5215 - val_accuracy: 0.7292\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.7535 - val_loss: 0.5215 - val_accuracy: 0.7292\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4771 - accuracy: 0.7552 - val_loss: 0.5216 - val_accuracy: 0.7292\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.7535 - val_loss: 0.5216 - val_accuracy: 0.7292\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4767 - accuracy: 0.7535 - val_loss: 0.5216 - val_accuracy: 0.7292\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4765 - accuracy: 0.7535 - val_loss: 0.5216 - val_accuracy: 0.7292\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7535 - val_loss: 0.5216 - val_accuracy: 0.7292\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4763 - accuracy: 0.7552 - val_loss: 0.5216 - val_accuracy: 0.7292\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4762 - accuracy: 0.7552 - val_loss: 0.5217 - val_accuracy: 0.7292\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.7569 - val_loss: 0.5217 - val_accuracy: 0.7292\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.7552 - val_loss: 0.5217 - val_accuracy: 0.7344\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.7569 - val_loss: 0.5217 - val_accuracy: 0.7292\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7552 - val_loss: 0.5217 - val_accuracy: 0.7292\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.7569 - val_loss: 0.5217 - val_accuracy: 0.7292\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4754 - accuracy: 0.7569 - val_loss: 0.5217 - val_accuracy: 0.7344\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4751 - accuracy: 0.7552 - val_loss: 0.5217 - val_accuracy: 0.7344\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4750 - accuracy: 0.7569 - val_loss: 0.5217 - val_accuracy: 0.7344\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4749 - accuracy: 0.7552 - val_loss: 0.5217 - val_accuracy: 0.7344\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7552 - val_loss: 0.5217 - val_accuracy: 0.7344\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7569 - val_loss: 0.5217 - val_accuracy: 0.7344\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.7552 - val_loss: 0.5217 - val_accuracy: 0.7344\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4744 - accuracy: 0.7552 - val_loss: 0.5217 - val_accuracy: 0.7344\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7552 - val_loss: 0.5217 - val_accuracy: 0.7344\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.7569 - val_loss: 0.5217 - val_accuracy: 0.7344\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7569 - val_loss: 0.5218 - val_accuracy: 0.7344\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7535 - val_loss: 0.5218 - val_accuracy: 0.7344\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7569 - val_loss: 0.5218 - val_accuracy: 0.7344\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7569 - val_loss: 0.5218 - val_accuracy: 0.7396\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4735 - accuracy: 0.7587 - val_loss: 0.5218 - val_accuracy: 0.7396\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4734 - accuracy: 0.7569 - val_loss: 0.5218 - val_accuracy: 0.7344\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4734 - accuracy: 0.7587 - val_loss: 0.5218 - val_accuracy: 0.7344\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4732 - accuracy: 0.7587 - val_loss: 0.5218 - val_accuracy: 0.7344\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7569 - val_loss: 0.5218 - val_accuracy: 0.7344\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.7587 - val_loss: 0.5218 - val_accuracy: 0.7344\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7587 - val_loss: 0.5218 - val_accuracy: 0.7344\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4728 - accuracy: 0.7604 - val_loss: 0.5219 - val_accuracy: 0.7396\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4726 - accuracy: 0.7587 - val_loss: 0.5219 - val_accuracy: 0.7396\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4725 - accuracy: 0.7569 - val_loss: 0.5219 - val_accuracy: 0.7396\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4724 - accuracy: 0.7569 - val_loss: 0.5219 - val_accuracy: 0.7344\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7569 - val_loss: 0.5219 - val_accuracy: 0.7396\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4722 - accuracy: 0.7569 - val_loss: 0.5219 - val_accuracy: 0.7396\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7587 - val_loss: 0.5219 - val_accuracy: 0.7396\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4721 - accuracy: 0.7587 - val_loss: 0.5219 - val_accuracy: 0.7396\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4719 - accuracy: 0.7587 - val_loss: 0.5219 - val_accuracy: 0.7396\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4718 - accuracy: 0.7552 - val_loss: 0.5219 - val_accuracy: 0.7396\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.7587 - val_loss: 0.5219 - val_accuracy: 0.7396\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.7569 - val_loss: 0.5219 - val_accuracy: 0.7396\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4715 - accuracy: 0.7587 - val_loss: 0.5219 - val_accuracy: 0.7344\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7569 - val_loss: 0.5219 - val_accuracy: 0.7344\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7569 - val_loss: 0.5219 - val_accuracy: 0.7344\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7552 - val_loss: 0.5220 - val_accuracy: 0.7344\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7587 - val_loss: 0.5220 - val_accuracy: 0.7344\n",
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7569 - val_loss: 0.5220 - val_accuracy: 0.7344\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.7587 - val_loss: 0.5220 - val_accuracy: 0.7344\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7552 - val_loss: 0.5220 - val_accuracy: 0.7344\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7587 - val_loss: 0.5220 - val_accuracy: 0.7344\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7587 - val_loss: 0.5221 - val_accuracy: 0.7344\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7587 - val_loss: 0.5221 - val_accuracy: 0.7344\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7604 - val_loss: 0.5221 - val_accuracy: 0.7344\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7587 - val_loss: 0.5221 - val_accuracy: 0.7344\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7587 - val_loss: 0.5221 - val_accuracy: 0.7344\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.7587 - val_loss: 0.5221 - val_accuracy: 0.7344\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.7587 - val_loss: 0.5221 - val_accuracy: 0.7344\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7587 - val_loss: 0.5221 - val_accuracy: 0.7344\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4698 - accuracy: 0.7569 - val_loss: 0.5221 - val_accuracy: 0.7344\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7587 - val_loss: 0.5221 - val_accuracy: 0.7396\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4695 - accuracy: 0.7587 - val_loss: 0.5221 - val_accuracy: 0.7396\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7587 - val_loss: 0.5221 - val_accuracy: 0.7396\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7552 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7587 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7587 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7569 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7569 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7587 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7569 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7587 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7569 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7587 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7569 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7587 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.7587 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.7552 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7587 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7622 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7587 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.7569 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7587 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7604 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7622 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7622 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7622 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7622 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7639 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7587 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7569 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7622 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7604 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7622 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.7639 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7639 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7622 - val_loss: 0.5222 - val_accuracy: 0.7500\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7622 - val_loss: 0.5222 - val_accuracy: 0.7500\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7639 - val_loss: 0.5222 - val_accuracy: 0.7500\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7639 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7622 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7622 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7639 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7622 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7622 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4662 - accuracy: 0.7622 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7622 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7639 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7622 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4660 - accuracy: 0.7622 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7622 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7622 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7639 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7622 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.7622 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.7622 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4655 - accuracy: 0.7622 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7639 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7622 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7622 - val_loss: 0.5223 - val_accuracy: 0.7396\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7639 - val_loss: 0.5223 - val_accuracy: 0.7396\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7622 - val_loss: 0.5223 - val_accuracy: 0.7396\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.7639 - val_loss: 0.5223 - val_accuracy: 0.7396\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7639 - val_loss: 0.5223 - val_accuracy: 0.7396\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7622 - val_loss: 0.5223 - val_accuracy: 0.7396\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7674 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7639 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.7656 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7639 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7674 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4647 - accuracy: 0.7656 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7656 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4646 - accuracy: 0.7656 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7656 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4646 - accuracy: 0.7674 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7674 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4644 - accuracy: 0.7656 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7656 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7674 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7708 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4641 - accuracy: 0.7674 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7691 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4639 - accuracy: 0.7691 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7726 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4639 - accuracy: 0.7708 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7726 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4637 - accuracy: 0.7708 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7726 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7726 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7726 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7726 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4634 - accuracy: 0.7743 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4633 - accuracy: 0.7726 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.7726 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7708 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7708 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7726 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7726 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7726 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7726 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7726 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7726 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7726 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4627 - accuracy: 0.7726 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4627 - accuracy: 0.7708 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7691 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4626 - accuracy: 0.7691 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7726 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7726 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4624 - accuracy: 0.7726 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7726 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4622 - accuracy: 0.7708 - val_loss: 0.5223 - val_accuracy: 0.7396\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7708 - val_loss: 0.5223 - val_accuracy: 0.7396\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7708 - val_loss: 0.5222 - val_accuracy: 0.7396\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7708 - val_loss: 0.5222 - val_accuracy: 0.7396\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4621 - accuracy: 0.7708 - val_loss: 0.5222 - val_accuracy: 0.7396\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7726 - val_loss: 0.5222 - val_accuracy: 0.7396\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7708 - val_loss: 0.5222 - val_accuracy: 0.7396\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7708 - val_loss: 0.5222 - val_accuracy: 0.7396\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4617 - accuracy: 0.7691 - val_loss: 0.5222 - val_accuracy: 0.7396\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7708 - val_loss: 0.5222 - val_accuracy: 0.7396\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7691 - val_loss: 0.5222 - val_accuracy: 0.7396\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7708 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7708 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7691 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7726 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7708 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.7708 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7691 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.7691 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.7691 - val_loss: 0.5220 - val_accuracy: 0.7448\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7691 - val_loss: 0.5220 - val_accuracy: 0.7448\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7691 - val_loss: 0.5220 - val_accuracy: 0.7448\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7691 - val_loss: 0.5219 - val_accuracy: 0.7448\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7691 - val_loss: 0.5219 - val_accuracy: 0.7448\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7691 - val_loss: 0.5218 - val_accuracy: 0.7448\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7691 - val_loss: 0.5218 - val_accuracy: 0.7448\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7708 - val_loss: 0.5217 - val_accuracy: 0.7448\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7708 - val_loss: 0.5217 - val_accuracy: 0.7448\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7674 - val_loss: 0.5217 - val_accuracy: 0.7448\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4607 - accuracy: 0.7674 - val_loss: 0.5217 - val_accuracy: 0.7448\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7674 - val_loss: 0.5216 - val_accuracy: 0.7448\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.7674 - val_loss: 0.5216 - val_accuracy: 0.7448\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.7674 - val_loss: 0.5216 - val_accuracy: 0.7448\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7691 - val_loss: 0.5215 - val_accuracy: 0.7448\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7691 - val_loss: 0.5215 - val_accuracy: 0.7448\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7674 - val_loss: 0.5215 - val_accuracy: 0.7448\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7674 - val_loss: 0.5215 - val_accuracy: 0.7448\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.7691 - val_loss: 0.5214 - val_accuracy: 0.7448\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7708 - val_loss: 0.5214 - val_accuracy: 0.7448\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7691 - val_loss: 0.5214 - val_accuracy: 0.7448\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7674 - val_loss: 0.5213 - val_accuracy: 0.7448\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7674 - val_loss: 0.5213 - val_accuracy: 0.7448\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7656 - val_loss: 0.5213 - val_accuracy: 0.7448\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7674 - val_loss: 0.5212 - val_accuracy: 0.7396\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7656 - val_loss: 0.5212 - val_accuracy: 0.7396\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7674 - val_loss: 0.5212 - val_accuracy: 0.7396\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.7674 - val_loss: 0.5212 - val_accuracy: 0.7396\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7708 - val_loss: 0.5211 - val_accuracy: 0.7396\n",
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4595 - accuracy: 0.7691 - val_loss: 0.5211 - val_accuracy: 0.7396\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7691 - val_loss: 0.5211 - val_accuracy: 0.7396\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7674 - val_loss: 0.5211 - val_accuracy: 0.7396\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7674 - val_loss: 0.5211 - val_accuracy: 0.7396\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7691 - val_loss: 0.5211 - val_accuracy: 0.7396\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7656 - val_loss: 0.5211 - val_accuracy: 0.7396\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7674 - val_loss: 0.5211 - val_accuracy: 0.7396\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7691 - val_loss: 0.5210 - val_accuracy: 0.7396\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7691 - val_loss: 0.5210 - val_accuracy: 0.7396\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7656 - val_loss: 0.5210 - val_accuracy: 0.7396\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7691 - val_loss: 0.5210 - val_accuracy: 0.7448\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.7691 - val_loss: 0.5210 - val_accuracy: 0.7448\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7674 - val_loss: 0.5210 - val_accuracy: 0.7448\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7674 - val_loss: 0.5210 - val_accuracy: 0.7448\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7691 - val_loss: 0.5209 - val_accuracy: 0.7448\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7674 - val_loss: 0.5209 - val_accuracy: 0.7448\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7708 - val_loss: 0.5210 - val_accuracy: 0.7448\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7691 - val_loss: 0.5209 - val_accuracy: 0.7448\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7674 - val_loss: 0.5209 - val_accuracy: 0.7448\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7691 - val_loss: 0.5209 - val_accuracy: 0.7448\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7708 - val_loss: 0.5209 - val_accuracy: 0.7448\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4586 - accuracy: 0.7674 - val_loss: 0.5209 - val_accuracy: 0.7448\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7691 - val_loss: 0.5209 - val_accuracy: 0.7448\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7708 - val_loss: 0.5209 - val_accuracy: 0.7448\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.7726 - val_loss: 0.5209 - val_accuracy: 0.7448\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7708 - val_loss: 0.5209 - val_accuracy: 0.7448\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7708 - val_loss: 0.5209 - val_accuracy: 0.7448\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7691 - val_loss: 0.5209 - val_accuracy: 0.7448\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7691 - val_loss: 0.5209 - val_accuracy: 0.7448\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.7691 - val_loss: 0.5209 - val_accuracy: 0.7448\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7674 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7708 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7726 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7691 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.7708 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4580 - accuracy: 0.7743 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4579 - accuracy: 0.7726 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7691 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4580 - accuracy: 0.7726 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7708 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4579 - accuracy: 0.7708 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7708 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7743 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7708 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7708 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7691 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7674 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4576 - accuracy: 0.7708 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7743 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7726 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7743 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7743 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4574 - accuracy: 0.7708 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7743 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7726 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7708 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4573 - accuracy: 0.7743 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7726 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7726 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7708 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4572 - accuracy: 0.7708 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7726 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7726 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7726 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7726 - val_loss: 0.5210 - val_accuracy: 0.7396\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4571 - accuracy: 0.7708 - val_loss: 0.5210 - val_accuracy: 0.7396\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7743 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7760 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7726 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7743 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4568 - accuracy: 0.7743 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7726 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7743 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7726 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7743 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7726 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7760 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7726 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7743 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4565 - accuracy: 0.7743 - val_loss: 0.5208 - val_accuracy: 0.7396\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7726 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7726 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7726 - val_loss: 0.5208 - val_accuracy: 0.7396\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7726 - val_loss: 0.5208 - val_accuracy: 0.7396\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4564 - accuracy: 0.7726 - val_loss: 0.5208 - val_accuracy: 0.7396\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7726 - val_loss: 0.5208 - val_accuracy: 0.7396\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7743 - val_loss: 0.5208 - val_accuracy: 0.7396\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7726 - val_loss: 0.5208 - val_accuracy: 0.7396\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7726 - val_loss: 0.5208 - val_accuracy: 0.7396\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4561 - accuracy: 0.7726 - val_loss: 0.5208 - val_accuracy: 0.7396\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7708 - val_loss: 0.5208 - val_accuracy: 0.7396\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4561 - accuracy: 0.7708 - val_loss: 0.5208 - val_accuracy: 0.7396\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7708 - val_loss: 0.5208 - val_accuracy: 0.7344\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7743 - val_loss: 0.5208 - val_accuracy: 0.7344\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7743 - val_loss: 0.5208 - val_accuracy: 0.7344\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7743 - val_loss: 0.5208 - val_accuracy: 0.7344\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7743 - val_loss: 0.5208 - val_accuracy: 0.7344\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7726 - val_loss: 0.5208 - val_accuracy: 0.7344\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4558 - accuracy: 0.7726 - val_loss: 0.5208 - val_accuracy: 0.7344\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7743 - val_loss: 0.5208 - val_accuracy: 0.7344\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7726 - val_loss: 0.5207 - val_accuracy: 0.7344\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4558 - accuracy: 0.7760 - val_loss: 0.5207 - val_accuracy: 0.7344\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7760 - val_loss: 0.5207 - val_accuracy: 0.7344\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7743 - val_loss: 0.5207 - val_accuracy: 0.7344\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7743 - val_loss: 0.5207 - val_accuracy: 0.7344\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7760 - val_loss: 0.5207 - val_accuracy: 0.7344\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7743 - val_loss: 0.5207 - val_accuracy: 0.7344\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4556 - accuracy: 0.7795 - val_loss: 0.5207 - val_accuracy: 0.7344\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7743 - val_loss: 0.5207 - val_accuracy: 0.7344\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4554 - accuracy: 0.7760 - val_loss: 0.5206 - val_accuracy: 0.7344\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7778 - val_loss: 0.5206 - val_accuracy: 0.7344\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4554 - accuracy: 0.7760 - val_loss: 0.5206 - val_accuracy: 0.7344\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4553 - accuracy: 0.7760 - val_loss: 0.5206 - val_accuracy: 0.7344\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7760 - val_loss: 0.5206 - val_accuracy: 0.7344\n",
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7760 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7778 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7778 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7760 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7778 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.7778 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7778 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7760 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.7760 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4551 - accuracy: 0.7743 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.7778 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7778 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.7778 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.7795 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.7795 - val_loss: 0.5202 - val_accuracy: 0.7448\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.7760 - val_loss: 0.5202 - val_accuracy: 0.7448\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.7795 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.7778 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.7778 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4546 - accuracy: 0.7760 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7743 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7760 - val_loss: 0.5200 - val_accuracy: 0.7448\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7778 - val_loss: 0.5200 - val_accuracy: 0.7448\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7760 - val_loss: 0.5200 - val_accuracy: 0.7448\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7778 - val_loss: 0.5199 - val_accuracy: 0.7448\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7760 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7778 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7778 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7760 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4543 - accuracy: 0.7778 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7778 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.7760 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.7760 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7778 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4542 - accuracy: 0.7778 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7760 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7795 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7812 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7795 - val_loss: 0.5195 - val_accuracy: 0.7344\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7812 - val_loss: 0.5195 - val_accuracy: 0.7344\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7812 - val_loss: 0.5195 - val_accuracy: 0.7344\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7812 - val_loss: 0.5195 - val_accuracy: 0.7344\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7812 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7812 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7812 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7812 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4539 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7344\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4538 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7344\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7344\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7344\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7344\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7344\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7812 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7830 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7830 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7830 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4535 - accuracy: 0.7830 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7830 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.7830 - val_loss: 0.5189 - val_accuracy: 0.7344\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4534 - accuracy: 0.7812 - val_loss: 0.5189 - val_accuracy: 0.7344\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.7812 - val_loss: 0.5188 - val_accuracy: 0.7344\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4534 - accuracy: 0.7812 - val_loss: 0.5188 - val_accuracy: 0.7344\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4533 - accuracy: 0.7812 - val_loss: 0.5187 - val_accuracy: 0.7344\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7795 - val_loss: 0.5187 - val_accuracy: 0.7344\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4532 - accuracy: 0.7812 - val_loss: 0.5186 - val_accuracy: 0.7344\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4532 - accuracy: 0.7830 - val_loss: 0.5186 - val_accuracy: 0.7344\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4531 - accuracy: 0.7812 - val_loss: 0.5186 - val_accuracy: 0.7344\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7830 - val_loss: 0.5185 - val_accuracy: 0.7344\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4531 - accuracy: 0.7830 - val_loss: 0.5184 - val_accuracy: 0.7344\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7830 - val_loss: 0.5184 - val_accuracy: 0.7396\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7847 - val_loss: 0.5184 - val_accuracy: 0.7396\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7396\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4530 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7396\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4528 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7396\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4529 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7396\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4529 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7396\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4527 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4528 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4526 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4526 - accuracy: 0.7847 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4525 - accuracy: 0.7847 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4525 - accuracy: 0.7847 - val_loss: 0.5178 - val_accuracy: 0.7396\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.7847 - val_loss: 0.5178 - val_accuracy: 0.7396\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.7847 - val_loss: 0.5178 - val_accuracy: 0.7396\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4525 - accuracy: 0.7847 - val_loss: 0.5178 - val_accuracy: 0.7396\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4525 - accuracy: 0.7847 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4524 - accuracy: 0.7830 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4524 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7847 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.7847 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7847 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7830 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7830 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7830 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7830 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7830 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7830 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7830 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7812 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7830 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7830 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7830 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.7830 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4516 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7830 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7830 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7830 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7830 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7830 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7830 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.7830 - val_loss: 0.5166 - val_accuracy: 0.7448\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7830 - val_loss: 0.5166 - val_accuracy: 0.7448\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7830 - val_loss: 0.5166 - val_accuracy: 0.7448\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7830 - val_loss: 0.5165 - val_accuracy: 0.7448\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7830 - val_loss: 0.5165 - val_accuracy: 0.7448\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7830 - val_loss: 0.5164 - val_accuracy: 0.7448\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7830 - val_loss: 0.5164 - val_accuracy: 0.7448\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4510 - accuracy: 0.7830 - val_loss: 0.5164 - val_accuracy: 0.7448\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4511 - accuracy: 0.7830 - val_loss: 0.5163 - val_accuracy: 0.7448\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7830 - val_loss: 0.5163 - val_accuracy: 0.7448\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4510 - accuracy: 0.7830 - val_loss: 0.5162 - val_accuracy: 0.7448\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7830 - val_loss: 0.5162 - val_accuracy: 0.7448\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7830 - val_loss: 0.5161 - val_accuracy: 0.7448\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7830 - val_loss: 0.5161 - val_accuracy: 0.7448\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4509 - accuracy: 0.7830 - val_loss: 0.5161 - val_accuracy: 0.7448\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4509 - accuracy: 0.7830 - val_loss: 0.5160 - val_accuracy: 0.7448\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.7830 - val_loss: 0.5160 - val_accuracy: 0.7448\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.7830 - val_loss: 0.5160 - val_accuracy: 0.7448\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7847 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7830 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7847 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7830 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7847 - val_loss: 0.5157 - val_accuracy: 0.7448\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7847 - val_loss: 0.5157 - val_accuracy: 0.7500\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7830 - val_loss: 0.5157 - val_accuracy: 0.7500\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7830 - val_loss: 0.5156 - val_accuracy: 0.7500\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7865 - val_loss: 0.5156 - val_accuracy: 0.7500\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7847 - val_loss: 0.5155 - val_accuracy: 0.7500\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7847 - val_loss: 0.5155 - val_accuracy: 0.7500\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7847 - val_loss: 0.5155 - val_accuracy: 0.7500\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.7847 - val_loss: 0.5155 - val_accuracy: 0.7500\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7847 - val_loss: 0.5154 - val_accuracy: 0.7500\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7847 - val_loss: 0.5154 - val_accuracy: 0.7500\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7865 - val_loss: 0.5154 - val_accuracy: 0.7500\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7847 - val_loss: 0.5153 - val_accuracy: 0.7500\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7847 - val_loss: 0.5153 - val_accuracy: 0.7500\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7865 - val_loss: 0.5152 - val_accuracy: 0.7500\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7847 - val_loss: 0.5152 - val_accuracy: 0.7500\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.7847 - val_loss: 0.5152 - val_accuracy: 0.7500\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7830 - val_loss: 0.5151 - val_accuracy: 0.7500\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7865 - val_loss: 0.5151 - val_accuracy: 0.7500\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.7847 - val_loss: 0.5151 - val_accuracy: 0.7500\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4500 - accuracy: 0.7865 - val_loss: 0.5150 - val_accuracy: 0.7500\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7847 - val_loss: 0.5150 - val_accuracy: 0.7500\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7865 - val_loss: 0.5150 - val_accuracy: 0.7500\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7865 - val_loss: 0.5150 - val_accuracy: 0.7500\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7865 - val_loss: 0.5149 - val_accuracy: 0.7500\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7847 - val_loss: 0.5149 - val_accuracy: 0.7500\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.7865 - val_loss: 0.5149 - val_accuracy: 0.7500\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7847 - val_loss: 0.5148 - val_accuracy: 0.7500\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7865 - val_loss: 0.5148 - val_accuracy: 0.7500\n",
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7847 - val_loss: 0.5148 - val_accuracy: 0.7500\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7830 - val_loss: 0.5148 - val_accuracy: 0.7500\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7882 - val_loss: 0.5148 - val_accuracy: 0.7500\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7847 - val_loss: 0.5147 - val_accuracy: 0.7500\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4496 - accuracy: 0.7865 - val_loss: 0.5147 - val_accuracy: 0.7500\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7899 - val_loss: 0.5147 - val_accuracy: 0.7500\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4496 - accuracy: 0.7865 - val_loss: 0.5147 - val_accuracy: 0.7500\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7882 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7899 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4494 - accuracy: 0.7899 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7882 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7882 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.7899 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7899 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.7882 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.7882 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.7882 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.7899 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7882 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7899 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7882 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7882 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.7882 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7882 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.7882 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7865 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4489 - accuracy: 0.7882 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7882 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4489 - accuracy: 0.7882 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7882 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7882 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7882 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7882 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7882 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7882 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7882 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4485 - accuracy: 0.7882 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4485 - accuracy: 0.7865 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7899 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7882 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7882 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7865 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7847 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7865 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7865 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7865 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7882 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.7865 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4481 - accuracy: 0.7865 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7899 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7865 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4480 - accuracy: 0.7847 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7865 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7847 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7847 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4479 - accuracy: 0.7847 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7847 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7847 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7847 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7847 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.7865 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7847 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7847 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7847 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7847 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7847 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7847 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7847 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7847 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7847 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7847 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7847 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.7847 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7847 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7847 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.7847 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7847 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7865 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7847 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7847 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7847 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.7847 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7847 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7847 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7847 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7847 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7847 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7847 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7847 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7847 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.7847 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.7847 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.7865 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.7847 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.7847 - val_loss: 0.5139 - val_accuracy: 0.7552\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.7847 - val_loss: 0.5139 - val_accuracy: 0.7552\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.7865 - val_loss: 0.5139 - val_accuracy: 0.7552\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7847 - val_loss: 0.5139 - val_accuracy: 0.7552\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7847 - val_loss: 0.5139 - val_accuracy: 0.7552\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.7847 - val_loss: 0.5139 - val_accuracy: 0.7552\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7847 - val_loss: 0.5139 - val_accuracy: 0.7552\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7847 - val_loss: 0.5138 - val_accuracy: 0.7552\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7847 - val_loss: 0.5138 - val_accuracy: 0.7552\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7847 - val_loss: 0.5138 - val_accuracy: 0.7552\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7847 - val_loss: 0.5138 - val_accuracy: 0.7552\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7847 - val_loss: 0.5138 - val_accuracy: 0.7552\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7847 - val_loss: 0.5137 - val_accuracy: 0.7552\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7847 - val_loss: 0.5137 - val_accuracy: 0.7552\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7847 - val_loss: 0.5137 - val_accuracy: 0.7552\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7847 - val_loss: 0.5137 - val_accuracy: 0.7552\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7847 - val_loss: 0.5137 - val_accuracy: 0.7552\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7847 - val_loss: 0.5137 - val_accuracy: 0.7552\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7847 - val_loss: 0.5137 - val_accuracy: 0.7552\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7847 - val_loss: 0.5137 - val_accuracy: 0.7552\n",
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7847 - val_loss: 0.5137 - val_accuracy: 0.7552\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4462 - accuracy: 0.7847 - val_loss: 0.5136 - val_accuracy: 0.7552\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.7847 - val_loss: 0.5136 - val_accuracy: 0.7552\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.7847 - val_loss: 0.5136 - val_accuracy: 0.7552\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.7865 - val_loss: 0.5136 - val_accuracy: 0.7552\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7847 - val_loss: 0.5136 - val_accuracy: 0.7552\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.7847 - val_loss: 0.5136 - val_accuracy: 0.7552\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7847 - val_loss: 0.5135 - val_accuracy: 0.7552\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.7847 - val_loss: 0.5135 - val_accuracy: 0.7552\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.7847 - val_loss: 0.5135 - val_accuracy: 0.7552\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7847 - val_loss: 0.5135 - val_accuracy: 0.7552\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4459 - accuracy: 0.7847 - val_loss: 0.5134 - val_accuracy: 0.7552\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7847 - val_loss: 0.5134 - val_accuracy: 0.7552\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7847 - val_loss: 0.5134 - val_accuracy: 0.7552\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.7847 - val_loss: 0.5134 - val_accuracy: 0.7552\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7847 - val_loss: 0.5134 - val_accuracy: 0.7552\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7847 - val_loss: 0.5133 - val_accuracy: 0.7552\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7847 - val_loss: 0.5133 - val_accuracy: 0.7552\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7847 - val_loss: 0.5133 - val_accuracy: 0.7552\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7847 - val_loss: 0.5133 - val_accuracy: 0.7552\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7847 - val_loss: 0.5133 - val_accuracy: 0.7552\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7847 - val_loss: 0.5132 - val_accuracy: 0.7552\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7847 - val_loss: 0.5132 - val_accuracy: 0.7552\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7847 - val_loss: 0.5132 - val_accuracy: 0.7552\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7882 - val_loss: 0.5132 - val_accuracy: 0.7552\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7847 - val_loss: 0.5132 - val_accuracy: 0.7552\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7847 - val_loss: 0.5132 - val_accuracy: 0.7552\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4455 - accuracy: 0.7847 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7847 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7847 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7847 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7847 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7847 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7847 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7847 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7847 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.7847 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7847 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7865 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7847 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7847 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7847 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7847 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4451 - accuracy: 0.7847 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7847 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7847 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7847 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7865 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7882 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7847 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7865 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7865 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7847 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.7865 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7882 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7847 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7865 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7847 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7865 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7865 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7865 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7865 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7847 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7865 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7847 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7882 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4446 - accuracy: 0.7847 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7882 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7865 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.7865 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7865 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7847 - val_loss: 0.5122 - val_accuracy: 0.7500\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7865 - val_loss: 0.5122 - val_accuracy: 0.7500\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7865 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4443 - accuracy: 0.7865 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.7882 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.7847 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7882 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7847 - val_loss: 0.5120 - val_accuracy: 0.7500\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7882 - val_loss: 0.5120 - val_accuracy: 0.7500\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7865 - val_loss: 0.5120 - val_accuracy: 0.7500\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7882 - val_loss: 0.5120 - val_accuracy: 0.7500\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7882 - val_loss: 0.5120 - val_accuracy: 0.7500\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4440 - accuracy: 0.7882 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7899 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7882 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7865 - val_loss: 0.5118 - val_accuracy: 0.7500\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7899 - val_loss: 0.5118 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "\n",
    "y_pred_prob_nn_2= model_2.predict(X_test) \n",
    "y_pred_class_nn_2= (y_pred_prob_nn_2 > 0.5).astype(\"int32\")\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy is 0.365\n",
      "roc-auc is 0.490\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_2.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_2.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb6dd87deb0>"
      ]
     },
     "metadata": {},
     "execution_count": 85
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}